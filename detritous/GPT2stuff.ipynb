{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e777a9aa-ef5e-4d37-b288-3647e3ba1c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.693       0.693         0.5         0.5           0           0        1.59\n",
      "2                     0           0        2.36        4.03       0.375        0.25           0           0        2.61\n",
      "4                     0           0        7.89          19       0.417         0.5        0.75        0.75         3.9\n",
      "8                     0           0        8.22        8.46       0.321        0.25        0.75           0        7.85\n",
      "16                    0           0        6.74        5.02       0.365       0.417       0.417        0.25        14.7\n",
      "32                    0           0        4.35        1.96        0.49       0.615       0.417       0.417        28.7\n",
      "64                    0           0        3.57        2.76       0.495         0.5       0.481       0.536        56.5\n",
      "128                   0           0        2.49         1.4        0.49       0.485       0.481       0.481         112\n",
      "256                   0           0        1.67       0.851       0.501       0.512       0.466       0.452         225\n",
      "512                   0           0        1.22       0.774       0.516       0.531        0.46       0.453         452\n",
      "1024                  0           0       0.987       0.751       0.503        0.49        0.48         0.5         907\n",
      "2048                  0           0       0.856       0.726       0.502         0.5       0.488       0.496    1.82e+03\n",
      "3045                  0           0       0.809       0.711       0.503       0.507       0.498       0.518     2.7e+03\n",
      "6090                0.5           1       0.755       0.702       0.506       0.508       0.512       0.526    5.37e+03\n",
      "9135                  1           2       0.735       0.693       0.517       0.539       0.517       0.526    8.03e+03\n",
      "12180               1.5           3       0.722       0.685       0.526       0.555       0.517       0.519    1.07e+04\n",
      "15225                 2           4       0.712       0.673       0.537       0.581       0.521       0.535    1.33e+04\n",
      "18270               2.5           5       0.703       0.653        0.55       0.611       0.522       0.528     1.6e+04\n",
      "21315                 3           6       0.692       0.628       0.563       0.641       0.524       0.532    1.87e+04\n",
      "24360               3.5           7        0.68       0.598       0.576       0.673       0.525       0.535    2.14e+04\n",
      "27405                 4           8       0.666       0.555       0.591       0.711       0.526       0.531     2.4e+04\n",
      "30092              4.45           9       0.653       0.518       0.605       0.741       0.526       0.526    2.64e+04\n"
     ]
    }
   ],
   "source": [
    "def peft_gpt_baselines():\n",
    "    from GPT2 import PeftGPT2Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    import torch\n",
    "    from transformers import AutoModelForCausalLM\n",
    "    import warnings\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "\n",
    "    train = train_loader(batch_size=4)\n",
    "    dev = dev_loader(batch_size=4)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    for k in range(1, 4):\n",
    "        torch.manual_seed(2112)\n",
    "        peft_config = IA3Config(task_type=TaskType.CAUSAL_LM, fan_in_fan_out=True)\n",
    "        gpt2 = prepare_model_for_kbit_training(AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-1.3B', load_in_8bit=True))\n",
    "        fewshot = PeftGPT2Classifier(train.num_labels, peft_config, gpt2=gpt2)\n",
    "        with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "\n",
    "            for iteration in range(16):\n",
    "                for istrain, (examples, labels) in interleave(train, dev):\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        target = torch.Tensor([ int(label == train.choices[1]) for label in labels ]).long().to(device)\n",
    "        \n",
    "                        for ex in examples:\n",
    "                            embeddings = train.embed([ ex['title'] ] + \n",
    "                                                     [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            index = torch.topk(embeddings[0,:] @ embeddings[1:,:].T, dim=0, k=k).indices.to('cpu')\n",
    "                            titles = [ f'\"{ex[\"profile\"][ind][\"title\"]}\"' for ind in index.tolist() ]\n",
    "                            concat_titles = ' and '.join(titles)\n",
    "                            input = train.append_to_title(ex, concat_titles)\n",
    "                            inputs.append(input)\n",
    "        \n",
    "                        fewshotacc = (fewshot.predict(inputs).argmax(dim=1) == target).float().mean().item()\n",
    "\n",
    "                    fewloss = fewshot.learn(inputs, target) if istrain else None\n",
    "                    printer.addobs(iteration, fewloss, fewshotacc if istrain else None, fewshotacc if not istrain else None)\n",
    "\n",
    "                printer.print()\n",
    "                printer.autoprint = False\n",
    "\n",
    " \n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or peft_gpt_baselines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84cc825-10ef-4a52-885d-4b644dfaf8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
