{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Step 1: fine-tune LLM using top result from (fixed) ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter (since)      5 loss (since)       5 acc (since) 5 acc (dev) (since)      dt\n",
      "1             0.000 (0.000)       0.670 (0.670)       0.500 (0.500)       0.000 (0.000)  4.05 s\n",
      "2             0.000 (0.000)       0.748 (0.825)       0.500 (0.500)       0.000 (0.000)  7.01 s\n",
      "4             0.000 (0.000)       0.650 (0.552)       0.750 (1.000)       0.000 (0.000)  13.2 s\n",
      "8             0.000 (0.000)       0.686 (0.722)       0.562 (0.375)       0.000 (0.000)    25 s\n",
      "16            0.000 (0.000)       0.693 (0.699)       0.531 (0.500)       0.000 (0.000)  49.2 s\n",
      "32            0.000 (0.000)       0.682 (0.672)       0.531 (0.531)       0.000 (0.000)  1.65 m\n",
      "64            0.000 (0.000)       0.677 (0.672)       0.570 (0.609)       0.000 (0.000)   3.3 m\n",
      "128           0.000 (0.000)       0.659 (0.641)       0.629 (0.688)       0.000 (0.000)  6.56 m\n",
      "256           0.000 (0.000)       0.624 (0.588)       0.689 (0.750)       0.000 (0.000)  13.1 m\n",
      "512           0.000 (0.000)       0.616 (0.609)       0.688 (0.688)       0.000 (0.000)  26.2 m\n",
      "1024          0.000 (0.000)       0.571 (0.526)       0.726 (0.764)       0.000 (0.000)  51.9 m\n",
      "2048          0.000 (0.000)       0.534 (0.498)       0.748 (0.771)       0.000 (0.000)   1.7 h\n",
      "4096          0.000 (0.000)       0.510 (0.485)       0.761 (0.775)       0.000 (0.000)  3.33 h\n",
      "6091          0.000 (0.000)       0.505 (0.477)       0.765 (0.784)       0.760 (0.760)  4.24 h\n",
      "12182         0.500 (1.000)       0.480 (0.455)       0.776 (0.787)       0.755 (0.750)  8.38 h\n",
      "18273         1.000 (2.000)       0.465 (0.435)       0.784 (0.799)       0.751 (0.744)  12.6 h\n"
     ]
    }
   ],
   "source": [
    "def step_one(*, k, max_iteration):\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    import warnings\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl', load_in_8bit=True))\n",
    "    taskllm_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(taskllm_config, \"taskllm\")\n",
    "    t5.enable_adapters()\n",
    "\n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*If you want to save 8-bit models.*\")\n",
    "        \n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev, sequential=True):\n",
    "                with torch.no_grad():\n",
    "                    prompts = []\n",
    "                    target = []\n",
    "    \n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                  [ v['title'] \n",
    "                                                   for v in ex['profile']\n",
    "                                                   if v['title'] != ex['title'] \n",
    "                                                 ])\n",
    "                        scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                        index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
    "                        titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in index.tolist() ]\n",
    "                        concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                        prompt = train.append_to_title(ex, concat_titles)\n",
    "                        prompts.append(prompt)\n",
    "                        target.append(int(label == train.choices[1]))\n",
    "\n",
    "                    target = torch.Tensor(target).long().to(device)\n",
    "                    acc = (taskllm.predict(prompts, augment=train.swap_refs).argmax(dim=1) == target).float().mean().item()\n",
    "\n",
    "                loss = taskllm.learn(prompts, target, augment=train.swap_refs) if istrain else None\n",
    "                printer.addobs(iteration, loss, acc if istrain else None, acc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            taskllm.save_pretrained(f'User_keq{k}_t5xxl_step1_iter{iteration}')\n",
    "\n",
    "from Util import Filter\n",
    "import sys\n",
    "sys.__stderr__ = sys.__stderr__ if type(sys.__stderr__) == Filter else Filter(sys.__stderr__, r'Bad pipe message') \n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or step_one(k=5, max_iteration=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Step 2: learn ranker using (fixed pre-finetuned) task LLM\n",
    "\n",
    "$\\gamma$ = 1, hypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c4dfb-cb62-4d2b-a0e7-d1c281da1c4d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter (since)      5 loss (since)       5 acc (since) 5 acc (dev) (since)       samps (since)      dt\n",
      "1             0.000 (0.000)       0.533 (0.533)       1.000 (1.000)       0.000 (0.000)      30.000 (30.000)  24.5 s\n",
      "2             0.000 (0.000)       0.552 (0.571)       1.000 (1.000)       0.000 (0.000)      20.000 (10.000)  41.7 s\n",
      "4             0.000 (0.000)       0.504 (0.456)       1.000 (1.000)       0.000 (0.000)      16.250 (12.500)  1.31 m\n",
      "8             0.000 (0.000)       0.529 (0.554)       0.812 (0.625)       0.000 (0.000)      14.375 (12.500)  2.58 m\n",
      "16            0.000 (0.000)       0.577 (0.624)       0.719 (0.625)       0.000 (0.000)      17.375 (20.375)  5.87 m\n",
      "32            0.000 (0.000)       0.632 (0.688)       0.688 (0.656)       0.000 (0.000)      16.156 (14.938)  11.3 m\n",
      "64            0.000 (0.000)       0.622 (0.611)       0.711 (0.734)       0.000 (0.000)      16.609 (17.062)  22.6 m\n",
      "128           0.000 (0.000)       0.584 (0.545)       0.758 (0.805)       0.000 (0.000)      14.445 (12.281)  42.3 m\n",
      "256           0.000 (0.000)       0.569 (0.555)       0.771 (0.785)       0.000 (0.000)      14.230 (14.016)   1.4 h\n",
      "512           0.000 (0.000)       0.562 (0.555)       0.759 (0.746)       0.000 (0.000)      13.965 (13.699)  2.75 h\n",
      "1024          0.000 (0.000)       0.552 (0.542)       0.763 (0.768)       0.000 (0.000)      13.137 (12.309)  5.38 h\n",
      "2048          0.000 (0.000)       0.541 (0.531)       0.766 (0.770)       0.000 (0.000)      11.566 (9.996)  10.3 h\n",
      "4096          0.000 (0.000)       0.526 (0.511)       0.777 (0.787)       0.000 (0.000)      10.370 (9.174)  19.9 h\n",
      "6091          0.000 (0.000)       0.521 (0.494)       0.779 (0.791)       0.767 (0.767)      10.146 (8.914)  1.13 d\n",
      "12182         0.500 (1.000)       0.506 (0.491)       0.787 (0.795)       0.768 (0.768)       9.436 (8.726)  2.21 d\n",
      "18273         1.000 (2.000)       0.496 (0.477)       0.791 (0.800)       0.769 (0.772)       9.091 (8.400)  3.28 d\n",
      "24364         1.500 (3.000)       0.489 (0.465)       0.794 (0.802)       0.769 (0.768)       8.852 (8.135)  4.35 d\n"
     ]
    }
   ],
   "source": [
    "def learn_ranker(*, step1_iter, max_iteration, k): # NB: nsamps is off by a factor of 2\n",
    "    from more_itertools import chunked\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from SimpleRegret import SimpleRegretHypercubeSampler\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    import warnings\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl', load_in_8bit=True))\n",
    "    t5.load_adapter(f'User_keq{k}_t5xxl_step1_iter{step1_iter}', 'taskllm')\n",
    "\n",
    "    rhat_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(rhat_config, \"rhat\")\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\")\n",
    "    \n",
    "    def reward_augment(prompts):\n",
    "        import re\n",
    "        return [ re.sub(r'Ref1: (.*)\\nRef2: (.*)\\nExtra:',\n",
    "                        r'Ref1: \\2\\nRef2: \\1\\nExtra:',\n",
    "                        z)\n",
    "                 for z in prompts ]\n",
    "\n",
    "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
    "    def randomized_similarity(ex, nsamples):\n",
    "        embeddings = dev.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                 [ v['title'] \n",
    "                                  for v in ex['profile']\n",
    "                                  if v['title'] != ex['title'] \n",
    "                                ])\n",
    "        scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "        temperature = scores[0].item() - scores[4].item()\n",
    "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
    "        gumbels = temperature * gumbel.sample(gumbel_shape)\n",
    "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=k).indices, sorted=False, dim=0).to('cpu')\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)', 'samps') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*If you want to save 8-bit models.*\")\n",
    "        \n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev, sequential=True):\n",
    "                greedyrewards, allloss, nsamps = [], [], 0\n",
    "                for ex, label in zip(examples, labels):\n",
    "                    with torch.no_grad():\n",
    "                        randos = randomized_similarity(ex, 64)\n",
    "                        \n",
    "                        rhatprompts = []\n",
    "                        prompts = []\n",
    "                        for rando in randos:\n",
    "                            titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in rando ]\n",
    "                            concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                            prompt = dev.append_to_title(ex, concat_titles)\n",
    "                            prompts.append(prompt)\n",
    "                            rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\n\" + '\\n'.join(\n",
    "                                       [ f\"Extra: {t}\" for t in titles ])\n",
    "                            rhatprompts.append(rhatprompt)\n",
    "\n",
    "                        rhats = rewardpredictor.predict(rhatprompts, augment=reward_augment)\n",
    "                        exploit, explore = SimpleRegretHypercubeSampler(rhats.view(1, -1), gamma=1)\n",
    "                        exploit = [ exploit.item() ]\n",
    "                        explore = explore[0].tolist() if istrain else []\n",
    "                        actionind = exploit + [ n for n, observed in enumerate(explore) if observed > 0 ]\n",
    "                        nsamps += len(actionind) \n",
    "                        guesses = taskllm.predict([ prompts[a] for a in actionind ], augment=dev.swap_refs).argmax(dim=1)\n",
    "                        target = int(label == dev.choices[1])\n",
    "                        rewards = (guesses == target).float().tolist()\n",
    "                        greedyreward = rewards[0]\n",
    "                        greedyrewards.append(greedyreward)\n",
    "\n",
    "                    if istrain:\n",
    "                        inner_batch_size = 4\n",
    "                        loss = sum(\n",
    "                            len(inner_batch[0]) * \n",
    "                            rewardpredictor.learn([ rhatprompts[a] for a in inner_batch[0] ], \n",
    "                                                    torch.Tensor([ [ r ] for r in inner_batch[1] ]).to(device),\n",
    "                                                    augment=reward_augment)\n",
    "                            for inner_batch in zip(chunked(actionind, inner_batch_size), chunked(rewards, inner_batch_size))\n",
    "                        ) / len(actionind)\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "\n",
    "                printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None, nsamps if istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            rewardpredictor.save_pretrained(f'User_keq{k}_t5xxl_step2_iter{iteration}')\n",
    "\n",
    "from Fork import SubProcess\n",
    "from Util import BadPipe\n",
    "with BadPipe(), SubProcess() as process: process.parent or learn_ranker(k=5, max_iteration=12, step1_iter=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c6dee-2e51-48f9-9b32-3b751657601a",
   "metadata": {},
   "source": [
    "# Step 3: Prepare submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a557f3f-5aac-4489-ab46-f01bb72b0b5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** step1_iter: 1 step2_iter: 2 nvoters 1 ***\n",
      "n       5 acc (dev) (since)      dt\n",
      "1             0.500 (0.500)  11.5 s\n",
      "4             0.750 (1.000)  47.5 s\n",
      "8             0.875 (1.000)  1.46 m\n",
      "16            0.750 (0.625)  2.83 m\n",
      "32            0.688 (0.625)  5.57 m\n",
      "64            0.781 (0.875)  11.4 m\n",
      "128           0.773 (0.766)  22.7 m\n",
      "256           0.781 (0.789)    45 m\n",
      "512           0.775 (0.770)  1.51 h\n",
      "1024          0.775 (0.775)  3.02 h\n",
      "2048          0.776 (0.777)  6.07 h\n",
      "2500          0.771 (0.748)  7.41 h\n",
      "*** step1_iter: 1 step2_iter: 2 nvoters 3 ***\n",
      "n       5 acc (dev) (since)      dt\n",
      "1             0.500 (0.500)  11.7 s\n",
      "4             0.750 (1.000)  48.9 s\n",
      "8             0.875 (1.000)  1.51 m\n",
      "16            0.750 (0.625)  2.92 m\n",
      "32            0.688 (0.625)  5.74 m\n",
      "64            0.781 (0.875)  11.7 m\n",
      "128           0.781 (0.781)  23.3 m\n",
      "256           0.777 (0.773)  46.1 m\n",
      "512           0.775 (0.773)  1.54 h\n",
      "1024          0.773 (0.771)  3.09 h\n",
      "2048          0.779 (0.785)  6.22 h\n",
      "2500          0.774 (0.750)  7.59 h\n",
      "*** step1_iter: 1 step2_iter: 2 nvoters 5 ***\n",
      "n       5 acc (dev) (since)      dt\n",
      "1             0.500 (0.500)  11.8 s\n",
      "4             0.750 (1.000)  49.4 s\n",
      "8             0.875 (1.000)  1.54 m\n",
      "16            0.750 (0.625)  2.98 m\n",
      "32            0.719 (0.688)  5.89 m\n",
      "64            0.781 (0.844)  12.1 m\n",
      "128           0.781 (0.781)  23.9 m\n",
      "256           0.785 (0.789)  47.4 m\n",
      "512           0.781 (0.777)  1.59 h\n",
      "1024          0.772 (0.764)  3.18 h\n",
      "2048          0.779 (0.785)   6.4 h\n",
      "2500          0.774 (0.750)   7.8 h\n"
     ]
    }
   ],
   "source": [
    "def prepare_submission_probensemble(*, nvoters, step2_iter, step1_iter, k):\n",
    "    import json\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader, test_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    import warnings\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    dev = dev_loader(batch_size=2)\n",
    "    test = test_loader(batch_size=2)\n",
    "\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl', load_in_8bit=True))\n",
    "    t5.load_adapter(f'User_keq{k}_t5xxl_step1_iter{step1_iter}', 'taskllm')\n",
    "    t5.load_adapter(f'User_keq{k}_t5xxl_step2_iter{step2_iter}', 'rhat')\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\", model_id=f'User_keq{k}_t5xxl_step2_iter{step2_iter}')\n",
    "    \n",
    "    def reward_augment(inputs):\n",
    "        import re\n",
    "        return [ re.sub(r'Ref1: (.*)\\nRef2: (.*)\\nExtra:',\n",
    "                        r'Ref1: \\2\\nRef2: \\1\\nExtra:',\n",
    "                        z)\n",
    "                 for z in inputs ]\n",
    "\n",
    "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
    "    def randomized_similarity(ex, nsamples):\n",
    "        embeddings = dev.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                [ v['title'] \n",
    "                                  for v in ex['profile']\n",
    "                                  if v['title'] != ex['title'] \n",
    "                                ])\n",
    "        scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "        temperature = scores[0].item() - scores[4].item()\n",
    "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
    "        gumbels = temperature * gumbel.sample(gumbel_shape)\n",
    "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=k).indices, sorted=False, dim=0).to('cpu')\n",
    "\n",
    "    print(f'*** step1_iter: {step1_iter} step2_iter: {step2_iter} nvoters {nvoters} ***')\n",
    "    \n",
    "    with ProgressPrinter(f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*If you want to save 8-bit models.*\")\n",
    "        \n",
    "        devgolds, testgolds = [], []\n",
    "        \n",
    "        for isdev, (examples, labels) in interleave(dev, test):\n",
    "            greedyrewards = []\n",
    "            for ex, label in zip(examples, labels):\n",
    "                with torch.no_grad():\n",
    "                    randos = randomized_similarity(ex, 64)\n",
    "                    \n",
    "                    rhatprompts = []\n",
    "                    prompts = []\n",
    "                    for rando in randos:\n",
    "                        titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in rando ]\n",
    "                        concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                        prompt = dev.append_to_title(ex, concat_titles)\n",
    "                        prompts.append(prompt)\n",
    "                        rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\n\" + '\\n'.join(\n",
    "                                   [ f\"Extra: {t}\" for t in titles ])\n",
    "                        rhatprompts.append(rhatprompt)\n",
    "\n",
    "                    rhats = rewardpredictor.predict(rhatprompts, augment=reward_augment)\n",
    "                    voters = torch.topk(rhats, k=min(nvoters, len(rhats)), dim=0).indices.view(-1).to('cpu').tolist()\n",
    "                    guess = taskllm.predict([ prompts[v] for v in voters ], augment=dev.swap_refs).logsumexp(dim=0, keepdim=True).argmax(dim=1)\n",
    "                        \n",
    "                    if isdev:\n",
    "                        target = int(label == dev.choices[1])\n",
    "                        reward = int(guess.item() == target)\n",
    "                        greedyrewards.append(reward)\n",
    "\n",
    "                    (devgolds if isdev else testgolds).append({ 'id': ex['id'], 'output': \"[2]\" if guess else \"[1]\" })\n",
    "\n",
    "            greedyacc = torch.Tensor(greedyrewards).float().mean().item() if isdev else None\n",
    "\n",
    "            printer.addobs(greedyacc)\n",
    "\n",
    "        printer.print()\n",
    "        printer.autoprint = False\n",
    "\n",
    "        for wut, golds in ( ('dev', devgolds), ('test', testgolds) ):\n",
    "            with open(f'lamp1u_{wut}golds_t5xxl_keq{k}_step1_iter{step1_iter}_step2_iter{step2_iter}_pens_nvoters{nvoters}.json', 'w') as jsonfile:\n",
    "                json.dump({ 'task': 'LaMP_1', 'golds': golds }, jsonfile)\n",
    "            \n",
    "from Fork import SubProcess\n",
    "from Util import BadPipe\n",
    "for nvoters in [1, 3, 5]:\n",
    "    with BadPipe(), SubProcess() as process: process.parent or prepare_submission_probensemble(k=5, step1_iter=1, step2_iter=2, nvoters=nvoters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf0dc4-2975-468b-8b01-63ff6e95ea65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
