{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Step 1: fine-tune LLM using top result from (fixed) ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.752       0.752           0           0           0           0        3.89\n",
      "2                     0           0       0.707       0.662         0.5           1           0           0        6.83\n",
      "4                     0           0       0.697       0.678         0.5         0.5         0.5         0.5          11\n",
      "8                     0           0       0.696       0.695       0.571       0.625         0.5           0        22.6\n",
      "16                    0           0       0.695       0.693       0.462       0.333         0.5         0.5        42.2\n",
      "32                    0           0       0.694       0.693         0.5       0.538       0.417       0.333        84.7\n",
      "64                    0           0       0.694       0.693       0.529        0.56       0.423       0.429         167\n",
      "128                   0           0       0.693       0.693       0.529       0.529       0.385       0.346         334\n",
      "256                   0           0       0.683       0.673       0.586       0.642       0.519       0.654         670\n",
      "512                   0           0       0.652       0.621       0.645       0.704       0.619       0.717    1.34e+03\n",
      "1024                  0           0       0.625       0.598        0.66       0.674       0.636       0.652    2.66e+03\n",
      "2048                  0           0       0.601       0.576       0.681       0.703       0.663        0.69     5.3e+03\n",
      "4096                  0           0       0.579       0.558       0.694       0.707       0.677       0.692    1.05e+04\n",
      "6090                  0           0       0.577       0.572       0.693        0.69       0.675        0.67    1.56e+04\n",
      "7339               0.17           1       0.577           0       0.693           0       0.686       0.696    1.69e+04\n"
     ]
    }
   ],
   "source": [
    "def step_one():\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    import warnings\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xl', load_in_8bit=True))\n",
    "    taskllm_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(taskllm_config, \"taskllm\")\n",
    "    t5.enable_adapters()\n",
    "\n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "\n",
    "    k = 1\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*If you want to save 8-bit models.*\")\n",
    "        \n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        target = []\n",
    "        \n",
    "                        for ex, label in zip(examples, labels):\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                inputs.append(input)\n",
    "                                target.append(int(label == train.choices[1]))\n",
    "\n",
    "                        target = torch.Tensor(target).long().to(device)\n",
    "                        acc = (taskllm.predict(inputs, augment=train.swap_refs).argmax(dim=1) == target).float().mean().item()\n",
    "    \n",
    "                    loss = taskllm.learn(inputs, target, augment=train.swap_refs) if istrain else None\n",
    "                    printer.addobs(iteration, loss, acc if istrain else None, acc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            if iteration == 0:\n",
    "                taskllm.save_pretrained('User_keq1_t5xl_step1')\n",
    "\n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or step_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Step 2: learn ranker using (fixed pre-finetuned) task LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c4dfb-cb62-4d2b-a0e7-d1c281da1c4d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      8 loss       since       8 acc       since 8 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.338       0.338           0           0           0           0        15.4\n",
      "2                     0           0       0.348       0.358         0.5           1           0           0          30\n",
      "4                     0           0        0.35       0.351         0.5         0.5           0           0        59.6\n",
      "8                     0           0       0.306       0.247       0.714           1           1           1         109\n",
      "16                    0           0       0.327       0.346       0.733        0.75           1           0         232\n",
      "32                    0           0       0.312       0.296       0.724       0.714           1           1         452\n",
      "64                    0           0       0.279       0.245       0.754       0.786           1           1         897\n",
      "128                   0           0       0.294        0.31       0.702       0.649       0.786       0.571    1.79e+03\n",
      "256                   0           0       0.297         0.3       0.722       0.743       0.724       0.667    3.54e+03\n",
      "512                   0           0         0.3       0.303       0.714       0.705       0.672       0.621    7.06e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'G\\x9c\\x01\\x12a\\xb0\\xe1\\x82\\x1d\\xf1\\xb6\\xd4\\xa1\\x1a\\xff\\xb9\\xf4; k\\x01:\\x82L@\\x7f\\x18\\x9ed&\\x8d\\x04*\\xb2!N\\xe1\\x85XR+\\x90\\xb6/\\xcd\\xd5p\\xa2c\\x13=\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02']\n",
      "Bad pipe message: %s [b'\\x92>=?$`My']\n",
      "Bad pipe message: %s [b'\\xf5\\x01E\\x96\\x1b\\xa6\\x03\\xc4\\x81\\xael\\xc1xc\\xab>\\xd1\\x1c\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\']\n",
      "Bad pipe message: %s [b\"U\\xb2\\x91=\\x07\\xfa\\x14\\xa5\\xb8^\\xdf?\\xbf\\xda\\xdc`\\xb3\\xe1\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\"]\n",
      "Bad pipe message: %s [b'\\x92KC\\x10\\x9d\\xb5\\xb5\\x08R\\x10\\xe2\\xd4\\x96\\xf3\\xb2Kh\\x10\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00', b'#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01\\x15']\n",
      "Bad pipe message: %s [b'\\x00\\x02']\n",
      "Bad pipe message: %s [b'I\\x8b\\x1b\\x86\\xe8\\xa93\\xd8\\x1b\\x90\\x1a\\x8cF\\xec-H\\xaa']\n",
      "Bad pipe message: %s [b'\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15']\n",
      "Bad pipe message: %s [b'h^=\\x81\\xf6\\x0f\\xaeBv\\x96\\x8bn\\xec\\x1e\\x87\\xebg\\x89\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024                  0           0       0.298       0.296       0.708       0.702       0.718       0.763     1.4e+04\n",
      "2048                  0           0       0.298       0.297       0.738       0.767       0.697       0.675    2.78e+04\n"
     ]
    }
   ],
   "source": [
    "def learn_ranker(rank):\n",
    "    from more_itertools import chunked\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    import warnings\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2, double_data=True)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xl', load_in_8bit=True))\n",
    "    t5.load_adapter('User_keq1_t5xl_step1', 'taskllm')\n",
    "\n",
    "    rhat_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(rhat_config, \"rhat\")\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\")\n",
    "    \n",
    "    def reward_augment(inputs):\n",
    "        import re\n",
    "        return [ re.sub(r'Ref1: (.*)\\nRef2: (.*)\\nExtra:',\n",
    "                        r'Ref1: \\2\\nRef2: \\1\\nExtra:',\n",
    "                        z)\n",
    "                 for z in inputs ]\n",
    "\n",
    "    with ProgressPrinter('iter', f'{rank} loss', f'{rank} acc', f'{rank} acc (dev)') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*If you want to save 8-bit models.*\")\n",
    "        \n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        greedyrewards = []\n",
    "                        allloss = []\n",
    "                        with torch.no_grad():\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=rank).indices.to('cpu')\n",
    "                            prompts = []\n",
    "                            rhatprompts = []\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                prompts.append(input)\n",
    "                                rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\nExtra: {titles[0]}\"\n",
    "                                rhatprompts.append(rhatprompt)\n",
    "\n",
    "                            guesses = taskllm.predict(prompts, augment=train.swap_refs).argmax(dim=1)\n",
    "                            target = int(label == train.choices[1])\n",
    "                            rewards = (guesses == target).float().unsqueeze(1)\n",
    "                            rhats = rewardpredictor.predict(rhatprompts, augment=reward_augment)\n",
    "                            greedy = torch.argmax(rhats, dim=0).item()\n",
    "                            greedyreward = rewards[greedy, 0].item()\n",
    "                            greedyrewards.append(greedyreward)\n",
    "\n",
    "                        inner_batch_size = 2\n",
    "                        loss = sum(len(x) * rewardpredictor.learn(x, rtensor, augment=reward_augment) \n",
    "                                   for x, r in zip(chunked(rhatprompts, inner_batch_size), chunked(rewards.tolist(), inner_batch_size))\n",
    "                                   for rtensor in (torch.Tensor(r).to(device),)\n",
    "                                  ) / len(rhatprompts) if istrain else None\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                    greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                    predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "\n",
    "                    printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "        rewardpredictor.save_pretrained(f'User_keq1_t5xl_step2_rankeq{rank}')\n",
    "\n",
    "from Fork import SubProcess\n",
    "for rank in range(8, 9):\n",
    "    with SubProcess() as process: process.parent or learn_ranker(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498ff16-f362-4447-a4fe-cf1e87721616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
