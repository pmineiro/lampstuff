{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a958c5-4e38-4d9e-bbc0-eb9792d38ae3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b59252e-b33a-4c6f-b0a9-a13da86a391e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0        0.68        0.68           1           1           0           0        1.04\n",
      "2                     0           0        1.43        2.18         0.5           0           0           0        1.42\n",
      "4                     0           0        1.23       0.821       0.333           0           0           0        2.02\n",
      "8                     0           0       0.925       0.698         0.5       0.625           0           0        3.45\n",
      "16                    0           0       0.878       0.823       0.423       0.333         0.5        0.75        5.98\n",
      "32                    0           0       0.798       0.717       0.462         0.5       0.583       0.667          12\n",
      "64                    0           0       0.746       0.692        0.52        0.58       0.731       0.857        22.7\n",
      "128                   0           0       0.734       0.721        0.51         0.5       0.577       0.423        45.4\n",
      "256                   0           0       0.723       0.713       0.507       0.505       0.558       0.538          90\n",
      "512                   0           0       0.708       0.692       0.512       0.517       0.519       0.481         181\n",
      "1024                  0           0       0.684       0.661       0.559       0.606       0.555        0.59         366\n",
      "2048                  0           0       0.659       0.633       0.598       0.638       0.583       0.612         743\n",
      "4096                  0           0       0.631       0.602       0.632       0.665       0.614       0.644    1.49e+03\n",
      "6090                  0           0       0.623       0.607       0.642       0.662       0.628       0.658    2.22e+03\n",
      "7339               0.17           1       0.623           0       0.642           0       0.646       0.663    2.59e+03\n"
     ]
    }
   ],
   "source": [
    "def trace(k):\n",
    "    from MegaT5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    fewshot = PeftT5Classifier(train.num_labels, peft_config, t5=t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, open(f'trace{k}.csv', 'w', newline='') as csvfile:\n",
    "        import csv\n",
    "        writer = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        trace = []\n",
    "                        target = torch.Tensor([ int(label == train.choices[1]) for label in labels ]).long().to(device)\n",
    "        \n",
    "                        for ex in examples:\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
    "                            titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in index.tolist() ]\n",
    "                            concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                            input = train.append_to_title(ex, concat_titles)\n",
    "                            inputs.append(input)\n",
    "                            trace.append((ex['title'], ex['ref1'], ex['ref2'], titles))\n",
    "        \n",
    "                        fewshotacc = (fewshot.predict(inputs).argmax(dim=1) == target).int()\n",
    "                        avfewshotacc = fewshotacc.float().mean().item()\n",
    "    \n",
    "                    fewloss = fewshot.learn(inputs, target) if istrain else None\n",
    "                    printer.addobs(iteration, fewloss, avfewshotacc if istrain else None, avfewshotacc if not istrain else None)\n",
    "\n",
    "                    if istrain:\n",
    "                        for (title, ref1, ref2, titles), acc in zip(trace, fewshotacc.tolist()):\n",
    "                            writer.writerow([acc, title, ref1, ref2] + titles)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    " \n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or peft_t5_baselines(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "caaa6f3c-cc33-4175-a91c-00f953bea73c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter     since    1 loss     since     1 acc     since   bc loss     since    dt (s)\n",
      "1                 0         0     0.705     0.705         0         0         0         0     0.547\n",
      "2                 0         0      3.05       5.4         0         0     0.448     0.896     0.626\n",
      "4                 0         0      1.95      0.85     0.375      0.75     0.503     0.558     0.769\n",
      "8                 0         0       1.2     0.456     0.562      0.75     0.584     0.665     0.996\n",
      "16                0         0      1.12      1.04     0.438     0.312      0.63     0.676      1.45\n",
      "32                0         0     0.988     0.853       0.5     0.562     0.657     0.684      2.35\n",
      "64                0         0     0.878     0.768     0.547     0.594     0.671     0.686      4.13\n",
      "128               0         0     0.833     0.788     0.504     0.461     0.681     0.691       7.7\n",
      "256               0         0     0.795     0.757      0.49     0.477     0.687     0.692      14.9\n",
      "512               0         0     0.758     0.721     0.515     0.539     0.687     0.687      29.2\n",
      "1024              0         0     0.722     0.685     0.546     0.578      0.68     0.673      58.1\n",
      "2048              0         0     0.687     0.652     0.599     0.651     0.666     0.651       116\n",
      "4096              0         0     0.664     0.641     0.628     0.657     0.655     0.644       231\n",
      "4841              0         0      0.66     0.638     0.634     0.668     0.652     0.637       273\n",
      "9682            0.5         1      0.66         0     0.638     0.642     0.652     0.652       361\n"
     ]
    }
   ],
   "source": [
    "# GPT2\n",
    "def model_trace(k):\n",
    "    from GPT2 import PeftGPT2Classifier\n",
    "    from more_itertools import chunked\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import AutoModelForCausalLM\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.CAUSAL_LM, fan_in_fan_out=True)\n",
    "    model = PeftGPT2Classifier(1, peft_config)\n",
    "    best_const, best_const_n = 0\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'bc loss') as printer:\n",
    "        for iteration in range(2):\n",
    "            with open(f'trace{k}.csv', 'r', newline='') as csvfile:\n",
    "                import csv\n",
    "                reader = csv.reader(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "                for batch in chunked(reader, 2):\n",
    "                    bc_pred = []\n",
    "                    inputs = []\n",
    "                    target = []\n",
    "                    for row in batch:\n",
    "                        acc, title, ref1, ref2 = row[0:4]\n",
    "                        extra = '\\n'.join([ f\"Extra: {extra}\" for extra in row[4:] ])\n",
    "                        prompt = f\"Title: {title}\\nRef1: {ref1}\\nRef2: {ref2}\\n{extra}\"\n",
    "                        inputs.append(prompt)\n",
    "                        target.append([float(acc)])\n",
    "                        if iteration == 0:\n",
    "                            best_const += float(acc)\n",
    "                            best_const_n += 1\n",
    "                        bc_pred.append([best_const / best_const_n])\n",
    "                            \n",
    "                    target = torch.Tensor(target).to(device)\n",
    "                        \n",
    "                    with torch.no_grad():\n",
    "                        acc = ((model.predict(inputs) > 1/2).float() == target).float().mean()\n",
    "                        best_const_loss = torch.nn.functional.binary_cross_entropy(torch.Tensor(bc_pred).to(device), target)\n",
    "        \n",
    "                    loss = model.learn(inputs, target) if iteration == 0 else None\n",
    "                    printer.addobs(iteration, loss, acc, best_const_loss)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    " \n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or model_trace(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fd5013a-efc7-44cf-8638-ecdea7815428",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter     since    1 loss     since     1 acc     since   bc loss     since    dt (s)\n",
      "1                 0         0     0.683     0.683         1         1         0         0     0.685\n",
      "2                 0         0      0.71     0.737       0.5         0     0.448     0.896     0.812\n",
      "4                 0         0     0.704     0.698     0.375      0.25     0.503     0.558      1.06\n",
      "8                 0         0       0.7     0.695     0.438       0.5     0.584     0.665      1.56\n",
      "16                0         0     0.701     0.703     0.406     0.375      0.63     0.676      2.54\n",
      "32                0         0       0.7     0.699     0.406     0.406     0.657     0.684      4.47\n",
      "64                0         0     0.697     0.694     0.461     0.516     0.671     0.686      8.39\n",
      "128               0         0     0.698     0.698     0.465     0.469     0.681     0.691      16.3\n",
      "256               0         0     0.698     0.698     0.471     0.477     0.687     0.692      31.9\n",
      "512               0         0     0.691     0.685     0.505     0.539     0.687     0.687      63.5\n",
      "1024              0         0      0.68     0.669     0.559     0.612      0.68     0.673       126\n",
      "2048              0         0     0.663     0.646     0.607     0.655     0.666     0.651       251\n",
      "4096              0         0     0.646     0.629     0.633     0.658     0.655     0.644       499\n",
      "4841              0         0     0.642     0.619     0.638     0.668     0.652     0.637       590\n",
      "9682            0.5         1     0.642         0      0.64     0.641     0.652     0.652       802\n"
     ]
    }
   ],
   "source": [
    "# flan-t5-base\n",
    "def model_trace(k):\n",
    "    from T5 import PeftT5Classifier\n",
    "    from more_itertools import chunked\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    model = PeftT5Classifier(1, peft_config, t5=t5)\n",
    "    best_const, best_const_n = 0, 0\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'bc loss') as printer:\n",
    "        for iteration in range(2):\n",
    "            with open(f'trace{k}.csv', 'r', newline='') as csvfile:\n",
    "                import csv\n",
    "                reader = csv.reader(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "                for batch in chunked(reader, 2):\n",
    "                    bc_pred = []\n",
    "                    inputs = []\n",
    "                    target = []\n",
    "                    for row in batch:\n",
    "                        acc, title, ref1, ref2 = row[0:4]\n",
    "                        extra = '\\n'.join([ f\"Extra: {extra}\" for extra in row[4:] ])\n",
    "                        prompt = f\"Title: {title}\\nRef1: {ref1}\\nRef2: {ref2}\\n{extra}\"\n",
    "                        inputs.append(prompt)\n",
    "                        target.append([float(acc)])\n",
    "                        if iteration == 0:\n",
    "                            best_const += float(acc)\n",
    "                            best_const_n += 1\n",
    "                        bc_pred.append([best_const / best_const_n])\n",
    "                            \n",
    "                    target = torch.Tensor(target).to(device)\n",
    "                        \n",
    "                    with torch.no_grad():\n",
    "                        acc = ((model.predict(inputs) > 1/2).float() == target).float().mean()\n",
    "                        best_const_loss = torch.nn.functional.binary_cross_entropy(torch.Tensor(bc_pred).to(device), target)\n",
    "        \n",
    "                    loss = model.learn(inputs, target) if iteration == 0 else None\n",
    "                    printer.addobs(iteration, loss, acc, best_const_loss)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or model_trace(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a2b8ab3-0e71-43d7-8f12-9162ce22d1fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter     since    1 loss     since     1 acc     since   bc loss     since    dt (s)\n",
      "1                 0         0     0.682     0.682         1         1         0         0      1.72\n",
      "2                 0         0     0.725     0.768       0.5         0     0.448     0.896      2.85\n",
      "4                 0         0     0.711     0.698     0.375      0.25     0.503     0.558      5.03\n",
      "8                 0         0     0.706       0.7     0.438       0.5     0.584     0.665      9.31\n",
      "16                0         0     0.707     0.709     0.406     0.375      0.63     0.676      17.9\n",
      "32                0         0     0.705     0.703     0.406     0.406     0.657     0.684      35.1\n",
      "64                0         0     0.701     0.696     0.453       0.5     0.671     0.686      69.3\n",
      "128               0         0       0.7     0.699     0.469     0.484     0.681     0.691       138\n",
      "256               0         0     0.699     0.698     0.475      0.48     0.687     0.692       277\n",
      "512               0         0     0.692     0.685     0.501     0.527     0.687     0.687       558\n",
      "1024              0         0     0.681     0.669     0.557     0.612      0.68     0.673  1.11e+03\n",
      "2048              0         0     0.659     0.638     0.606     0.655     0.666     0.651  2.23e+03\n",
      "4096              0         0     0.633     0.607      0.63     0.654     0.655     0.644  4.44e+03\n",
      "4841              0         0     0.628       0.6     0.636     0.668     0.652     0.637  5.24e+03\n",
      "9682            0.5         1     0.628         0     0.643     0.651     0.652     0.652  7.25e+03\n"
     ]
    }
   ],
   "source": [
    "# flan-t5-xl\n",
    "def model_trace(k):\n",
    "    from T5 import PeftT5Classifier\n",
    "    from more_itertools import chunked\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    import warnings\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xl', load_in_8bit=True))\n",
    "    model = PeftT5Classifier(1, peft_config, t5=t5)\n",
    "    best_const, best_const_n = 0, 0\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'bc loss') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        for iteration in range(2):\n",
    "            with open(f'trace{k}.csv', 'r', newline='') as csvfile:\n",
    "                import csv\n",
    "                reader = csv.reader(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "                for batch in chunked(reader, 2):\n",
    "                    bc_pred = []\n",
    "                    inputs = []\n",
    "                    target = []\n",
    "                    for row in batch:\n",
    "                        acc, title, ref1, ref2 = row[0:4]\n",
    "                        extra = '\\n'.join([ f\"Extra: {extra}\" for extra in row[4:] ])\n",
    "                        prompt = f\"Title: {title}\\nRef1: {ref1}\\nRef2: {ref2}\\n{extra}\"\n",
    "                        inputs.append(prompt)\n",
    "                        target.append([float(acc)])\n",
    "                        if iteration == 0:\n",
    "                            best_const += float(acc)\n",
    "                            best_const_n += 1\n",
    "                        bc_pred.append([best_const / best_const_n])\n",
    "                            \n",
    "                    target = torch.Tensor(target).to(device)\n",
    "                        \n",
    "                    with torch.no_grad():\n",
    "                        acc = ((model.predict(inputs) > 1/2).float() == target).float().mean()\n",
    "                        best_const_loss = torch.nn.functional.binary_cross_entropy(torch.Tensor(bc_pred).to(device), target)\n",
    "        \n",
    "                    loss = model.learn(inputs, target) if iteration == 0 else None\n",
    "                    printer.addobs(iteration, loss, acc, best_const_loss)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or model_trace(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e545c3-d092-409b-a65c-581252459a76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# mega trace (no finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "760c380e-15a2-4b47-b3ff-7fc47e1d20ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0           0           0        0.75        0.75           0           0        1.03\n",
      "2                     0           0           0           0       0.438       0.125           0           0        1.38\n",
      "4                     0           0           0           0       0.625           1           0           0        2.08\n",
      "8                     0           0           0           0       0.554         0.5           0           0        3.43\n",
      "16                    0           0           0           0        0.49       0.417       0.354       0.531        6.05\n",
      "32                    0           0           0           0       0.529       0.567        0.24       0.125        12.3\n",
      "64                    0           0           0           0       0.501       0.472       0.346       0.438        23.6\n",
      "128                   0           0           0           0       0.483       0.464       0.502       0.659        47.4\n",
      "256                   0           0           0           0       0.483       0.482        0.48       0.457        95.1\n",
      "512                   0           0           0           0       0.487       0.492       0.499       0.519         194\n",
      "1024                  0           0           0           0       0.488       0.489       0.489       0.479         397\n",
      "2048                  0           0           0           0       0.482       0.476       0.486       0.483         811\n",
      "4096                  0           0           0           0       0.481        0.48       0.479       0.472    1.63e+03\n",
      "6090                  0           0           0           0       0.482       0.484       0.482       0.489    2.42e+03\n",
      "7339               0.17           1           0           0       0.482           0       0.482       0.482    2.93e+03\n"
     ]
    }
   ],
   "source": [
    "# no finetuning ...\n",
    "def mega_trace(k):\n",
    "    from MegaT5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    assert k == 1\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    fewshot = PeftT5Classifier(train.num_labels, peft_config, t5=t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, open(f'megatrace{k}.csv', 'w', newline='') as csvfile:\n",
    "        import csv\n",
    "        writer = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        trace = []\n",
    "                        target = []\n",
    "        \n",
    "                        for ex, label in zip(examples, labels):\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=8).indices.to('cpu')\n",
    "                            for oneind in index.tolist():\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                inputs.append(input)\n",
    "                                trace.append((ex['title'], ex['ref1'], ex['ref2'], titles))\n",
    "                                target.append(int(label == train.choices[1]))\n",
    "\n",
    "                        target = torch.Tensor(target).long().to(device)\n",
    "                        fewshotacc = (fewshot.predict(inputs).argmax(dim=1) == target).int()\n",
    "                        avfewshotacc = fewshotacc.float().mean().item()\n",
    "    \n",
    "                    fewloss = None # fewshot.learn(inputs, target) if istrain else None\n",
    "                    printer.addobs(iteration, fewloss, avfewshotacc if istrain else None, avfewshotacc if not istrain else None)\n",
    "\n",
    "                    if istrain:\n",
    "                        for (title, ref1, ref2, titles), acc in zip(trace, fewshotacc.tolist()):\n",
    "                            writer.writerow([acc, title, ref1, ref2] + titles)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or mega_trace(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62239262-ce72-4d38-9de8-a40509bfcf62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter     since    1 loss     since     1 acc     since   bc loss     since    dt (s)\n",
      "1                 0         0     0.703     0.703         0         0         0         0      1.02\n",
      "2                 0         0     0.687     0.671       0.5         1         0         0      1.15\n",
      "4                 0         0     0.678     0.669     0.625      0.75      0.26      0.52      1.39\n",
      "8                 0         0     0.683     0.688     0.625     0.625     0.469     0.678      1.88\n",
      "16                0         0     0.681      0.68     0.625     0.625     0.562     0.655      2.85\n",
      "32                0         0     0.696      0.71     0.531     0.438     0.649     0.737      4.76\n",
      "64                0         0     0.696     0.696     0.461     0.391     0.668     0.687      8.64\n",
      "128               0         0     0.697     0.699      0.48       0.5      0.68     0.692      16.3\n",
      "256               0         0     0.696     0.696       0.5      0.52     0.684     0.689      31.7\n",
      "512               0         0     0.695     0.694     0.512     0.523     0.687     0.691      62.5\n",
      "1024              0         0     0.695     0.694     0.501     0.491     0.691     0.694       124\n",
      "2048              0         0     0.694     0.693     0.515     0.529     0.691     0.691       244\n",
      "4096              0         0     0.694     0.693     0.514     0.513     0.692     0.693       484\n",
      "8192              0         0     0.693     0.693      0.51     0.506     0.692     0.693       962\n",
      "16384             0         0     0.693     0.692     0.514     0.519     0.692     0.692   1.9e+03\n",
      "32768             0         0     0.693     0.693     0.516     0.519     0.692     0.692  3.77e+03\n",
      "38728             0         0     0.693     0.692     0.517      0.52     0.692     0.692  4.45e+03\n",
      "77456           0.5         1     0.693         0     0.517     0.518     0.693     0.692  6.03e+03\n"
     ]
    }
   ],
   "source": [
    "# flan-t5-base\n",
    "def model_trace(k):\n",
    "    from T5 import PeftT5Classifier\n",
    "    from more_itertools import chunked\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import random\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "    random.seed(8675309)\n",
    "    \n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    model = PeftT5Classifier(1, peft_config, t5=t5)\n",
    "    best_const, best_const_n = 0, 0\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'bc loss') as printer:\n",
    "        for iteration in range(2):\n",
    "            with open(f'megatrace{k}.csv', 'r', newline='') as csvfile:\n",
    "                import csv\n",
    "                reader = csv.reader(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "                rows = [row for row in reader]\n",
    "                random.shuffle(rows)\n",
    "                for batch in chunked(rows, 2):\n",
    "                    bc_pred = []\n",
    "                    inputs = []\n",
    "                    target = []\n",
    "                    for row in batch:\n",
    "                        acc, title, ref1, ref2 = row[0:4]\n",
    "                        extra = '\\n'.join([ f\"Extra: {extra}\" for extra in row[4:] ])\n",
    "                        prompt = f\"Title: {title}\\nRef1: {ref1}\\nRef2: {ref2}\\n{extra}\"\n",
    "                        inputs.append(prompt)\n",
    "                        target.append([float(acc)])\n",
    "                        if iteration == 0:\n",
    "                            best_const += float(acc)\n",
    "                            best_const_n += 1\n",
    "                        bc_pred.append([best_const / best_const_n])\n",
    "                            \n",
    "                    target = torch.Tensor(target).to(device)\n",
    "                        \n",
    "                    with torch.no_grad():\n",
    "                        acc = ((model.predict(inputs) > 1/2).float() == target).float().mean()\n",
    "                        best_const_loss = torch.nn.functional.binary_cross_entropy(torch.Tensor(bc_pred).to(device), target)\n",
    "        \n",
    "                    loss = model.learn(inputs, target) if iteration == 0 else None\n",
    "                    printer.addobs(iteration, loss, acc, best_const_loss)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or model_trace(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8717a-444e-45cc-8f6f-1bab154702c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ultra trace (with finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f661042-0ec5-4782-9c29-15e5891e87b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0        0.68        0.68        0.75        0.75           0           0        1.14\n",
      "2                     0           0        1.43        2.18       0.375           0           0           0        1.61\n",
      "4                     0           0        1.23       0.821        0.25           0           0           0         2.4\n",
      "8                     0           0       0.925       0.698       0.455       0.609           0           0         4.2\n",
      "16                    0           0       0.878       0.823       0.399       0.333         0.5        0.75        7.46\n",
      "32                    0           0       0.798       0.717       0.466       0.534       0.573       0.646          15\n",
      "64                    0           0       0.746       0.692       0.522        0.58       0.726       0.857        29.8\n",
      "128                   0           0       0.734       0.721       0.512       0.501        0.57       0.413        59.1\n",
      "256                   0           0       0.723       0.713       0.504       0.496       0.558       0.546         118\n",
      "512                   0           0       0.708       0.692       0.506       0.509       0.514       0.472         240\n",
      "1024                  0           0       0.684        0.66       0.543        0.58       0.521       0.527         488\n",
      "2048                  0           0       0.659       0.633       0.573       0.602       0.555       0.589         983\n",
      "4096                  0           0       0.631       0.603       0.596       0.619       0.578         0.6    1.97e+03\n",
      "6090                  0           0       0.623       0.608       0.605       0.625        0.59       0.614    2.92e+03\n",
      "7339               0.17           1       0.623           0       0.605           0       0.607       0.623    3.43e+03\n"
     ]
    }
   ],
   "source": [
    "# with finetuning ...\n",
    "def ultra_trace(k):\n",
    "    from MegaT5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    assert k == 1\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    fewshot = PeftT5Classifier(train.num_labels, peft_config, t5=t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, open(f'ultratrace{k}.csv', 'w', newline='') as csvfile:\n",
    "        import csv\n",
    "        writer = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        trace = []\n",
    "                        target = []\n",
    "                        traininputs = []\n",
    "                        traintarget = []\n",
    "        \n",
    "                        for ex, label in zip(examples, labels):\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=8).indices.to('cpu')\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                inputs.append(input)\n",
    "                                trace.append((ex['title'], ex['ref1'], ex['ref2'], titles))\n",
    "                                target.append(int(label == train.choices[1]))\n",
    "                                if n == 0:\n",
    "                                    traininputs.append(input)\n",
    "                                    traintarget.append(int(label == train.choices[1]))\n",
    "\n",
    "                        target = torch.Tensor(target).long().to(device)\n",
    "                        traintarget = torch.Tensor(traintarget).long().to(device)\n",
    "                        fewshotacc = (fewshot.predict(inputs).argmax(dim=1) == target).int()\n",
    "                        avfewshotacc = fewshotacc.float().mean().item()\n",
    "    \n",
    "                    fewloss = fewshot.learn(traininputs, traintarget) if istrain else None\n",
    "                    printer.addobs(iteration, fewloss, avfewshotacc if istrain else None, avfewshotacc if not istrain else None)\n",
    "\n",
    "                    if istrain:\n",
    "                        for (title, ref1, ref2, titles), acc in zip(trace, fewshotacc.tolist()):\n",
    "                            writer.writerow([acc, title, ref1, ref2] + titles)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or ultra_trace(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b5a9250-24ce-4449-abeb-bf8972777c8a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter     since    1 loss     since     1 acc     since   bc loss     since    dt (s)\n",
      "1                 0         0     0.693     0.693       0.5       0.5     0.347     0.347     0.966\n",
      "2                 0         0     0.693     0.693       0.5       0.5     0.448     0.549      1.09\n",
      "4                 0         0      0.69     0.688     0.625      0.75     0.503     0.558      1.33\n",
      "8                 0         0     0.696     0.702     0.562       0.5     0.584     0.665      1.82\n",
      "16                0         0     0.699     0.701     0.469     0.375      0.63     0.676      2.78\n",
      "32                0         0     0.698     0.697     0.516     0.562     0.653     0.676      4.71\n",
      "64                0         0     0.698     0.698     0.531     0.547     0.668     0.683      8.59\n",
      "128               0         0     0.691     0.684     0.559     0.586     0.673     0.677      16.3\n",
      "256               0         0     0.674     0.658     0.598     0.637     0.666     0.659      31.7\n",
      "512               0         0     0.678     0.681     0.594      0.59     0.671     0.676      62.5\n",
      "1024              0         0     0.677     0.676     0.596     0.599     0.672     0.673       124\n",
      "2048              0         0     0.676     0.674     0.599     0.602     0.672     0.672       249\n",
      "4096              0         0     0.671     0.667     0.607     0.615     0.669     0.666       497\n",
      "8192              0         0     0.669     0.667     0.605     0.604      0.67     0.671       988\n",
      "16384             0         0     0.662     0.656     0.607     0.609      0.67     0.669  1.96e+03\n",
      "32768             0         0     0.658     0.653     0.605     0.603      0.67     0.671  3.84e+03\n",
      "38728             0         0     0.657     0.654     0.604     0.596     0.671     0.673  4.52e+03\n",
      "77456           0.5         1     0.657         0     0.605     0.606      0.67     0.671   6.1e+03\n"
     ]
    }
   ],
   "source": [
    "# flan-t5-base\n",
    "def model_trace(k):\n",
    "    from T5 import PeftT5Classifier\n",
    "    from more_itertools import chunked\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import random\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "    random.seed(8675309)\n",
    "    \n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    model = PeftT5Classifier(1, peft_config, t5=t5)\n",
    "    best_const, best_const_n = 0, 0\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'bc loss') as printer:\n",
    "        for iteration in range(2):\n",
    "            with open(f'ultratrace{k}.csv', 'r', newline='') as csvfile:\n",
    "                import csv\n",
    "                reader = csv.reader(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "                rows = [row for row in reader]\n",
    "                random.shuffle(rows)\n",
    "                for batch in chunked(rows, 2):\n",
    "                    bc_pred = []\n",
    "                    inputs = []\n",
    "                    target = []\n",
    "                    for row in batch:\n",
    "                        acc, title, ref1, ref2 = row[0:4]\n",
    "                        extra = '\\n'.join([ f\"Extra: {extra}\" for extra in row[4:] ])\n",
    "                        prompt = f\"Title: {title}\\nRef1: {ref1}\\nRef2: {ref2}\\n{extra}\"\n",
    "                        inputs.append(prompt)\n",
    "                        target.append([float(acc)])\n",
    "                        if iteration == 0:\n",
    "                            best_const += float(acc)\n",
    "                            best_const_n += 1\n",
    "                        bc_pred.append([best_const / best_const_n])\n",
    "                            \n",
    "                    target = torch.Tensor(target).to(device)\n",
    "                        \n",
    "                    with torch.no_grad():\n",
    "                        acc = ((model.predict(inputs) > 1/2).float() == target).float().mean()\n",
    "                        best_const_loss = torch.nn.functional.binary_cross_entropy(torch.Tensor(bc_pred).to(device), target)\n",
    "        \n",
    "                    loss = model.learn(inputs, target) if iteration == 0 else None\n",
    "                    printer.addobs(iteration, loss, acc, best_const_loss)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or model_trace(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bccd9-3718-4a03-8575-f04e955d2755",
   "metadata": {},
   "source": [
    "# giga trace (finetuning on k=1, save at end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7ee305-d5b6-40a5-9e30-15c15fcc4031",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.748       0.748           0           0           0           0        1.24\n",
      "2                     0           0       0.913        1.08        0.25         0.5           0           0        1.77\n",
      "4                     0           0       0.781        0.65         0.5        0.75           0           0        2.81\n",
      "8                     0           0       0.908        1.08       0.286           0           1           1        4.59\n",
      "16                    0           0       0.793       0.693         0.4         0.5           1           0        9.05\n",
      "32                    0           0       0.765       0.736       0.431       0.464       0.667         0.5        17.2\n",
      "64                    0           0       0.721       0.675       0.509       0.589         0.5       0.375        33.6\n",
      "128                   0           0       0.704       0.687       0.553       0.596         0.5         0.5        67.3\n",
      "256                   0           0       0.706       0.708        0.54       0.527       0.552         0.6         135\n",
      "512                   0           0       0.691       0.676       0.565        0.59       0.491       0.431         273\n",
      "1024                  0           0       0.667       0.642       0.596       0.627       0.534       0.576         544\n",
      "2048                  0           0       0.647       0.626       0.622       0.649       0.553       0.573     1.1e+03\n",
      "4096                  0           0       0.625       0.604       0.649       0.675       0.604       0.654    2.19e+03\n",
      "8192                  0           0       0.609       0.593       0.662       0.674       0.642       0.679    4.36e+03\n",
      "10931                 0           0       0.604       0.589       0.667       0.685       0.645       0.657     5.8e+03\n",
      "12180             0.103           1       0.604           0       0.667           0        0.65       0.655    6.36e+03\n"
     ]
    }
   ],
   "source": [
    "# with finetuning and data doubling ...\n",
    "def giga_trace(k):\n",
    "    from MegaT5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    assert k == 1\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2, double_data=True)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    fewshot = PeftT5Classifier(train.num_labels, peft_config, t5=t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, open(f'gigatrace{k}.csv', 'w', newline='') as csvfile:\n",
    "        import csv\n",
    "        writer = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        trace = []\n",
    "                        target = []\n",
    "                        traininputs = []\n",
    "                        traintarget = []\n",
    "        \n",
    "                        for ex, label in zip(examples, labels):\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=8).indices.to('cpu')\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                inputs.append(input)\n",
    "                                trace.append((ex['title'], ex['ref1'], ex['ref2'], titles))\n",
    "                                target.append(int(label == train.choices[1]))\n",
    "                                if n == 0:\n",
    "                                    traininputs.append(input)\n",
    "                                    traintarget.append(int(label == train.choices[1]))\n",
    "\n",
    "                        target = torch.Tensor(target).long().to(device)\n",
    "                        traintarget = torch.Tensor(traintarget).long().to(device)\n",
    "                        fewshotacc = (fewshot.predict(inputs).argmax(dim=1) == target).int()\n",
    "                        trainfewshotacc = (fewshot.predict(traininputs).argmax(dim=1) == traintarget).float().mean()\n",
    "    \n",
    "                    fewloss = fewshot.learn(traininputs, traintarget) if istrain else None\n",
    "                    printer.addobs(iteration, fewloss, trainfewshotacc if istrain else None, trainfewshotacc if not istrain else None)\n",
    "\n",
    "                    if istrain:\n",
    "                        for (title, ref1, ref2, titles), acc in zip(trace, fewshotacc.tolist()):\n",
    "                            writer.writerow([acc, title, ref1, ref2] + titles)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            if iteration == 0:\n",
    "                fewshot.save_pretrained('gigafewshot')\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or giga_trace(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca688d7-19ac-4f9b-baf4-f5116445aff1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def wazzup():\n",
    "    from MegaT5 import PeftT5Classifier\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    from peft import PeftConfig\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    peft_config = PeftConfig.from_pretrained('gigafewshot')\n",
    "    fewshot = PeftT5Classifier(2, peft_config, t5=t5, model_id='gigafewshot')\n",
    "    print(fewshot.predict(['yo']))\n",
    "    fewshot = PeftT5Classifier(2, peft_config, t5=t5)\n",
    "    print(fewshot.predict(['yo']))\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or wazzup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c93acb-358a-4044-8b03-be2e3485ac69",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# check save/load works ... yes but not if the underlying T5 is reused ... figure this out ... \n",
    "# https://stackoverflow.com/questions/76197574/loading-multiple-lora-bins\n",
    "def check_save_load(k):\n",
    "    from MegaT5 import PeftT5Classifier as TaskLLM\n",
    "    from T5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import PeftConfig, IA3Config, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    assert k == 1\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    peft_config = PeftConfig.from_pretrained('gigafewshot')\n",
    "    taskllm = TaskLLM(train.num_labels, peft_config, t5=t5, model_id='gigafewshot')\n",
    "    rhat_peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    rhat_t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    rewardpredictor = PeftT5Classifier(1, rhat_peft_config, t5=rhat_t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer:\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        greedyrewards = []\n",
    "                        allloss = []\n",
    "                        with torch.no_grad():\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=8).indices.to('cpu')\n",
    "                            prompts = []\n",
    "                            rhatprompts = []\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                prompts.append(input)\n",
    "                                rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\nExtra: {titles[0]}\"\n",
    "                                rhatprompts.append(rhatprompt)\n",
    "                      \n",
    "                            guesses = taskllm.predict(prompts).argmax(dim=1)\n",
    "                            target = int(label == train.choices[1])\n",
    "                            rewards = (guesses == target).float().unsqueeze(1)\n",
    "                            rhats = rewardpredictor.predict(rhatprompts)\n",
    "                            #greedy = torch.argmax(rhats, dim=0).item()\n",
    "                            greedy = 0\n",
    "                            greedyreward = rewards[greedy, 0].item()\n",
    "                            greedyrewards.append(greedyreward)\n",
    "                            \n",
    "                        loss = rewardpredictor.learn(rhatprompts, rewards) if istrain else None\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                    greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                    predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "\n",
    "                    printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or check_save_load(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0218efc7-43cf-4b25-98e0-917153f435f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.697       0.697           0           0           0           0         1.3\n",
      "2                     0           0        0.69       0.683           0           0           0           0           2\n",
      "4                     0           0       0.706       0.722        0.25         0.5           0           0        3.38\n",
      "8                     0           0        0.69       0.668       0.571           1           1           1         5.8\n",
      "16                    0           0       0.697       0.703       0.467       0.375           1           0          12\n",
      "32                    0           0       0.672       0.645       0.586       0.714       0.667         0.5          23\n",
      "64                    0           0       0.652       0.632       0.667        0.75       0.571         0.5        45.8\n",
      "128                   0           0       0.636       0.619       0.675       0.684       0.643       0.714        91.9\n",
      "256                   0           0       0.638       0.641       0.687       0.699       0.621         0.6         182\n",
      "512                   0           0       0.648       0.657       0.696       0.705       0.621       0.621         366\n",
      "1024                  0           0       0.652       0.656       0.671       0.647        0.59       0.559         726\n",
      "2048                  0           0       0.649       0.645       0.691        0.71       0.628       0.667    1.46e+03\n",
      "4096                  0           0       0.643       0.637       0.706       0.721       0.658       0.688    2.92e+03\n",
      "8192                  0           0       0.638       0.634       0.721       0.737       0.699       0.739    5.83e+03\n",
      "10931                 0           0       0.637       0.634       0.723       0.726       0.701       0.706    7.78e+03\n",
      "12180             0.103           1       0.637           0       0.723           0       0.706       0.712    8.44e+03\n"
     ]
    }
   ],
   "source": [
    "# learn over top 8 results retrieved by ranker using frozen fine-tuned task llm\n",
    "def learn_ranker(k):\n",
    "    from MegaT5 import PeftT5Classifier as TaskLLM\n",
    "    from T5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import PeftConfig, IA3Config, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    assert k == 1\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2, double_data=True)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    peft_config = PeftConfig.from_pretrained('gigafewshot')\n",
    "    taskllm = TaskLLM(train.num_labels, peft_config, t5=t5, model_id='gigafewshot')\n",
    "    rhat_peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    rhat_t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    rewardpredictor = PeftT5Classifier(1, rhat_peft_config, t5=rhat_t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer:\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        greedyrewards = []\n",
    "                        allloss = []\n",
    "                        with torch.no_grad():\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=8).indices.to('cpu')\n",
    "                            prompts = []\n",
    "                            rhatprompts = []\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                prompts.append(input)\n",
    "                                rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\nExtra: {titles[0]}\"\n",
    "                                rhatprompts.append(rhatprompt)\n",
    "                      \n",
    "                            guesses = taskllm.predict(prompts).argmax(dim=1)\n",
    "                            target = int(label == train.choices[1])\n",
    "                            rewards = (guesses == target).float().unsqueeze(1)\n",
    "                            rhats = rewardpredictor.predict(rhatprompts)\n",
    "                            greedy = torch.argmax(rhats, dim=0).item()\n",
    "                            greedyreward = rewards[greedy, 0].item()\n",
    "                            greedyrewards.append(greedyreward)\n",
    "                            \n",
    "                        loss = rewardpredictor.learn(rhatprompts, rewards) if istrain else None\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                    greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                    predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "\n",
    "                    printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or learn_ranker(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9eadf7-42b3-4f6d-b428-aad77cbb38ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.666       0.666           0           0           0           0        1.69\n",
      "2                     0           0       0.667       0.668           0           0           0           0        2.78\n",
      "4                     0           0       0.692       0.717        0.25         0.5           0           0        4.99\n",
      "8                     0           0       0.686       0.679       0.571           1           1           1        8.89\n",
      "16                    0           0       0.693       0.699         0.6       0.625           1           0        18.9\n",
      "32                    0           0       0.673       0.651       0.621       0.643       0.667         0.5        36.8\n",
      "64                    0           0        0.65       0.626       0.684        0.75       0.714        0.75        73.7\n",
      "128                   0           0       0.642       0.634       0.658       0.632       0.786       0.857         148\n",
      "256                   0           0       0.647       0.652       0.665       0.673        0.69         0.6         294\n",
      "512                   0           0       0.657       0.666        0.67       0.674       0.638       0.586         588\n",
      "1024                  0           0       0.661       0.666       0.638       0.607       0.658       0.678    1.17e+03\n",
      "2048                  0           0       0.657       0.653       0.656       0.674       0.632       0.607    2.34e+03\n",
      "4096                  0           0       0.655       0.652       0.679       0.702       0.667       0.701    4.68e+03\n"
     ]
    }
   ],
   "source": [
    "# learn over top 16 results retrieved by ranker using frozen fine-tuned task llm\n",
    "def learn_ranker(k):\n",
    "    from MegaT5 import PeftT5Classifier as TaskLLM\n",
    "    from T5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import PeftConfig, IA3Config, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    assert k == 1\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2, double_data=True)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    peft_config = PeftConfig.from_pretrained('gigafewshot')\n",
    "    taskllm = TaskLLM(train.num_labels, peft_config, t5=t5, model_id='gigafewshot')\n",
    "    rhat_peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    rhat_t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    rewardpredictor = PeftT5Classifier(1, rhat_peft_config, t5=rhat_t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer:\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        greedyrewards = []\n",
    "                        allloss = []\n",
    "                        with torch.no_grad():\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=16).indices.to('cpu')\n",
    "                            prompts = []\n",
    "                            rhatprompts = []\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                prompts.append(input)\n",
    "                                rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\nExtra: {titles[0]}\"\n",
    "                                rhatprompts.append(rhatprompt)\n",
    "                      \n",
    "                            guesses = taskllm.predict(prompts).argmax(dim=1)\n",
    "                            target = int(label == train.choices[1])\n",
    "                            rewards = (guesses == target).float().unsqueeze(1)\n",
    "                            rhats = rewardpredictor.predict(rhatprompts)\n",
    "                            greedy = torch.argmax(rhats, dim=0).item()\n",
    "                            greedyreward = rewards[greedy, 0].item()\n",
    "                            greedyrewards.append(greedyreward)\n",
    "                            \n",
    "                        loss = rewardpredictor.learn(rhatprompts, rewards) if istrain else None\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                    greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                    predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "\n",
    "                    printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or learn_ranker(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a9558-ee53-45cb-9d81-0986a8885a17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# learn over top 24 results retrieved by ranker using frozen fine-tuned task llm\n",
    "def learn_ranker(k):\n",
    "    from MegaT5 import PeftT5Classifier as TaskLLM\n",
    "    from T5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import PeftConfig, IA3Config, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    assert k == 1\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2, double_data=True)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    peft_config = PeftConfig.from_pretrained('gigafewshot')\n",
    "    taskllm = TaskLLM(train.num_labels, peft_config, t5=t5, model_id='gigafewshot')\n",
    "    rhat_peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    rhat_t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    rewardpredictor = PeftT5Classifier(1, rhat_peft_config, t5=rhat_t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer:\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        greedyrewards = []\n",
    "                        allloss = []\n",
    "                        with torch.no_grad():\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=24).indices.to('cpu')\n",
    "                            prompts = []\n",
    "                            rhatprompts = []\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                prompts.append(input)\n",
    "                                rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\nExtra: {titles[0]}\"\n",
    "                                rhatprompts.append(rhatprompt)\n",
    "                      \n",
    "                            guesses = taskllm.predict(prompts).argmax(dim=1)\n",
    "                            target = int(label == train.choices[1])\n",
    "                            rewards = (guesses == target).float().unsqueeze(1)\n",
    "                            rhats = rewardpredictor.predict(rhatprompts)\n",
    "                            greedy = torch.argmax(rhats, dim=0).item()\n",
    "                            greedyreward = rewards[greedy, 0].item()\n",
    "                            greedyrewards.append(greedyreward)\n",
    "                            \n",
    "                        loss = rewardpredictor.learn(rhatprompts, rewards) if istrain else None\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                    greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                    predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "\n",
    "                    printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(1, 2):\n",
    "    with SubProcess() as process: process.parent or learn_ranker(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3104d-3ff3-4fb4-b305-aff5c598c691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
