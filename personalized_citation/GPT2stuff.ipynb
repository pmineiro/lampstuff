{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42eeac9f-b607-4450-b7ac-9ec8cca9b2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n          0 shot acc      since     dt (s)\n",
      "1                   1          1       1.29\n",
      "2                   1          1       2.03\n",
      "4                0.75        0.5       3.86\n",
      "8               0.625        0.5       7.43\n",
      "16              0.688       0.75       13.4\n",
      "32              0.578      0.469       27.2\n",
      "64              0.516      0.453       56.5\n",
      "128             0.469      0.422        136\n",
      "256             0.506      0.543        305\n",
      "512             0.514      0.521        592\n",
      "1024            0.505      0.496   1.19e+03\n",
      "2048              0.5      0.495   2.32e+03\n",
      "4096            0.495      0.489   4.64e+03\n",
      "4841            0.493      0.483   5.46e+03\n"
     ]
    }
   ],
   "source": [
    "def baselines():\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from FewShot import ZeroShotClassifier\n",
    "    from PersonalizedCitation import train_loader\n",
    "    import torch\n",
    "\n",
    "    device = 'cpu'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    zero = ZeroShotClassifier()\n",
    "\n",
    "    with ProgressPrinter('0 shot acc') as printer:\n",
    "        for inputs, profiles, answers in train:\n",
    "            with torch.no_grad():\n",
    "                multichoices = [ ( i, train.choices ) for i in inputs ] \n",
    "                zeroguesses = zero(multichoices)\n",
    "                zeroreward = torch.Tensor([ float(guess == answer) for guess, answer in zip(zeroguesses, answers) ]).mean().item()\n",
    "\n",
    "            printer.addobs(zeroreward)\n",
    "\n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or baselines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "735aa321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n          0 shot acc      since 3 shot acc      since     dt (s)\n",
      "1                   0          0          0          0        240\n",
      "1                   0          0          0          0        256"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m             printer\u001b[38;5;241m.\u001b[39maddobs(zeroreward, fewreward)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SubProcess\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SubProcess() \u001b[38;5;28;01mas\u001b[39;00m process: process\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;129;01mor\u001b[39;00m baselines()\n",
      "File \u001b[0;32m~/src/lampstuff/personalized_citation/Fork.py:16\u001b[0m, in \u001b[0;36mSubProcess.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfork()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'KeyboardInterrupt'>\n",
      "  File \"/tmp/ipykernel_20442/805610364.py\", line 35, in <module>\n",
      "    with SubProcess() as process: process.parent or baselines()\n",
      "  File \"/tmp/ipykernel_20442/805610364.py\", line 24, in baselines\n",
      "    profile_embeddings = train.embeddings(profile)\n",
      "  File \"/home/pmineiro/src/lampstuff/personalized_citation/PersonalizedCitation.py\", line 103, in embeddings\n",
      "    self._embeddings[article_id] = embedder(stuff)\n",
      "  File \"/home/pmineiro/src/lampstuff/personalized_citation/PersonalizedCitation.py\", line 5, in embedder\n",
      "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 95, in __init__\n",
      "    modules = self._load_sbert_model(model_path)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 840, in _load_sbert_model\n",
      "    module = module_class.load(os.path.join(model_path, module_config['path']))\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py\", line 137, in load\n",
      "    return Transformer(model_name_or_path=input_path, **config)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py\", line 29, in __init__\n",
      "    self._load_model(model_name_or_path, config, cache_dir)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py\", line 49, in _load_model\n",
      "    self.auto_model = AutoModel.from_pretrained(model_name_or_path, config=config, cache_dir=cache_dir)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 563, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 2954, in from_pretrained\n",
      "    model = cls(config, *model_args, **model_kwargs)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 892, in __init__\n",
      "    self.encoder = BertEncoder(config)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 560, in __init__\n",
      "    self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 560, in <listcomp>\n",
      "    self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 483, in __init__\n",
      "    self.output = BertOutput(config)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 459, in __init__\n",
      "    self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 101, in __init__\n",
      "    self.reset_parameters()\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 107, in reset_parameters\n",
      "    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/torch/nn/init.py\", line 396, in kaiming_uniform_\n",
      "    return torch.overrides.handle_torch_function(\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/torch/overrides.py\", line 1534, in handle_torch_function\n",
      "    result = mode.__torch_function__(public_api, types, args, kwargs)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/torch/utils/_device.py\", line 62, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/pmineiro/miniconda3/envs/megalampstuff/lib/python3.10/site-packages/torch/nn/init.py\", line 412, in kaiming_uniform_\n",
      "    return tensor.uniform_(-bound, bound)\n"
     ]
    }
   ],
   "source": [
    "def baselines():\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from FewShot import ZeroShotClassifier, FewShotClassifier\n",
    "    from PersonalizedCitation import embedder, train_loader\n",
    "    import torch\n",
    "\n",
    "    device = 'cpu'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    zero = ZeroShotClassifier()\n",
    "    few = FewShotClassifier()\n",
    "\n",
    "    with ProgressPrinter('0 shot acc', '3 shot acc') as printer:\n",
    "        for inputs, profiles, answers in train:\n",
    "            with torch.no_grad():\n",
    "                multichoices = [ ( i, train.choices ) for i in inputs ] \n",
    "                zeroguesses = zero(multichoices)\n",
    "                zeroreward = torch.Tensor([ float(guess == answer) for guess, answer in zip(zeroguesses, answers) ]).mean().item()\n",
    "\n",
    "                shots = []\n",
    "                for input, profile in zip(inputs, profiles):\n",
    "                    profile_embeddings = train.embeddings(profile)\n",
    "                    input_embeddings = embedder([input])\n",
    "                    indices = torch.topk(input_embeddings @ profile_embeddings.T, dim=1, k=3).indices.to('cpu')\n",
    "                    shots.append(train.stringify_articles(indices[0]))\n",
    "\n",
    "                fewguesses = few(multichoices, shots)\n",
    "                fewreward = torch.Tensor([ float(guess == answer) for guess, answer in zip(fewguesses, answers) ]).mean().item()\n",
    "                \n",
    "            printer.addobs(zeroreward, fewreward)\n",
    "\n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or baselines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777a9aa-ef5e-4d37-b288-3647e3ba1c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
