{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e58dc7f-b6f0-4277-935a-342899438ff3",
   "metadata": {},
   "source": [
    "# flan-t5-base "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2525a36-09e7-4c89-95fe-1c562f3201f1",
   "metadata": {},
   "source": [
    "peft ia3, top-k titles based upon `'\\n\\n'.join([ ex['ref1'], ex['ref2'] ])` ... not as good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dbad86-686e-4fb2-bd75-54fb6492fe87",
   "metadata": {},
   "source": [
    "peft ia3, top-k titles based upon max similarity with ref1 and ref2 ... best result yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8fc0d49-3d39-4c40-b82a-3dbc31d9ccf4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      0 loss       since       0 acc       since 0 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.674       0.674           1           1           0           0       0.769\n",
      "2                     0           0        1.44        2.21         0.5           0           0           0        1.03\n",
      "4                     0           0        1.23       0.799       0.333           0           0           0        1.35\n",
      "8                     0           0        0.92        0.69         0.5       0.625           0           0        2.18\n",
      "16                    0           0       0.881       0.835       0.423       0.333         0.5        0.75        3.65\n",
      "32                    0           0         0.8       0.718         0.5       0.577       0.583       0.667        6.82\n",
      "64                    0           0       0.747       0.691       0.539        0.58       0.731       0.857        12.9\n",
      "128                   0           0       0.734       0.722        0.51        0.48       0.577       0.423        25.3\n",
      "256                   0           0       0.725       0.715       0.502       0.495       0.567       0.558        49.8\n",
      "512                   0           0       0.716       0.707       0.498       0.493         0.5       0.434        99.5\n",
      "1024                  0           0       0.707       0.699       0.515       0.532       0.519       0.538         198\n",
      "2048                  0           0       0.702       0.697       0.518       0.521       0.502       0.486         398\n",
      "4096                  0           0       0.698       0.694        0.51       0.503       0.513       0.524         798\n",
      "6090                  0           0       0.696       0.693       0.507         0.5       0.515        0.52    1.18e+03\n",
      "7339               0.17           1       0.696           0       0.507           0       0.514       0.512    1.32e+03\n",
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.693       0.693         0.5         0.5           0           0       0.837\n",
      "2                     0           0        1.43        2.16        0.25           0           0           0        1.06\n",
      "4                     0           0        1.22       0.814       0.167           0           0           0        1.39\n",
      "8                     0           0       0.926       0.704       0.429       0.625           0           0        2.22\n",
      "16                    0           0       0.879       0.823       0.385       0.333         0.5        0.75        3.69\n",
      "32                    0           0       0.799        0.72       0.462       0.538         0.5         0.5        6.86\n",
      "64                    0           0       0.747       0.692        0.52        0.58       0.692       0.857        12.9\n",
      "128                   0           0       0.735       0.723        0.51         0.5       0.558       0.423        25.4\n",
      "256                   0           0       0.723       0.711       0.505         0.5       0.548       0.538          50\n",
      "512                   0           0        0.71       0.697       0.512        0.52        0.51       0.472        99.5\n",
      "1024                  0           0       0.688       0.666        0.56       0.607       0.524       0.538         198\n",
      "2048                  0           0       0.664       0.641       0.603       0.646       0.564       0.605         398\n",
      "4096                  0           0       0.638       0.611       0.631        0.66       0.598       0.632         797\n",
      "6090                  0           0       0.629        0.61       0.642       0.665       0.616       0.653    1.19e+03\n",
      "7339               0.17           1       0.629           0       0.642           0       0.633        0.65    1.32e+03\n",
      "n                  iter       since      2 loss       since       2 acc       since 2 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.692       0.692         0.5         0.5           0           0       0.784\n",
      "2                     0           0        1.44        2.19        0.25           0           0           0        1.01\n",
      "4                     0           0        1.24       0.849       0.167           0           0           0        1.33\n",
      "8                     0           0       0.936       0.706       0.429       0.625           0           0        2.18\n",
      "16                    0           0       0.882        0.82       0.385       0.333         0.5        0.75        3.64\n",
      "32                    0           0         0.8       0.717       0.462       0.538       0.583       0.667        6.84\n",
      "64                    0           0       0.745       0.688        0.52        0.58       0.731       0.857          13\n",
      "128                   0           0       0.733       0.721       0.515        0.51       0.558       0.385        25.6\n",
      "256                   0           0       0.712        0.69       0.515       0.515       0.548       0.538        50.5\n",
      "512                   0           0       0.685       0.658       0.553       0.591        0.59       0.632         101\n",
      "1024                  0           0        0.66       0.636       0.602       0.651       0.595         0.6         200\n",
      "2048                  0           0       0.639       0.617       0.638       0.674       0.617       0.638         402\n",
      "4096                  0           0        0.61       0.581       0.667       0.696        0.64       0.664         797\n",
      "6090                  0           0       0.599       0.578       0.677       0.698       0.649       0.665    1.18e+03\n",
      "7339               0.17           1       0.599           0       0.677           0       0.665       0.681    1.32e+03\n",
      "n                  iter       since      3 loss       since       3 acc       since 3 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.695       0.695         0.5         0.5           0           0       0.866\n",
      "2                     0           0        1.43        2.16        0.25           0           0           0        1.09\n",
      "4                     0           0        1.24       0.854       0.167           0           0           0        1.42\n",
      "8                     0           0       0.931       0.702       0.429       0.625           0           0        2.29\n",
      "16                    0           0       0.878       0.816       0.385       0.333         0.5        0.75        3.81\n",
      "32                    0           0       0.797       0.717       0.462       0.538       0.583       0.667        7.15\n",
      "64                    0           0       0.746       0.692        0.52        0.58       0.731       0.857        13.3\n",
      "128                   0           0       0.731       0.717       0.525       0.529       0.558       0.385          26\n",
      "256                   0           0       0.713       0.694       0.527       0.529       0.587       0.615        51.2\n",
      "512                   0           0        0.68       0.647       0.571       0.616       0.605       0.623         101\n",
      "1024                  0           0       0.647       0.614       0.615        0.66       0.619       0.633         200\n",
      "2048                  0           0       0.624       0.601       0.655       0.695       0.645       0.671         399\n",
      "4096                  0           0       0.594       0.565       0.684       0.713       0.666       0.687         792\n",
      "6090                  0           0       0.585       0.567       0.691       0.706       0.676       0.697    1.17e+03\n",
      "7339               0.17           1       0.585           0       0.691           0        0.69       0.704     1.3e+03\n",
      "n                  iter       since      4 loss       since       4 acc       since 4 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.705       0.705           0           0           0           0       0.788\n",
      "2                     0           0        1.45         2.2           0           0           0           0        1.01\n",
      "4                     0           0        1.26       0.878           0           0           0           0        1.34\n",
      "8                     0           0       0.944       0.706       0.357       0.625           0           0        2.19\n",
      "16                    0           0       0.887        0.82       0.346       0.333         0.5        0.75        3.65\n",
      "32                    0           0       0.804       0.722       0.423         0.5       0.583       0.667        6.85\n",
      "64                    0           0       0.747       0.688         0.5        0.58       0.731       0.857        12.9\n",
      "128                   0           0       0.734        0.72         0.5         0.5       0.558       0.385        25.5\n",
      "256                   0           0       0.715       0.696        0.52       0.539       0.567       0.577        50.1\n",
      "512                   0           0       0.681       0.647       0.565       0.611       0.629       0.689        99.5\n",
      "1024                  0           0       0.646       0.611       0.621       0.677       0.629       0.629         198\n",
      "2048                  0           0       0.618       0.591       0.663       0.705       0.651       0.674         395\n",
      "4096                  0           0       0.586       0.555       0.692       0.721       0.667       0.683         789\n",
      "6090                  0           0        0.58       0.566       0.696       0.704       0.678         0.7    1.17e+03\n",
      "7339               0.17           1        0.58           0       0.696           0       0.693       0.709    1.31e+03\n"
     ]
    }
   ],
   "source": [
    "def peft_t5_baselines(k):\n",
    "    from MegaT5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    fewshot = PeftT5Classifier(train.num_labels, peft_config, t5=t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer:\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        target = torch.Tensor([ int(label == train.choices[1]) for label in labels ]).long().to(device)\n",
    "        \n",
    "                        for ex in examples:\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
    "                            titles = [ f'\"{ex[\"profile\"][ind][\"title\"]}\"' for ind in index.tolist() ]\n",
    "                            concat_titles = ' and '.join(titles)\n",
    "                            input = train.append_to_title(ex, concat_titles)\n",
    "                            inputs.append(input)\n",
    "        \n",
    "                        fewshotacc = (fewshot.predict(inputs).argmax(dim=1) == target).float().mean().item()\n",
    "    \n",
    "                    fewloss = fewshot.learn(inputs, target) if istrain else None\n",
    "                    printer.addobs(iteration, fewloss, fewshotacc if istrain else None, fewshotacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    " \n",
    "from Fork import SubProcess\n",
    "for k in range(0, 5):\n",
    "    with SubProcess() as process: process.parent or peft_t5_baselines(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d6d5b-2844-493a-896e-b30a6004a489",
   "metadata": {},
   "source": [
    "# flan-t5-xl (8bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c9056-4313-47d1-967a-cfdbe2a71a8f",
   "metadata": {},
   "source": [
    "peft ia3, top-k titles based upon max similarity with ref1 and ref2\n",
    "\n",
    "better than flan-t5-base.  maybe flan-t5-xxl is even better. unfortunately flan-t5-xxl doesn't fit on a T4 in 8bit, and 4bit doesn't seem to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041707bc-a504-4383-ae7c-c5fac9bf5db0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      0 loss       since       0 acc       since 0 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.775       0.775           0           0           0           0        2.12\n",
      "2                     0           0        2.23        3.68           0           0           0           0        3.58\n",
      "4                     0           0        1.88        1.19           0           0           0           0        5.48\n",
      "8                     0           0        1.24       0.766       0.214       0.375           0           0          11\n"
     ]
    }
   ],
   "source": [
    "def peft_t5_baselines(k):\n",
    "    from MegaT5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    import warnings\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xl', load_in_8bit=True))\n",
    "    fewshot = PeftT5Classifier(train.num_labels, peft_config, t5=t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        target = torch.Tensor([ int(label == train.choices[1]) for label in labels ]).long().to(device)\n",
    "        \n",
    "                        for ex in examples:\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
    "                            titles = [ f'\"{ex[\"profile\"][ind][\"title\"]}\"' for ind in index.tolist() ]\n",
    "                            concat_titles = ' and '.join(titles)\n",
    "                            input = train.append_to_title(ex, concat_titles)\n",
    "                            inputs.append(input)\n",
    "        \n",
    "                        fewshotacc = (fewshot.predict(inputs).argmax(dim=1) == target).float().mean().item()\n",
    "    \n",
    "                    fewloss = fewshot.learn(inputs, target) if istrain else None\n",
    "                    printer.addobs(iteration, fewloss, fewshotacc if istrain else None, fewshotacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "from Fork import SubProcess\n",
    "for k in range(0, 5):\n",
    "    with SubProcess() as process: process.parent or peft_t5_baselines(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d76bd3-182c-4135-9d75-5db1660142a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      4 loss       since       4 acc       since 4 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.657       0.657         0.5         0.5           0           0        2.14\n",
      "2                     0           0        2.39        4.13        0.25           0           0           0        3.68\n",
      "4                     0           0         1.9       0.906       0.167           0           0           0        5.82\n",
      "8                     0           0        1.23       0.735       0.357         0.5           0           0        11.9\n",
      "16                    0           0        1.09        0.92       0.346       0.333         0.5        0.75        22.1\n",
      "32                    0           0       0.907       0.726       0.423         0.5       0.583       0.667        44.1\n",
      "64                    0           0       0.808       0.704       0.539        0.66       0.731       0.857        86.9\n",
      "128                   0           0       0.759        0.71       0.578       0.618       0.654       0.577         174\n",
      "256                   0           0       0.701       0.643       0.615       0.652       0.663       0.673         350\n",
      "512                   0           0       0.643       0.585       0.667       0.719       0.676       0.689         700\n",
      "1024                  0           0       0.609       0.575       0.682       0.698       0.667       0.657     1.4e+03\n",
      "2048                  0           0       0.575        0.54       0.708       0.734       0.683         0.7    2.79e+03\n",
      "4096                  0           0       0.547       0.519       0.726       0.744       0.704       0.725    5.57e+03\n",
      "6090                  0           0       0.538        0.52       0.731        0.74       0.717       0.743    8.27e+03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SubProcess\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m4\u001b[39m]:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m SubProcess() \u001b[38;5;28;01mas\u001b[39;00m process: process\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;129;01mor\u001b[39;00m peft_t5_baselines(k)\n",
      "File \u001b[0;32m~/lampstuff/personalized_citation/Fork.py:16\u001b[0m, in \u001b[0;36mSubProcess.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfork()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10027             0.393           1       0.517       0.486       0.742        0.76       0.721       0.728    1.36e+04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'KeyboardInterrupt'>\n",
      "\n",
      "  File \"/tmp/ipykernel_3916943/3896096721.py\", line 77, in <module>\n",
      "    with SubProcess() as process: process.parent or peft_t5_baselines(k)\n",
      "  File \"/tmp/ipykernel_3916943/3896096721.py\", line 68, in peft_t5_baselines\n",
      "    fewloss = fewshot.learn(inputs, target) if istrain else None\n",
      "  File \"/home/pmineiro/lampstuff/personalized_citation/MegaT5.py\", line 48, in learn\n",
      "    loss.backward()\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/torch/_tensor.py\", line 478, in backward\n",
      "    return handle_torch_function(\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/torch/overrides.py\", line 1534, in handle_torch_function\n",
      "    result = mode.__torch_function__(public_api, types, args, kwargs)\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/torch/utils/_device.py\", line 62, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "def peft_t5_baselines(k):\n",
    "    from MegaT5 import PeftT5Classifier\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    import warnings\n",
    "\n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    def interleave(a, b):\n",
    "        from math import inf\n",
    "        \n",
    "        atot, btot = a.num_examples, b.num_examples\n",
    "        aiter, biter = a.__iter__(), b.__iter__()\n",
    "        aelem, belem = next(aiter), next(biter)\n",
    "        anum, bnum = 1, 1\n",
    "\n",
    "        while anum != inf and bnum != inf:\n",
    "            if anum * btot <= bnum * atot:\n",
    "                yield (True, aelem)\n",
    "                try:\n",
    "                    aelem = next(aiter)\n",
    "                    anum += 1\n",
    "                except StopIteration:\n",
    "                    anum = inf\n",
    "            else:\n",
    "                yield (False, belem)\n",
    "                try:\n",
    "                    belem = next(biter)\n",
    "                    bnum += 1\n",
    "                except StopIteration:\n",
    "                    bnum = inf\n",
    "\n",
    "    peft_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xl', load_in_8bit=True))\n",
    "    fewshot = PeftT5Classifier(train.num_labels, peft_config, t5=t5)\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        \n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                with torch.no_grad():\n",
    "                    inputs = []\n",
    "                    target = torch.Tensor([ int(label == train.choices[1]) for label in labels ]).long().to(device)\n",
    "    \n",
    "                    for ex in examples:\n",
    "                        embeddings = train.embed([ '\\n\\n'.join([ ex['ref1'], ex['ref2'] ]) ] + \n",
    "                                                 [ v['title'] \n",
    "                                                   for v in ex['profile']\n",
    "                                                   if v['title'] != ex['title'] \n",
    "                                                 ])\n",
    "                        index = torch.topk(embeddings[0,:] @ embeddings[1:,:].T, dim=0, k=k).indices.to('cpu')\n",
    "                        titles = [ f'\"{ex[\"profile\"][ind][\"title\"]}\"' for ind in index.tolist() ]\n",
    "                        concat_titles = ' and '.join(titles)\n",
    "                        input = train.append_to_title(ex, concat_titles)\n",
    "                        inputs.append(input)\n",
    "    \n",
    "                    fewshotacc = (fewshot.predict(inputs).argmax(dim=1) == target).float().mean().item()\n",
    "\n",
    "                fewloss = fewshot.learn(inputs, target) if istrain else None\n",
    "                printer.addobs(iteration, fewloss, fewshotacc if istrain else None, fewshotacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    " \n",
    "from Fork import SubProcess\n",
    "for k in [4]:\n",
    "    with SubProcess() as process: process.parent or peft_t5_baselines(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e38ce-2900-473c-a10d-909c67d89f33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
