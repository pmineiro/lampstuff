{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Step 1: fine-tune LLM using top result from (fixed) ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      1 loss       since       1 acc       since 1 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.702       0.702           0           0           0           0        1.02\n",
      "2                     0           0       0.701         0.7           0           0           0           0        1.51\n",
      "4                     0           0        0.71       0.719       0.125        0.25           0           0        2.52\n",
      "8                     0           0       0.705       0.698       0.286         0.5           0           0        4.17\n",
      "16                    0           0       0.696       0.686         0.5        0.75       0.333         0.5        7.36\n",
      "32                    0           0       0.693       0.691       0.481       0.462         0.5       0.667        14.5\n",
      "64                    0           0       0.692       0.691       0.471       0.462       0.583       0.667        30.3\n",
      "128                   0           0       0.682       0.672       0.538       0.606       0.604       0.625        60.3\n",
      "256                   0           0       0.671       0.661       0.557       0.576       0.585       0.565         119\n",
      "512                   0           0       0.682       0.693       0.565       0.572       0.611       0.635         238\n",
      "1024                  0           0       0.682       0.681        0.57       0.576       0.592       0.573         473\n",
      "2048                  0           0       0.661       0.641       0.604       0.637       0.613       0.634         951\n",
      "4020                  0           0       0.644       0.627       0.628       0.654       0.628       0.643    1.86e+03\n",
      "4769              0.157           1       0.644           0       0.628           0        0.64       0.653    2.09e+03\n"
     ]
    }
   ],
   "source": [
    "def step_one(k):\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType\n",
    "    import sys\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave, Filter\n",
    "\n",
    "    sys.stderr = Filter(sys.stderr, r'Bad pipe message') \n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2, timesplit=True)\n",
    "    dev = dev_loader(batch_size=2, timesplit=True)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    taskllm_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(taskllm_config, \"taskllm\")\n",
    "    t5.enable_adapters()\n",
    "\n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer:\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        inputs = []\n",
    "                        target = []\n",
    "        \n",
    "                        for ex, label in zip(examples, labels):\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                inputs.append(input)\n",
    "                                target.append(int(label == train.choices[1]))\n",
    "\n",
    "                        target = torch.Tensor(target).long().to(device)\n",
    "                        acc = (taskllm.predict(inputs, augment=train.swap_refs).argmax(dim=1) == target).float().mean().item()\n",
    "    \n",
    "                    loss = taskllm.learn(inputs, target, augment=train.swap_refs) if istrain else None\n",
    "                    printer.addobs(iteration, loss, acc if istrain else None, acc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            if iteration == 0:\n",
    "                taskllm.save_pretrained(f'Time_keq{k}_t5base_step1')\n",
    "\n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or step_one(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Step 2: learn ranker using (fixed pre-finetuned) task LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3c4dfb-cb62-4d2b-a0e7-d1c281da1c4d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      8 loss       since       8 acc       since 8 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.686       0.686           1           1           0           0        1.69\n",
      "2                     0           0       0.669       0.653         0.5           0           0           0        2.76\n",
      "4                     0           0       0.679       0.689         0.5         0.5           0           0        4.98\n",
      "8                     0           0       0.693       0.706         0.5         0.5           0           0        9.12\n",
      "16                    0           0       0.688       0.684         0.6       0.714           1           1        17.5\n",
      "32                    0           0       0.644       0.596       0.586       0.571       0.667         0.5        34.8\n",
      "64                    0           0       0.666       0.688       0.603       0.621       0.667       0.667        69.2\n",
      "128                   0           0       0.678        0.69       0.522       0.439       0.615       0.571         141\n",
      "256                   0           0       0.661       0.645       0.591       0.661       0.692       0.769         290\n",
      "512                   0           0       0.641       0.621       0.657       0.722       0.712       0.731         585\n",
      "1024                  0           0       0.632       0.623       0.679       0.702       0.657       0.604    1.18e+03\n",
      "2048                  0           0       0.633       0.635       0.678       0.678       0.638       0.619    2.37e+03\n",
      "4096                  0           0       0.634       0.634       0.682       0.685       0.644       0.649    4.75e+03\n",
      "5191                  0           0       0.632       0.626       0.679        0.67       0.648       0.664    6.02e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'KeyboardInterrupt'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m                 rewardpredictor\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_keq1_t5base_step2_rankeq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_iter\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SubProcess\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SubProcess() \u001b[38;5;28;01mas\u001b[39;00m process: process\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;129;01mor\u001b[39;00m learn_ranker(rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, max_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "File \u001b[0;32m~/lampstuff/personalized_citation/Fork.py:16\u001b[0m, in \u001b[0;36mSubProcess.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfork()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  File \"/tmp/ipykernel_1753555/693645465.py\", line 85, in <module>\n",
      "    with SubProcess() as process: process.parent or learn_ranker(rank=8, max_iteration=8)\n",
      "  File \"/tmp/ipykernel_1753555/693645465.py\", line 63, in learn_ranker\n",
      "    guesses = taskllm.predict(prompts, augment=train.swap_refs).argmax(dim=1)\n",
      "  File \"/home/pmineiro/lampstuff/personalized_citation/TaskLLM.py\", line 39, in predict\n",
      "    return self.forward(x, augment=augment)\n",
      "  File \"/home/pmineiro/lampstuff/personalized_citation/TaskLLM.py\", line 29, in forward\n",
      "    augment_logprobs = self.forward(augment(data))[:,[1,0]]\n",
      "  File \"/home/pmineiro/lampstuff/personalized_citation/TaskLLM.py\", line 22, in forward\n",
      "    enc = self._tokenizer(data, return_tensors='pt', padding=True).to(self._transformer.device)\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 2602, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 2688, in _call_one\n",
      "    return self.batch_encode_plus(\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 2879, in batch_encode_plus\n",
      "    return self._batch_encode_plus(\n",
      "  File \"/home/pmineiro/miniconda3/envs/lampstuff/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py\", line 452, in _batch_encode_plus\n",
      "    encodings = self._tokenizer.encode_batch(\n"
     ]
    }
   ],
   "source": [
    "def learn_ranker(*, max_iteration, rank):\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType\n",
    "    import sys\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave, Filter\n",
    "\n",
    "    sys.stderr = Filter(sys.stderr, r'Bad pipe message') \n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2, double_data=True, timesplit=True)\n",
    "    dev = dev_loader(batch_size=2, timesplit=True)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    t5.load_adapter('Time_keq1_t5base_step1', 'taskllm')\n",
    "\n",
    "    rhat_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(rhat_config, \"rhat\")\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\")\n",
    "    \n",
    "    def reward_augment(inputs):\n",
    "        import re\n",
    "        return [ re.sub(r'Ref1: (.*)\\nRef2: (.*)\\nExtra:',\n",
    "                        r'Ref1: \\2\\nRef2: \\1\\nExtra:',\n",
    "                        z)\n",
    "                 for z in inputs ]\n",
    "\n",
    "    with ProgressPrinter('iter', f'{rank} loss', f'{rank} acc', f'{rank} acc (dev)') as printer:\n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration + 1 < max_iteration or not istrain:\n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        greedyrewards = []\n",
    "                        allloss = []\n",
    "                        with torch.no_grad():\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=rank).indices.to('cpu')\n",
    "                            prompts = []\n",
    "                            rhatprompts = []\n",
    "                            for n, oneind in enumerate(index.tolist()):\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                input = train.append_to_title(ex, concat_titles)\n",
    "                                prompts.append(input)\n",
    "                                rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\nExtra: {titles[0]}\"\n",
    "                                rhatprompts.append(rhatprompt)\n",
    "                            \n",
    "                            guesses = taskllm.predict(prompts, augment=train.swap_refs).argmax(dim=1)\n",
    "                            target = int(label == train.choices[1])\n",
    "                            rewards = (guesses == target).float().unsqueeze(1)\n",
    "                            rhats = rewardpredictor.predict(rhatprompts, augment=reward_augment)\n",
    "                            greedy = torch.argmax(rhats, dim=0).item()\n",
    "                            greedyreward = rewards[greedy, 0].item()\n",
    "                            greedyrewards.append(greedyreward)\n",
    "                            \n",
    "                        loss = rewardpredictor.learn(rhatprompts, rewards, augment=reward_augment) if istrain else None\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                    greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                    predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "\n",
    "                    printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            if iteration + 1 < max_iteration:\n",
    "                rewardpredictor.save_pretrained(f'Time_keq1_t5base_step2_rankeq{rank}_iter{iteration}')\n",
    "\n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or learn_ranker(rank=8, max_iteration=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ceafbc-7af5-4035-8b41-712b221c6d39",
   "metadata": {},
   "source": [
    "# Step 3: Prepare leaderboard submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00691200-4034-407f-ae0b-a3a8b39d5799",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prepare_submission(*, rank):\n",
    "    import json\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader, test_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import PeftConfig, IA3Config, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    dev = dev_loader(batch_size=2, timesplit=True)\n",
    "    test = test_loader(batch_size=2, timesplit=True)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    t5.load_adapter('Time_keq1_t5base_step1', 'taskllm')\n",
    "    t5.load_adapter(f'Time_keq1_t5base_step2_rankeq{rank}', 'rhat')\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\", model_id=f'Time_keq1_t5base_step2_rankeq{rank}')\n",
    "    \n",
    "    def reward_augment(inputs):\n",
    "        import re\n",
    "        return [ re.sub(r'Ref1: (.*)\\nRef2: (.*)\\nExtra:',\n",
    "                        r'Ref1: \\2\\nRef2: \\1\\nExtra:',\n",
    "                        z)\n",
    "                 for z in inputs ]\n",
    "\n",
    "    with ProgressPrinter(f'{rank} acc (dev)') as printer:\n",
    "        devgolds = []\n",
    "        testgolds = []\n",
    "        for isdev, (examples, labels) in interleave(dev, test):\n",
    "            for ex, label in zip(examples, labels):\n",
    "                greedyrewards = []\n",
    "                with torch.no_grad():\n",
    "                    embeddings = dev.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                              [ v['title'] \n",
    "                                               for v in ex['profile']\n",
    "                                               if v['title'] != ex['title'] \n",
    "                                             ])\n",
    "                    scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                    index = torch.topk(scores, dim=0, k=rank).indices.to('cpu')\n",
    "                    prompts = []\n",
    "                    rhatprompts = []\n",
    "                    for n, oneind in enumerate(index.tolist()):\n",
    "                        titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in (oneind,) ]\n",
    "                        concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                        input = dev.append_to_title(ex, concat_titles)\n",
    "                        prompts.append(input)\n",
    "                        rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\nExtra: {titles[0]}\"\n",
    "                        rhatprompts.append(rhatprompt)\n",
    "\n",
    "                    rhats = rewardpredictor.predict(rhatprompts, augment=reward_augment)\n",
    "                    greedy = torch.argmax(rhats, dim=0).item()\n",
    "                    guess = taskllm.predict([ prompts[greedy] ], augment=dev.swap_refs).argmax(dim=1)\n",
    "                    if isdev:\n",
    "                        target = int(label == dev.choices[1])\n",
    "                        reward = float(guess == target)\n",
    "                        greedyrewards.append(reward)\n",
    "\n",
    "                    (devgolds if isdev else testgolds).append({ 'id': ex['id'], 'output': \"[2]\" if guess else \"[1]\" })\n",
    "\n",
    "            greedyacc = torch.Tensor(greedyrewards).float().mean().item() if isdev else None\n",
    "\n",
    "            printer.addobs(greedyacc)\n",
    "\n",
    "        printer.print()\n",
    "        printer.autoprint = False\n",
    "\n",
    "        for wut, golds in ( ('dev', devgolds), ('test', testgolds) ):\n",
    "            with open(f'lamp1t_{wut}golds_rankeq{rank}.json', 'w') as jsonfile:\n",
    "                json.dump({ 'task': 'LaMP_1', 'golds': golds }, jsonfile)\n",
    "            \n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or prepare_submission(rank=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce32545b-9a67-43dd-86a8-6f7a1dad6215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
