{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Case 1: Fixed Ranker, no-fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n       5 acc (dev) (since)      dt\n",
      "1             1.000 (1.000)  3.41 s\n",
      "2             0.500 (0.000)  5.03 s\n",
      "4             0.250 (0.000)  8.82 s\n",
      "8             0.500 (0.750)  16.2 s\n",
      "16            0.375 (0.250)  30.3 s\n",
      "32            0.469 (0.562)  58.1 s\n",
      "64            0.578 (0.688)  1.93 m\n",
      "128           0.523 (0.469)  3.83 m\n",
      "256           0.520 (0.516)  7.61 m\n",
      "512           0.520 (0.520)  15.2 m\n",
      "1024          0.519 (0.518)  30.5 m\n",
      "2048          0.527 (0.536)  1.06 h\n",
      "2500          0.534 (0.564)  1.28 h\n"
     ]
    }
   ],
   "source": [
    "def fixed_ranker_noft(*, k):\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    import warnings\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    dev = dev_loader(batch_size=1)\n",
    "\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl', load_in_8bit=True))\n",
    "    taskllm = TaskLLM(t5=t5)\n",
    "\n",
    "    with ProgressPrinter(f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*If you want to save 8-bit models.*\")\n",
    "        \n",
    "        for examples, labels in dev:\n",
    "            with torch.no_grad():\n",
    "                prompts = []\n",
    "                target = []\n",
    "\n",
    "                for ex, label in zip(examples, labels):\n",
    "                    embeddings = dev.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                            [ v['title'] \n",
    "                                              for v in ex['profile']\n",
    "                                              if v['title'] != ex['title'] \n",
    "                                            ])\n",
    "                    scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                    index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
    "                    titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in index.tolist() ]\n",
    "                    concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                    prompt = dev.append_to_title(ex, concat_titles)\n",
    "                    prompts.append(prompt)\n",
    "                    target.append(int(label == dev.choices[1]))\n",
    "\n",
    "                target = torch.Tensor(target).long().to(device)\n",
    "                acc = (taskllm.predict(prompts, augment=dev.swap_refs).argmax(dim=1) == target).float().mean().item()\n",
    "\n",
    "            printer.addobs(acc)\n",
    "\n",
    "fixed_ranker_noft(k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Case 2: Learned Ranker, no fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c4dfb-cb62-4d2b-a0e7-d1c281da1c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter (since)      5 loss (since)       5 acc (since) 5 acc (dev) (since)       samps (since)      dt\n",
      "1             0.000 (0.000)       0.693 (0.693)       1.000 (1.000)       0.000 (0.000)      22.000 (22.000)  1.07 m\n",
      "2             0.000 (0.000)       0.694 (0.696)       1.000 (1.000)       0.000 (0.000)      36.000 (50.000)  3.34 m\n",
      "4             0.000 (0.000)       0.712 (0.729)       0.750 (0.500)       0.000 (0.000)      24.375 (12.750)  5.06 m\n",
      "8             0.000 (0.000)       0.681 (0.650)       0.625 (0.500)       0.000 (0.000)      21.500 (18.625)  9.58 m\n",
      "16            0.000 (0.000)       0.684 (0.686)       0.656 (0.688)       0.000 (0.000)      18.719 (15.938)  18.1 m\n",
      "32            0.000 (0.000)       0.689 (0.693)       0.625 (0.594)       0.000 (0.000)      25.047 (31.375)  43.7 m\n",
      "64            0.000 (0.000)       0.689 (0.690)       0.547 (0.469)       0.000 (0.000)      26.492 (27.938)   1.5 h\n",
      "128           0.000 (0.000)       0.688 (0.687)       0.543 (0.539)       0.000 (0.000)      27.027 (27.562)  3.06 h\n",
      "256           0.000 (0.000)       0.689 (0.690)       0.535 (0.527)       0.000 (0.000)      24.439 (21.852)  5.26 h\n",
      "512           0.000 (0.000)       0.689 (0.689)       0.525 (0.516)       0.000 (0.000)      24.983 (25.527)  8.01 h\n",
      "1024          0.000 (0.000)       0.689 (0.689)       0.539 (0.553)       0.000 (0.000)      21.468 (17.952)  12.4 h\n",
      "2048          0.000 (0.000)       0.687 (0.686)       0.549 (0.559)       0.000 (0.000)      18.560 (15.653)  20.3 h\n",
      "4096          0.000 (0.000)       0.684 (0.681)       0.557 (0.565)       0.000 (0.000)      15.847 (13.133)  1.45 d\n",
      "6091          0.000 (0.000)       0.682 (0.674)       0.558 (0.562)       0.584 (0.584)      15.177 (11.493)  1.81 d\n",
      "12182         0.500 (1.000)       0.679 (0.676)       0.564 (0.569)       0.580 (0.576)      13.401 (11.626)  3.29 d\n"
     ]
    }
   ],
   "source": [
    "def learn_ranker(*, max_iteration, k):\n",
    "    from more_itertools import chunked\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from SimpleRegret import SimpleRegretHypercubeSampler\n",
    "    from peft import PeftConfig, IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    import warnings\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl', load_in_8bit=True))\n",
    "\n",
    "    rhat_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(rhat_config, \"rhat\")\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5)\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\")\n",
    "    \n",
    "    def reward_augment(prompts):\n",
    "        import re\n",
    "        return [ re.sub(r'Ref1: (.*)\\nRef2: (.*)\\nExtra:',\n",
    "                        r'Ref1: \\2\\nRef2: \\1\\nExtra:',\n",
    "                        z)\n",
    "                 for z in prompts ]\n",
    "\n",
    "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
    "    def randomized_similarity(ex, nsamples):\n",
    "        embeddings = dev.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                 [ v['title'] \n",
    "                                  for v in ex['profile']\n",
    "                                  if v['title'] != ex['title'] \n",
    "                                ])\n",
    "        scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "        temperature = scores[0].item() - scores[4].item()\n",
    "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
    "        gumbels = temperature * gumbel.sample(gumbel_shape)\n",
    "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=k).indices, sorted=False, dim=0).to('cpu')\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)', 'samps') as printer, warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*If you want to save 8-bit models.*\")\n",
    "        \n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev, sequential=True):\n",
    "                greedyrewards, allloss, nsamps = [], [], []\n",
    "                for ex, label in zip(examples, labels):\n",
    "                    with torch.no_grad():\n",
    "                        randos = randomized_similarity(ex, 64)\n",
    "                        \n",
    "                        rhatprompts = []\n",
    "                        prompts = []\n",
    "                        for rando in randos:\n",
    "                            titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in rando ]\n",
    "                            concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                            prompt = dev.append_to_title(ex, concat_titles)\n",
    "                            prompts.append(prompt)\n",
    "                            rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\n\" + '\\n'.join(\n",
    "                                       [ f\"Extra: {t}\" for t in titles ])\n",
    "                            rhatprompts.append(rhatprompt)\n",
    "\n",
    "                        rhats = rewardpredictor.predict(rhatprompts, augment=reward_augment)\n",
    "                        exploit, explore = SimpleRegretHypercubeSampler(rhats.view(1, -1), gamma=1)\n",
    "                        exploit = [ exploit.item() ]\n",
    "                        explore = explore[0].tolist() if istrain else []\n",
    "                        actionind = exploit + [ n for n, observed in enumerate(explore) if observed > 0 ]\n",
    "                        nsamps.append(len(actionind)) \n",
    "                        guesses = taskllm.predict([ prompts[a] for a in actionind ], augment=dev.swap_refs).argmax(dim=1)\n",
    "                        target = int(label == dev.choices[1])\n",
    "                        rewards = (guesses == target).float().tolist()\n",
    "                        greedyreward = rewards[0]\n",
    "                        greedyrewards.append(greedyreward)\n",
    "\n",
    "                    if istrain:\n",
    "                        inner_batch_size = 4\n",
    "                        loss = sum(\n",
    "                            len(inner_batch[0]) * \n",
    "                            rewardpredictor.learn([ rhatprompts[a] for a in inner_batch[0] ], \n",
    "                                                    torch.Tensor([ [ r ] for r in inner_batch[1] ]).to(device),\n",
    "                                                    augment=reward_augment)\n",
    "                            for inner_batch in zip(chunked(actionind, inner_batch_size), chunked(rewards, inner_batch_size))\n",
    "                        ) / len(actionind)\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "                nsamples = torch.Tensor(nsamps).mean().item() if istrain else None\n",
    "\n",
    "                printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None, nsamples)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "\n",
    "learn_ranker(k=5, max_iteration=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28408ef1-b7b6-4ccd-b137-df6a70a9fe57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
