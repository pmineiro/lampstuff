{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Step 1: fine-tune LLM using top result from (fixed) ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3a4d92-ccf2-4278-a697-beea8e911dfd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      4 loss       since       4 acc       since 4 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.711       0.711           0           0           0           0         1.2\n",
      "2                     0           0       0.695       0.678         0.5           1           0           0        1.69\n",
      "4                     0           0       0.689       0.677       0.667           1           1           1        2.46\n",
      "8                     0           0        0.69       0.691       0.643       0.625           1           0        4.38\n",
      "16                    0           0       0.675       0.658       0.654       0.667       0.667         0.5        7.73\n",
      "32                    0           0       0.681       0.686       0.654       0.654       0.833           1        15.5\n",
      "64                    0           0        0.67       0.659       0.686        0.72       0.808       0.786        29.7\n",
      "128                   0           0       0.662       0.653       0.662       0.637       0.654         0.5        59.7\n",
      "256                   0           0       0.625       0.588       0.684       0.706       0.663       0.673         119\n",
      "512                   0           0       0.611       0.597       0.699       0.714       0.714       0.764         241\n",
      "1024                  0           0       0.599       0.588         0.7         0.7        0.69       0.667         485\n",
      "2048                  0           0       0.585       0.571       0.711       0.723         0.7        0.71         982\n",
      "4096                  0           0       0.563       0.541       0.725       0.739       0.692       0.683    1.97e+03\n",
      "6090                  0           0        0.56       0.553       0.723       0.718       0.696       0.705    2.92e+03\n",
      "7339               0.17           1        0.56           0       0.723           0       0.704       0.712    3.34e+03\n"
     ]
    }
   ],
   "source": [
    "def step_one(*, k):\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import IA3Config, TaskType, prepare_model_for_kbit_training\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    taskllm_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(taskllm_config, \"taskllm\")\n",
    "    t5.enable_adapters()\n",
    "\n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer:\n",
    "        for iteration in range(2):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration == 0 or not istrain:\n",
    "                    with torch.no_grad():\n",
    "                        prompts = []\n",
    "                        target = []\n",
    "        \n",
    "                        for ex, label in zip(examples, labels):\n",
    "                            embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                                      [ v['title'] \n",
    "                                                       for v in ex['profile']\n",
    "                                                       if v['title'] != ex['title'] \n",
    "                                                     ])\n",
    "                            scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "                            index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
    "                            titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in index.tolist() ]\n",
    "                            concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                            prompt = train.append_to_title(ex, concat_titles)\n",
    "                            prompts.append(prompt)\n",
    "                            target.append(int(label == train.choices[1]))\n",
    "\n",
    "                        target = torch.Tensor(target).long().to(device)\n",
    "                        acc = (taskllm.predict(prompts, augment=train.swap_refs).argmax(dim=1) == target).float().mean().item()\n",
    "    \n",
    "                    loss = taskllm.learn(prompts, target, augment=train.swap_refs) if istrain else None\n",
    "                    printer.addobs(iteration, loss, acc if istrain else None, acc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            if iteration == 0:\n",
    "                taskllm.save_pretrained(f'User_keq{k}_t5base_step1')\n",
    "\n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or step_one(k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Step 2: learn ranker using (fixed pre-finetuned) task LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28408ef1-b7b6-4ccd-b137-df6a70a9fe57",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n                  iter       since      4 loss       since       4 acc       since 4 acc (dev)       since      dt (s)\n",
      "1                     0           0       0.694       0.694           0           0           0           0        2.92\n",
      "2                     0           0       0.727        0.76           0           0           0           0        6.21\n",
      "4                     0           0       0.678       0.629         0.5           1           0           0        12.8\n",
      "8                     0           0       0.602         0.5       0.714           1           1           1        24.3\n",
      "16                    0           0       0.661       0.713         0.6         0.5           1           0        50.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b\"v\\x1b)\\\\\\xaa\\xf4\\xe8}'\\xa7\\xf7\\xb1xaw\\x07\\xd8. x8\\x10\\xb6\\xe4\\xe62\\xd5\\x1b1\\xd4f\\x196Z\"]\n",
      "Bad pipe message: %s [b\"?\\xab\\xd4\\xf6A\\xc9\\x1c\\xd9PSF\\xcd\\xeeS%Bn1\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\"]\n",
      "Bad pipe message: %s [b\"\\xcb\\xd5:\\xa7-o\\x14\\xbc\\xa3\\x80\\x8b\\xe8\\xd8\\xdeg\\xf1\\xf6\\x96\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\"]\n",
      "Bad pipe message: %s [b'\\x0c\\x00\\x00\\t127.0.0.1']\n",
      "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
      "Bad pipe message: %s [b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'\\xb99\\xad\\xe6L\\xcb[ &L#C)\\xfa\\x95\\x14\\xc6u\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15']\n",
      "Bad pipe message: %s [b'\\r\\x02rjG\\xc3\\xf5\\xa0J\\r\\x0b\\xaa\\xe8\\xf9\\xe2;\\x99]\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n']\n",
      "Bad pipe message: %s [b'#*\\xef\\xb7\\xdc\\x05  \\x08\\x1c\\xd0L\\xe2\\x1d\\x81\\x07\\xc9%\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06']\n",
      "Bad pipe message: %s [b\"\\xb6w\\xca\\xfc\\x84\\xf9;\\x1dRpwc\\xa3S;kd\\xdb\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\"]\n",
      "Bad pipe message: %s [b'Qg\\xe4\\xec\\xb1\\xf0\\xcf\\xa5\\x14\\xecSe]\\x86 iA\\xdb\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x00']\n",
      "Bad pipe message: %s [b\"7\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32                    0           0       0.572       0.477       0.724       0.857       0.667         0.5        97.5\n",
      "64                    0           0       0.552       0.531       0.737        0.75       0.857           1         198\n",
      "128                   0           0       0.545       0.538       0.772       0.807       0.786       0.714         393\n",
      "256                   0           0       0.558       0.571       0.744       0.717       0.793         0.8         792\n",
      "512                   0           0       0.579       0.601       0.736       0.727       0.655       0.517    1.59e+03\n",
      "1024                  0           0       0.593       0.607       0.729       0.722       0.718        0.78    3.18e+03\n",
      "2048                  0           0       0.596         0.6        0.72       0.711       0.667       0.615    6.37e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b\"\\x9a\\xb9\\xfb\\x87\\xa9YP\\xbc'\\x97\", b\"\\xfb4\\xad\\n\\xa5q \\xdb\\x08\\xea\\xd2\\xe5\\x0c\\xa5'\\xd2\\xb3\\xc95\\x80;z\\xd6<]h\\xe3\\x1b0\\x16\\x0c\\x14\\xa9\\xe7\\xae6m\\xa03\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\"]\n",
      "Bad pipe message: %s [b'\\xcdU\\xc3\\x0b!\\xc7\\xde\\xc5a\\xdf\\x811\\xf3\\xfcI\\xc8p\\xc4 \\xce_[l\\xe0\\xf8=p\\x82fBE\\xae\\xee\\x1c\\x0e\\xe3a\\xe9\\xf0\\x90{\\n\\xca\\x9d4\\xf8\\xc5\\xcd\\xfdU\\xc2\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03']\n",
      "Bad pipe message: %s [b\"\\xe0W\\x97\\xce\\x95z\\xf2\\x93e\\x0426NCH\\xf4c\\x90\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.\"]\n",
      "Bad pipe message: %s [b'0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03']\n",
      "Bad pipe message: %s [b'\\x06\\x03\\x08\\x07', b'\\x08\\t\\x08\\n\\x08\\x0b\\x08']\n",
      "Bad pipe message: %s [b'\\x05\\x08\\x06']\n",
      "Bad pipe message: %s [b'\\x05\\x01\\x06', b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b\"/'\\x8d C\\xd9^\\xfc\\xb8>t\\x08\\xdf\\x95p8\\xb3S\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\", b\"\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\"]\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
      "Bad pipe message: %s [b'\\x00\\x1c\\xbbq\\x17\\xa47\\x06!\\xdc\\xdd\\xf5C6\\x15I\\x08\\x08\\x00\\x00>\\xc0\\x14\\xc0', b'9\\x008\\x007\\x006\\xc0\\x0f']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'\\x10\\xc4\\x0fd\\xc1\\xe8\\x04\\x0eQzY\\xc5\\x15\\x19o1\\x04\\xea']\n",
      "Bad pipe message: %s [b'\\x0b+\\x07\\x9ecb\\x9cYC~\\xd4\\x00\\xdf\\xe9\\xc7\\x99\\x98\\xe7\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00']\n",
      "Bad pipe message: %s [b'\\xb8\\x8e\\x1c\\xc6;x\\x96l_\\xbe\\xab<\\x84\\xe9\\xaer\\xc5\\xd0\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1']\n",
      "Bad pipe message: %s [b'X7iv\\x18`\\xfa\\xfc\\xb2<\\xc6\\x98+\\x00$M\\xb7V\\x00\\x00\\xa2\\xc0', b'\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096                  0           0       0.594       0.592       0.723       0.725        0.66       0.654    1.28e+04\n",
      "8192                  0           0       0.596       0.597       0.717       0.712       0.688       0.716    2.54e+04\n",
      "10931                 0           0       0.597       0.601       0.714       0.705       0.693       0.706    3.39e+04\n",
      "21862               0.5           1        0.59       0.582       0.724       0.735       0.693       0.693    6.78e+04\n"
     ]
    }
   ],
   "source": [
    "def learn_ranker(*, max_iteration, k):\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedCitation import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from SimpleRegret import SimpleRegretGreedyDoubleSampler\n",
    "    from peft import PeftConfig, IA3Config, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=2, double_data=True)\n",
    "    dev = dev_loader(batch_size=2)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    t5.load_adapter('User_keq4_t5base_step1', 'taskllm')\n",
    "\n",
    "    rhat_config = IA3Config(task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(rhat_config, \"rhat\")\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\")\n",
    "    \n",
    "    def reward_augment(prompts):\n",
    "        import re\n",
    "        return [ re.sub(r'Ref1: (.*)\\nRef2: (.*)\\nExtra:',\n",
    "                        r'Ref1: \\2\\nRef2: \\1\\nExtra:',\n",
    "                        z)\n",
    "                 for z in prompts ]\n",
    "\n",
    "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
    "    def randomized_similarity(ex, nsamples):\n",
    "        embeddings = train.embed( [ ex['ref1'], ex['ref2'] ] + \n",
    "                                  [ v['title'] \n",
    "                                   for v in ex['profile']\n",
    "                                   if v['title'] != ex['title'] \n",
    "                                 ])\n",
    "        scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
    "        temperature = scores[0].item() - scores[4].item()\n",
    "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
    "        gumbels = temperature * gumbel.sample(gumbel_shape)\n",
    "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=k).indices, sorted=False, dim=0).to('cpu')\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} acc', f'{k} acc (dev)') as printer:\n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev):\n",
    "                if iteration + 1 < max_iteration or not istrain:\n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        greedyrewards = []\n",
    "                        allloss = []\n",
    "                        with torch.no_grad():\n",
    "                            randos = randomized_similarity(ex, 64)\n",
    "                            \n",
    "                            rhatprompts = []\n",
    "                            prompts = []\n",
    "                            for rando in randos:\n",
    "                                titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in rando ]\n",
    "                                concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
    "                                prompt = train.append_to_title(ex, concat_titles)\n",
    "                                prompts.append(prompt)\n",
    "                                rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\n\" + '\\n'.join(\n",
    "                                           [ f\"Extra: {t}\" for t in titles ])\n",
    "                                rhatprompts.append(rhatprompt)\n",
    "\n",
    "                            rhats = rewardpredictor.predict(rhatprompts, augment=reward_augment)\n",
    "                            if len(rhats) > 1:\n",
    "                                explore, exploit = SimpleRegretGreedyDoubleSampler(rhats.view(1, -1), gamma=10)\n",
    "                                actionind = [exploit.item(), explore.item()]\n",
    "                            else:\n",
    "                                actionind = [0]\n",
    "\n",
    "                            guesses = taskllm.predict([ prompts[a] for a in actionind ], augment=train.swap_refs).argmax(dim=1)\n",
    "                            target = int(label == train.choices[1])\n",
    "                            rewards = (guesses == target).float().unsqueeze(1)\n",
    "                            greedyreward = rewards[0, 0].item()\n",
    "                            greedyrewards.append(greedyreward)\n",
    "                            \n",
    "                        loss = rewardpredictor.learn([ rhatprompts[a] for a in actionind ], rewards, augment=reward_augment) if istrain else None\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                    greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
    "                    predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "\n",
    "                    printer.addobs(iteration, predloss, greedyacc if istrain else None, greedyacc if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            if iteration + 1 < max_iteration:\n",
    "                rewardpredictor.save_pretrained(f'User_keq{k}_t5base_step2_iter{iteration}')\n",
    "\n",
    "from Fork import SubProcess\n",
    "with SubProcess() as process: process.parent or learn_ranker(k=4, max_iteration=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9869e3a-55cd-47d0-9b42-d67dec76df4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
