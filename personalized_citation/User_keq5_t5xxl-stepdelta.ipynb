{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad399461-4441-462c-8b0b-671c948404be",
      "metadata": {},
      "source": [
        "# Step 1 Dev Set Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9cc1a5-21fa-49a9-b30a-279c17958b2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** step1_iter: 0 ***\n",
            "n       5 acc (dev) (since)      dt\n",
            "1             1.000 (1.000)  5.22 s\n",
            "2             1.000 (1.000)  8.75 s\n",
            "4             0.750 (0.500)  15.5 s\n",
            "8             0.688 (0.625)  28.9 s\n",
            "16            0.688 (0.688)    56 s\n",
            "32            0.750 (0.812)  1.83 m\n",
            "64            0.750 (0.750)  3.57 m\n",
            "128           0.734 (0.719)  7.04 m\n",
            "256           0.740 (0.746)    14 m\n",
            "512           0.745 (0.750)  27.8 m\n",
            "1024          0.754 (0.763)  54.7 m\n",
            "1250          0.757 (0.770)   1.1 h\n"
          ]
        }
      ],
      "source": [
        "def step1_dev_set_labels(*, step1_iter, k):\n",
        "    import json\n",
        "    from RewardPredictor import RewardPredictor\n",
        "    from TaskLLM import TaskLLM\n",
        "    from PersonalizedCitation import train_loader, dev_loader\n",
        "    from ProgressPrinter import ProgressPrinter\n",
        "    from peft import PeftConfig, IA3Config, TaskType, prepare_model_for_kbit_training\n",
        "    from transformers import T5ForConditionalGeneration\n",
        "    import torch\n",
        "    import warnings\n",
        "    \n",
        "    device = 'cuda'\n",
        "    torch.set_default_device(device)\n",
        "    torch.manual_seed(2112)\n",
        "\n",
        "    dev = dev_loader(batch_size=2)\n",
        "\n",
        "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl', load_in_8bit=True))\n",
        "    t5.load_adapter(f'User_keq{k}_t5xxl_step1_iter{step1_iter}', 'taskllm')\n",
        "    t5.enable_adapters()\n",
        "    \n",
        "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
        "\n",
        "    print(f'*** step1_iter: {step1_iter} ***')\n",
        "    \n",
        "    with ProgressPrinter(f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
        "        devgolds = []\n",
        "        \n",
        "        for examples, labels in dev:\n",
        "            greedyrewards = []\n",
        "            for ex, label in zip(examples, labels):\n",
        "                with torch.no_grad():\n",
        "                    targets, guesses = [], []\n",
        "    \n",
        "                    for ex, label in zip(examples, labels):\n",
        "                        embeddings = dev.embed( [ ex['ref1'], ex['ref2'] ] + \n",
        "                                                [ v['title'] \n",
        "                                                  for v in ex['profile']\n",
        "                                                  if v['title'] != ex['title'] \n",
        "                                                ])\n",
        "                        scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
        "                        index = torch.topk(scores, dim=0, k=k).indices.to('cpu')\n",
        "                        titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in index.tolist() ]\n",
        "                        concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
        "                        prompt = dev.append_to_title(ex, concat_titles)\n",
        "                        guess = taskllm.predict([prompt], augment=dev.swap_refs).argmax(dim=1).item()\n",
        "                        devgolds.append({ 'id': ex['id'], 'output': \"[2]\" if guess else \"[1]\" })\n",
        "                        guesses.append(guess)\n",
        "                        targets.append(int(label == dev.choices[1]))\n",
        "\n",
        "            greedyacc = (torch.Tensor(guesses) == torch.Tensor(targets)).float().mean().item()\n",
        "\n",
        "            printer.addobs(greedyacc)\n",
        "\n",
        "        printer.print()\n",
        "        printer.autoprint = False\n",
        "\n",
        "        with open(f'lamp1u_xxl_step1_dev_golds.json', 'w') as jsonfile:\n",
        "            json.dump({ 'task': 'LaMP_1', 'golds': devgolds }, jsonfile)\n",
        "\n",
        "step1_dev_set_labels(k=5, step1_iter=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52956689-a1bb-4dc2-b2f1-62f209415795",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** step1_iter: 0 step2_iter: 2 ***\n",
            "n       5 acc (dev) (since)      dt\n",
            "1             0.500 (0.500)  13.2 s\n",
            "2             0.750 (1.000)  24.7 s\n",
            "4             0.750 (0.750)  43.2 s\n",
            "8             0.688 (0.625)  1.34 m\n",
            "16            0.719 (0.750)  2.78 m\n",
            "32            0.781 (0.844)  5.79 m\n",
            "64            0.781 (0.781)  11.4 m\n",
            "128           0.777 (0.773)  22.7 m\n",
            "256           0.777 (0.777)  45.4 m\n",
            "512           0.769 (0.760)  1.52 h\n",
            "1024          0.777 (0.785)  3.04 h\n",
            "1250          0.775 (0.765)  3.71 h\n"
          ]
        }
      ],
      "source": [
        "def step2_dev_set_labels(*, step2_iter, step1_iter, k):\n",
        "    import json\n",
        "    from RewardPredictor import RewardPredictor\n",
        "    from TaskLLM import TaskLLM\n",
        "    from PersonalizedCitation import train_loader, dev_loader\n",
        "    from ProgressPrinter import ProgressPrinter\n",
        "    from peft import PeftConfig, IA3Config, TaskType, prepare_model_for_kbit_training\n",
        "    from transformers import T5ForConditionalGeneration\n",
        "    import torch\n",
        "    import warnings\n",
        "    \n",
        "    device = 'cuda'\n",
        "    torch.set_default_device(device)\n",
        "    torch.manual_seed(2112)\n",
        "\n",
        "    dev = dev_loader(batch_size=2)\n",
        "\n",
        "    t5 = prepare_model_for_kbit_training(T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl', load_in_8bit=True))\n",
        "    t5.load_adapter(f'User_keq{k}_t5xxl_step1_iter{step1_iter}', 'taskllm')\n",
        "    t5.load_adapter(f'User_keq{k}_t5xxl_step2_iter{step2_iter}', 'rhat')\n",
        "    t5.enable_adapters()\n",
        "    \n",
        "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
        "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\", model_id=f'User_keq{k}_t5xxl_step2_iter{step2_iter}')\n",
        "\n",
        "    def reward_augment(inputs):\n",
        "        import re\n",
        "        return [ re.sub(r'Ref1: (.*)\\nRef2: (.*)\\nExtra:',\n",
        "                        r'Ref1: \\2\\nRef2: \\1\\nExtra:',\n",
        "                        z)\n",
        "                 for z in inputs ]\n",
        "\n",
        "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
        "    def randomized_similarity(ex, nsamples):\n",
        "        embeddings = dev.embed( [ ex['ref1'], ex['ref2'] ] + \n",
        "                                [ v['title'] \n",
        "                                  for v in ex['profile']\n",
        "                                  if v['title'] != ex['title'] \n",
        "                                ])\n",
        "        scores = torch.max(embeddings[[0,1],:] @ embeddings[2:,:].T, dim=0).values\n",
        "        temperature = scores[0].item() - scores[4].item()\n",
        "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
        "        gumbels = temperature * gumbel.sample(gumbel_shape)\n",
        "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=k).indices, sorted=False, dim=0).to('cpu')\n",
        "\n",
        "    print(f'*** step1_iter: {step1_iter} step2_iter: {step2_iter} ***')\n",
        "    nvoters = 1\n",
        "    \n",
        "    with ProgressPrinter(f'{k} acc (dev)') as printer, warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", message=\".*MatMul8bitLt.*\")\n",
        "        devgolds = []\n",
        "        \n",
        "        for examples, labels in dev:\n",
        "            greedyrewards = []\n",
        "            for ex, label in zip(examples, labels):\n",
        "                with torch.no_grad():\n",
        "                    randos = randomized_similarity(ex, 64)\n",
        "                    \n",
        "                    rhatprompts = []\n",
        "                    prompts = []\n",
        "                    for rando in randos:\n",
        "                        titles = [ f'{ex[\"profile\"][ind][\"title\"]}' for ind in rando ]\n",
        "                        concat_titles = ' and '.join([f'\"{v}\"' for v in titles])\n",
        "                        prompt = dev.append_to_title(ex, concat_titles)\n",
        "                        prompts.append(prompt)\n",
        "                        rhatprompt = f\"Title: {ex['title']}\\nRef1: {ex['ref1']}\\nRef2: {ex['ref2']}\\n\" + '\\n'.join(\n",
        "                                   [ f\"Extra: {t}\" for t in titles ])\n",
        "                        rhatprompts.append(rhatprompt)\n",
        "\n",
        "                    rhats = rewardpredictor.predict(rhatprompts, augment=reward_augment)\n",
        "                    voters = torch.topk(rhats, k=min(nvoters, len(rhats)), dim=0).indices.view(-1).to('cpu').tolist()\n",
        "                    guess = taskllm.predict([ prompts[v] for v in voters ], augment=dev.swap_refs).logsumexp(dim=0, keepdim=True).argmax(dim=1)\n",
        "                        \n",
        "                    target = int(label == dev.choices[1])\n",
        "                    reward = int(guess.item() == target)\n",
        "                    greedyrewards.append(reward)\n",
        "\n",
        "                    devgolds.append({ 'id': ex['id'], 'output': \"[2]\" if guess else \"[1]\" })\n",
        "\n",
        "            greedyacc = torch.Tensor(greedyrewards).float().mean().item()\n",
        "\n",
        "            printer.addobs(greedyacc)\n",
        "\n",
        "        printer.print()\n",
        "        printer.autoprint = False\n",
        "\n",
        "        with open(f'lamp1u_xxl_step2_dev_golds.json', 'w') as jsonfile:\n",
        "            json.dump({ 'task': 'LaMP_1', 'golds': devgolds }, jsonfile)\n",
        "\n",
        "step2_dev_set_labels(k=5, step1_iter=0, step2_iter=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5520dd-ce2b-4d74-aac8-b1310ed80528",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
