{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Step 1: fine-tune LLM using top result from (fixed) ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** augment = 2 max_iteration = 5 model_type = xxl *********\n",
      "n              iter (since)      4 loss (since)       4 acc (since)   4 ema acc (since) 4 acc (dev) (since)      dt\n",
      "1             0.000 (0.000)       1.058 (1.058)       0.750 (0.750)       0.750 (0.750)       0.000 (0.000)  3.29 s\n",
      "2             0.000 (0.000)       0.714 (0.371)       0.750 (0.750)       0.875 (1.000)       0.000 (0.000)  7.27 s\n",
      "4             0.000 (0.000)       3.102 (5.490)       0.688 (0.625)       0.875 (0.875)       0.000 (0.000)  13.7 s\n",
      "8             0.000 (0.000)       2.223 (1.344)       0.656 (0.625)       0.906 (0.938)       0.000 (0.000)  26.5 s\n",
      "16            0.000 (0.000)       1.520 (0.817)       0.703 (0.750)       0.812 (0.719)       0.000 (0.000)  54.8 s\n",
      "32            0.000 (0.000)       1.443 (1.365)       0.680 (0.656)       0.758 (0.703)       0.000 (0.000)  1.83 m\n",
      "64            0.000 (0.000)       1.250 (1.057)       0.660 (0.641)       0.711 (0.664)       0.000 (0.000)  3.64 m\n",
      "128           0.000 (0.000)       0.968 (0.686)       0.725 (0.789)       0.742 (0.773)       0.000 (0.000)  7.18 m\n",
      "256           0.000 (0.000)       0.863 (0.758)       0.743 (0.762)       0.754 (0.766)       0.000 (0.000)    14 m\n",
      "512           0.000 (0.000)       0.726 (0.589)       0.778 (0.812)       0.779 (0.805)       0.000 (0.000)  27.9 m\n",
      "1024          0.000 (0.000)       0.655 (0.583)       0.798 (0.818)       0.803 (0.827)       0.000 (0.000)  55.9 m\n",
      "2048          0.000 (0.000)       0.626 (0.597)       0.802 (0.806)       0.814 (0.826)       0.000 (0.000)  1.86 h\n",
      "4096          0.000 (0.000)       0.580 (0.535)       0.817 (0.832)       0.826 (0.837)       0.000 (0.000)  3.71 h\n",
      "4699          0.000 (0.000)       0.574 (0.499)       0.818 (0.838)       0.826 (0.824)       0.868 (0.868)  4.11 h\n",
      "9398          0.500 (1.000)       0.509 (0.444)       0.839 (0.860)       0.841 (0.856)       0.866 (0.865)  8.22 h\n",
      "14097         1.000 (2.000)       0.456 (0.350)       0.856 (0.890)       0.850 (0.868)       0.865 (0.863)  12.3 h\n",
      "18796         1.500 (3.000)       0.412 (0.280)       0.871 (0.916)       0.856 (0.876)       0.864 (0.859)  16.4 h\n",
      "23495         2.000 (4.000)       0.374 (0.222)       0.884 (0.934)       0.863 (0.889)       0.864 (0.867)  20.5 h\n"
     ]
    }
   ],
   "source": [
    "def launch():\n",
    "    import os\n",
    "    import StepOne\n",
    "    import torch\n",
    "\n",
    "    os.environ['MODEL_TYPE'] = 'xxl'\n",
    "    os.environ['BATCH_SIZE'] = '1'\n",
    "    os.environ['AUGMENT'] = os.environ.get('AUGMENT', '2')\n",
    "    \n",
    "    world_size = torch.cuda.device_count()\n",
    "    torch.multiprocessing.spawn(StepOne.step_one,\n",
    "                                args=(world_size,),\n",
    "                                nprocs=world_size,\n",
    "                                join=True)\n",
    "    \n",
    "launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Step 2: learn ranker using (fixed pre-finetuned) task LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58810c2b-35e5-4efe-bd43-1b5f25c16357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** augment = 2 max_iteration = 5 model_type = xxl *********\n",
      "n              iter (since)      4 loss (since)       4 acc (since)   4 acc ema (since) 4 acc (dev) (since)      nsamps (since)      dt\n",
      "1             0.000 (0.000)       0.075 (0.075)       1.000 (1.000)       1.000 (1.000)       0.000 (0.000)     140.000 (140.000)  2.79 m\n",
      "2             0.000 (0.000)       0.055 (0.035)       1.000 (1.000)       1.000 (1.000)       0.000 (0.000)      72.000 (4.000)  3.81 m\n",
      "4             0.000 (0.000)       0.027 (0.000)       1.000 (1.000)       1.000 (1.000)       0.000 (0.000)      36.875 (1.750)  6.13 m\n",
      "8             0.000 (0.000)       0.014 (0.000)       1.000 (1.000)       1.000 (1.000)       0.000 (0.000)      19.812 (2.750)  10.4 m\n",
      "16            0.000 (0.000)       0.361 (0.709)       0.875 (0.750)       0.875 (0.750)       0.000 (0.000)      13.812 (7.812)  17.7 m\n",
      "32            0.000 (0.000)       0.510 (0.659)       0.781 (0.688)       0.812 (0.750)       0.000 (0.000)      15.062 (16.312)  36.7 m\n",
      "64            0.000 (0.000)       0.412 (0.314)       0.852 (0.922)       0.867 (0.922)       0.000 (0.000)      12.352 (9.641)  1.18 h\n",
      "128           0.000 (0.000)       0.366 (0.319)       0.883 (0.914)       0.887 (0.906)       0.000 (0.000)       9.723 (7.094)  2.28 h\n",
      "256           0.000 (0.000)       0.365 (0.363)       0.881 (0.879)       0.883 (0.879)       0.000 (0.000)       8.529 (7.336)  4.45 h\n",
      "512           0.000 (0.000)       0.380 (0.395)       0.867 (0.854)       0.870 (0.857)       0.000 (0.000)       8.627 (8.725)  9.04 h\n",
      "1024          0.000 (0.000)       0.400 (0.420)       0.850 (0.833)       0.851 (0.831)       0.000 (0.000)       8.755 (8.884)  17.9 h\n",
      "2048          0.000 (0.000)       0.409 (0.418)       0.843 (0.835)       0.844 (0.836)       0.000 (0.000)       8.686 (8.616)  1.49 d\n",
      "4096          0.000 (0.000)       0.412 (0.415)       0.842 (0.841)       0.844 (0.845)       0.000 (0.000)       8.644 (8.602)  2.97 d\n",
      "8192          0.000 (0.000)       0.367 (0.323)       0.843 (0.845)       0.844 (0.844)       0.000 (0.000)       7.914 (7.184)  5.88 d\n",
      "9397          0.000 (0.000)       0.358 (0.248)       0.844 (0.848)       0.844 (0.845)       0.870 (0.870)       7.761 (5.912)  6.67 d\n"
     ]
    }
   ],
   "source": [
    "def launch():\n",
    "    import os\n",
    "    import StepTwo\n",
    "    import torch\n",
    "\n",
    "    os.environ['MODEL_TYPE'] = 'xxl'\n",
    "    os.environ['BATCH_SIZE'] = '2'\n",
    "    os.environ['LEARN_BATCH_SIZE'] = '2'\n",
    "    os.environ['STEP1_ITER'] = '0_augment2'\n",
    "    \n",
    "    world_size = torch.cuda.device_count()\n",
    "    torch.multiprocessing.spawn(StepTwo.step_two,\n",
    "                                args=(world_size,),\n",
    "                                nprocs=world_size,\n",
    "                                join=True)\n",
    "    \n",
    "launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19b04cb-41dc-4ad3-b43a-662a2822ce4c",
   "metadata": {},
   "source": [
    "# Step 3: Prepare Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe04c6-5858-4130-a12c-308610861567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** step1_iter: 0_augment2 step2_iter: 0_augment2 nvoters 1 ***\n",
      "n       4 acc (dev) (since)      dt\n",
      "1             0.750 (0.750)  36.2 s\n",
      "2             0.875 (1.000)  1.09 m\n",
      "4             0.875 (0.875)  1.93 m\n",
      "8             0.891 (0.906)  3.72 m\n",
      "16            0.891 (0.891)  7.23 m\n",
      "32            0.891 (0.891)  14.8 m\n",
      "64            0.857 (0.824)  30.1 m\n",
      "128           0.862 (0.867)  1.02 h\n",
      "256           0.865 (0.938)   2.1 h\n",
      "*** step1_iter: 0_augment2 step2_iter: 0_augment2 nvoters 3 ***\n",
      "n       4 acc (dev) (since)      dt\n",
      "1             0.750 (0.750)  37.3 s\n",
      "2             0.812 (0.875)  1.12 m\n",
      "4             0.812 (0.812)  1.98 m\n",
      "8             0.859 (0.906)  3.83 m\n",
      "16            0.883 (0.906)  7.46 m\n",
      "32            0.887 (0.891)  15.3 m\n",
      "64            0.857 (0.828)  31.1 m\n",
      "128           0.861 (0.865)  1.05 h\n",
      "256           0.864 (0.938)  2.17 h\n",
      "*** step1_iter: 0_augment2 step2_iter: 0_augment2 nvoters 5 ***\n",
      "n       4 acc (dev) (since)      dt\n",
      "1             0.750 (0.750)  38.5 s\n",
      "2             0.812 (0.875)  1.16 m\n",
      "4             0.812 (0.812)  2.05 m\n",
      "8             0.859 (0.906)  3.96 m\n",
      "16            0.883 (0.906)  7.73 m\n",
      "32            0.887 (0.891)  15.9 m\n",
      "64            0.857 (0.828)  32.3 m\n",
      "128           0.863 (0.869)  1.09 h\n",
      "256           0.866 (0.938)  2.25 h\n",
      "*** step1_iter: 0_augment2 step2_iter: 0_augment2 nvoters 7 ***\n",
      "n       4 acc (dev) (since)      dt\n",
      "1             0.750 (0.750)  39.8 s\n",
      "2             0.812 (0.875)   1.2 m\n",
      "4             0.812 (0.812)  2.11 m\n",
      "8             0.859 (0.906)  4.09 m\n",
      "16            0.883 (0.906)  7.99 m\n",
      "32            0.887 (0.891)  16.5 m\n",
      "64            0.857 (0.828)  33.5 m\n",
      "128           0.864 (0.871)  1.13 h\n",
      "256           0.866 (0.938)  2.33 h\n"
     ]
    }
   ],
   "source": [
    "def prepare_submission_probensemble(*, nvoters, step2_iter, step1_iter, k):\n",
    "    import json\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedNewsCat import dev_loader, test_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    \n",
    "    device = 0\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(8675309)\n",
    "\n",
    "    dev = dev_loader(batch_size=8)\n",
    "    test = test_loader(batch_size=8)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl', load_in_8bit=True, device_map=0)\n",
    "    taskllm_model_id = f'User_keq{k}_t5xxl_step1_iter{step1_iter}'\n",
    "    t5.load_adapter(taskllm_model_id, 'raw_taskllm')\n",
    "    t5.load_adapter(taskllm_model_id, 'ema_taskllm')\n",
    "    rhat_model_id = f'User_keq{k}_t5xxl_step2_iter{step2_iter}'\n",
    "    t5.load_adapter(rhat_model_id, 'raw_rhat')\n",
    "    t5.load_adapter(rhat_model_id, 'ema_rhat')\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_suffix=\"taskllm\", model_id=taskllm_model_id, choices=dev.choices)\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_suffix=\"rhat\", model_id=rhat_model_id)\n",
    "\n",
    "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
    "    def randomized_similarity(embeddings, nsamples):\n",
    "        scores = embeddings[0,:] @ embeddings[1:,:].T\n",
    "        temperature = scores[0].item() - scores[min(scores.shape[0]-1, 4)].item()\n",
    "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
    "        gumbels = temperature * gumbel.sample(gumbel_shape).to(scores.device)\n",
    "        safek = min(k, scores.shape[0])\n",
    "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=safek).indices, sorted=False, dim=0)\n",
    "\n",
    "    def inner_batch(func, inner_batch_size, inputs):\n",
    "        from more_itertools import chunked\n",
    "        return [ func(*ib) for ib in zip(*[ chunked(g, inner_batch_size) for g in inputs ]) ]\n",
    "\n",
    "    def make_prior(profile):\n",
    "        from math import log\n",
    "\n",
    "        c = [1]*len(dev.choices)\n",
    "        for v in profile:\n",
    "            c[dev.choices.index(v['category'])] += 1\n",
    "        n = sum(c)\n",
    "\n",
    "        return [ log(cnt) - log(n) for cnt in c ]\n",
    "    \n",
    "    print(f'*** step1_iter: {step1_iter} step2_iter: {step2_iter} nvoters {nvoters} ***')\n",
    "\n",
    "    devgolds, testgolds = [], []\n",
    "    with ProgressPrinter(f'{k} acc (dev)') as printer:\n",
    "        cumsum = lambda z, acc=0: [0] + [ acc := acc + v for v in z ]\n",
    "\n",
    "        for isdev, (examples, labels) in interleave(dev, test, sequential=True):\n",
    "            with torch.no_grad():\n",
    "                prior = [ make_prior(ex['profile']) for ex in examples ]\n",
    "                texts_to_embed = [ [ text[:256]\n",
    "                                     for text in (' '.join(ex['article'].split()), )\n",
    "                                   ] +\n",
    "                                   [ text[:256]\n",
    "                                     for v in ex['profile']\n",
    "                                     for text in (' '.join(v['text'].split()), )\n",
    "                                   ]\n",
    "                                   for ex in examples\n",
    "                                 ]\n",
    "                embeddings = torch.cat(inner_batch(func = dev.embed,\n",
    "                                                   inner_batch_size = 128,\n",
    "                                                   inputs = (sum(texts_to_embed, []),)\n",
    "                                                  ),\n",
    "                                       dim=0)\n",
    "                splits = cumsum(map(len, texts_to_embed))\n",
    "                randos = [ randomized_similarity(embeddings[a:b,:], 64) for a, b in zip(splits, splits[1:]) ]\n",
    "                prompts = [ [ dev.prepend_to_prompt(ex, [ ex['profile'][ind] for ind in indices ])\n",
    "                              for indices in rando.to('cpu').tolist()\n",
    "                            ]\n",
    "                            for ex, rando in zip(examples, randos)\n",
    "                          ]\n",
    "                rhats = torch.cat(inner_batch(func = rewardpredictor.predict,\n",
    "                                              inner_batch_size = 128,\n",
    "                                              inputs = (sum(prompts, []),)\n",
    "                                             ),\n",
    "                                  dim=0)\n",
    "                splits = cumsum(map(len, prompts))\n",
    "                votingprompts = [ [ prompt[v] for v in torch.topk(rhats[a:b].view(-1), k=min(nvoters, b-a)).indices.to('cpu').tolist() ]\n",
    "                                    for a, b, prompt in zip(splits, splits[1:], prompts)\n",
    "                                ]\n",
    "                votingpriors = [ [q]*min(nvoters, b-a) for a, b, q in zip(splits, splits[1:], prior) ]\n",
    "                predicts = torch.cat(inner_batch(func = lambda p, q: taskllm.predict(p, prior=torch.Tensor(q).to(device)),\n",
    "                                                 inner_batch_size = 128,\n",
    "                                                 inputs = (sum(votingprompts, []), sum(votingpriors, [])),\n",
    "                                                ),\n",
    "                                     dim=0)\n",
    "                splits = cumsum(map(len, votingprompts))\n",
    "                guesses = torch.cat([ predicts[a:b,:].logsumexp(dim=0, keepdim=True).argmax(dim=1)\n",
    "                                      for a, b in zip(splits, splits[1:])\n",
    "                                    ],\n",
    "                                    dim=0)\n",
    "\n",
    "                if isdev:\n",
    "                    targets = [ dev.choices.index(label) for label in labels ]\n",
    "                    targets = torch.Tensor(targets).long().to(guesses.device)\n",
    "                    acc = (guesses == targets).float().mean().item()\n",
    "                else:\n",
    "                    acc = None\n",
    "\n",
    "                for ex, guess in zip(examples, guesses):\n",
    "                    (devgolds if isdev else testgolds).append({ 'id': ex['id'], 'output': dev.choices[guess] })\n",
    "\n",
    "            printer.addobs(acc)\n",
    "\n",
    "    for wut, golds in ( ('dev', devgolds), ('test', testgolds) ):\n",
    "        with open(f'lamp2u_{wut}golds_t5xxl_keq{k}_step1_iter{step1_iter}_step2_iter{step2_iter}_nvoters{nvoters}.json', 'w') as jsonfile:\n",
    "            json.dump({ 'task': 'LaMP_2', 'golds': golds }, jsonfile)\n",
    "\n",
    "for nvoters in [1, 3, 5, 7]:\n",
    "    # ugh ... without complete cleanup, run out of memory\n",
    "    from multiprocessing import Process\n",
    "    p = Process(target=prepare_submission_probensemble, \n",
    "                kwargs = { 'k': 4,\n",
    "                           'step1_iter': '0_augment2', \n",
    "                           'step2_iter': '0_augment2', \n",
    "                           'nvoters': nvoters\n",
    "                         })\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c50e3-77dc-402a-a7ce-26d973fb2981",
   "metadata": {},
   "source": [
    "> Hi,\n",
    "> \n",
    "> This is the results of your latest submission to the LaMP benchmark:\n",
    "> \n",
    "> {\"accuracy\": 0.7880690737833596, \"f1\": 0.6566988264536381}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19e971-5282-4cb9-ba02-c365843e7b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
