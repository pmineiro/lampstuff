{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
      "metadata": {},
      "source": [
        "# Step 1: fine-tune LLM using top result from (fixed) ranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******** augment = 4 max_iteration = 5 model_type = base *********\n",
            "n              iter (since)      4 loss (since)       4 acc (since) 4 acc (dev) (since)      dt\n",
            "1             0.000 (0.000)       2.592 (2.592)       0.594 (0.594)       0.000 (0.000)  16.9 s\n",
            "2             0.000 (0.000)       1.997 (1.402)       0.609 (0.625)       0.000 (0.000)  30.4 s\n",
            "4             0.000 (0.000)       1.396 (0.796)       0.703 (0.797)       0.000 (0.000)  57.7 s\n",
            "8             0.000 (0.000)       1.081 (0.765)       0.730 (0.758)       0.000 (0.000)  1.74 m\n",
            "16            0.000 (0.000)       0.895 (0.709)       0.766 (0.801)       0.000 (0.000)  3.32 m\n",
            "32            0.000 (0.000)       0.815 (0.736)       0.767 (0.768)       0.000 (0.000)  6.27 m\n",
            "64            0.000 (0.000)       0.761 (0.707)       0.775 (0.784)       0.000 (0.000)  12.9 m\n",
            "128           0.000 (0.000)       0.748 (0.734)       0.774 (0.773)       0.000 (0.000)  25.5 m\n",
            "256           0.000 (0.000)       0.708 (0.659)       0.783 (0.795)       0.829 (0.829)  48.4 m\n",
            "264           0.000 (0.000)       0.708 (0.000)       0.783 (0.000)       0.828 (0.825)  48.9 m\n",
            "528           0.500 (1.000)       0.657 (0.605)       0.800 (0.816)       0.826 (0.824)  1.64 h\n",
            "792           1.000 (2.000)       0.622 (0.554)       0.809 (0.827)       0.818 (0.801)  2.47 h\n",
            "1056          1.500 (3.000)       0.593 (0.503)       0.817 (0.843)       0.819 (0.821)  3.27 h\n",
            "1320          2.000 (4.000)       0.563 (0.444)       0.826 (0.859)       0.818 (0.816)  4.07 h\n"
          ]
        }
      ],
      "source": [
        "def launch():\n",
        "    import os\n",
        "    import StepOne\n",
        "    import torch\n",
        "\n",
        "    os.environ['MODEL_TYPE'] = 'base'\n",
        "    augment = int(os.environ.get('AUGMENT', '4'))\n",
        "    os.environ['BATCH_SIZE'] = '32'\n",
        "    \n",
        "    world_size = torch.cuda.device_count()\n",
        "    torch.multiprocessing.spawn(StepOne.step_one,\n",
        "                                args=(world_size,),\n",
        "                                nprocs=world_size,\n",
        "                                join=True)\n",
        "    \n",
        "launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf16df8-9320-4be9-98f9-da38da180a91",
      "metadata": {},
      "source": [
        "# Step 2: learn ranker using (fixed pre-finetuned) task LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58810c2b-35e5-4efe-bd43-1b5f25c16357",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******** augment = 1 max_iteration = 5 model_type = base *********\n",
            "n              iter (since)      4 loss (since)       4 acc (since) 4 acc (dev) (since)      nsamps (since)      dt\n",
            "1             0.000 (0.000)       0.560 (0.560)       0.719 (0.719)       0.000 (0.000)      57.219 (57.219)  1.16 m\n",
            "2             0.000 (0.000)       0.594 (0.629)       0.750 (0.781)       0.000 (0.000)      30.656 (4.094)  1.63 m\n",
            "4             0.000 (0.000)       0.526 (0.457)       0.781 (0.812)       0.000 (0.000)      17.719 (4.781)  2.48 m\n",
            "8             0.000 (0.000)       0.536 (0.546)       0.781 (0.781)       0.000 (0.000)      11.125 (4.531)  4.44 m\n",
            "16            0.000 (0.000)       0.522 (0.507)       0.791 (0.801)       0.000 (0.000)       8.256 (5.387)  8.53 m\n",
            "32            0.000 (0.000)       0.523 (0.524)       0.789 (0.787)       0.000 (0.000)       6.785 (5.314)    17 m\n",
            "64            0.000 (0.000)       0.522 (0.519)       0.792 (0.799)       0.812 (0.812)       6.043 (4.458)  28.2 m\n",
            "80            0.000 (0.000)       0.522 (0.000)       0.792 (0.000)       0.816 (0.819)       6.043 (0.000)  32.1 m\n",
            "160           0.500 (1.000)       0.514 (0.506)       0.787 (0.781)       0.818 (0.821)       5.286 (4.529)  1.04 h\n",
            "240           1.000 (2.000)       0.504 (0.486)       0.791 (0.800)       0.822 (0.829)       4.905 (4.145)  1.55 h\n",
            "320           1.500 (3.000)       0.500 (0.486)       0.796 (0.811)       0.821 (0.817)       4.739 (4.239)  2.06 h\n",
            "400           2.000 (4.000)       0.500 (0.498)       0.793 (0.782)       0.820 (0.818)       4.677 (4.432)  2.57 h\n"
          ]
        }
      ],
      "source": [
        "def launch():\n",
        "    import os\n",
        "    import StepTwo\n",
        "    import torch\n",
        "\n",
        "    os.environ['MODEL_TYPE'] = 'base'\n",
        "    augment = int(os.environ.get('AUGMENT', '1'))\n",
        "    os.environ['BATCH_SIZE'] = '32'\n",
        "    os.environ['LEARN_BATCH_SIZE'] = '16'\n",
        "    os.environ['STEP1_ITER'] = '0_augment4'\n",
        "    \n",
        "    world_size = torch.cuda.device_count()\n",
        "    torch.multiprocessing.spawn(StepTwo.step_two,\n",
        "                                args=(world_size,),\n",
        "                                nprocs=world_size,\n",
        "                                join=True)\n",
        "    \n",
        "launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19b04cb-41dc-4ad3-b43a-662a2822ce4c",
      "metadata": {},
      "source": [
        "# Step 3: Prepare Submission Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dfe04c6-5858-4130-a12c-308610861567",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** step1_iter: 0_augment4 step2_iter: 2_augment1 nvoters 1 ***\n",
            "n       4 acc (dev) (since)      dt\n",
            "1             0.500 (0.500)  13.4 s\n",
            "2             0.562 (0.625)  26.7 s\n",
            "4             0.719 (0.875)    49 s\n",
            "8             0.766 (0.812)  1.61 m\n",
            "16            0.820 (0.875)  3.12 m\n",
            "32            0.844 (0.867)   6.3 m\n",
            "64            0.820 (0.797)  12.7 m\n",
            "128           0.824 (0.828)  25.6 m\n",
            "256           0.826 (0.875)  54.8 m\n",
            "*** step1_iter: 0_augment4 step2_iter: 2_augment1 nvoters 3 ***\n",
            "n       4 acc (dev) (since)      dt\n",
            "1             0.500 (0.500)  14.1 s\n",
            "2             0.625 (0.750)  28.5 s\n",
            "4             0.750 (0.875)  52.5 s\n",
            "8             0.781 (0.812)   1.7 m\n",
            "16            0.820 (0.859)  3.26 m\n",
            "32            0.840 (0.859)  6.51 m\n",
            "64            0.812 (0.785)    13 m\n",
            "128           0.819 (0.826)  26.3 m\n",
            "256           0.821 (0.875)    56 m\n",
            "*** step1_iter: 0_augment4 step2_iter: 2_augment1 nvoters 5 ***\n",
            "n       4 acc (dev) (since)      dt\n",
            "1             0.500 (0.500)  14.3 s\n",
            "2             0.625 (0.750)    29 s\n",
            "4             0.750 (0.875)  53.3 s\n",
            "8             0.781 (0.812)  1.73 m\n",
            "16            0.820 (0.859)  3.31 m\n",
            "32            0.844 (0.867)  6.64 m\n",
            "64            0.818 (0.793)  13.3 m\n",
            "128           0.826 (0.834)  26.8 m\n",
            "256           0.828 (0.875)  57.2 m\n",
            "*** step1_iter: 0_augment4 step2_iter: 2_augment1 nvoters 7 ***\n",
            "n       4 acc (dev) (since)      dt\n",
            "1             0.500 (0.500)  14.7 s\n",
            "2             0.625 (0.750)  29.7 s\n",
            "4             0.750 (0.875)  54.5 s\n",
            "8             0.766 (0.781)  1.77 m\n",
            "16            0.812 (0.859)   3.4 m\n",
            "32            0.836 (0.859)  6.82 m\n",
            "64            0.812 (0.789)  13.6 m\n",
            "128           0.822 (0.832)  27.5 m\n",
            "256           0.824 (0.875)  58.7 m\n"
          ]
        }
      ],
      "source": [
        "def prepare_submission_probensemble(*, nvoters, step2_iter, step1_iter, k):\n",
        "    import json\n",
        "    from RewardPredictor import RewardPredictor\n",
        "    from TaskLLM import TaskLLM\n",
        "    from PersonalizedNewsCat import dev_loader, test_loader\n",
        "    from ProgressPrinter import ProgressPrinter\n",
        "    from transformers import T5ForConditionalGeneration\n",
        "    import torch\n",
        "    from Util import interleave\n",
        "    \n",
        "    device = 'cuda'\n",
        "    torch.set_default_device(device)\n",
        "    torch.manual_seed(8675309)\n",
        "\n",
        "    dev = dev_loader(batch_size=8)\n",
        "    test = test_loader(batch_size=8)\n",
        "\n",
        "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
        "    t5.load_adapter(f'User_keq{k}_t5base_step1_iter{step1_iter}', 'taskllm')\n",
        "    t5.load_adapter(f'User_keq{k}_t5base_step2_iter{step2_iter}', 'rhat')\n",
        "    t5.enable_adapters()\n",
        "    \n",
        "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\", choices=dev.choices)\n",
        "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\", model_id=f'User_keq{k}_t5base_step2_iter{step2_iter}')\n",
        "\n",
        "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
        "    def randomized_similarity(embeddings, nsamples):\n",
        "        scores = embeddings[0,:] @ embeddings[1:,:].T\n",
        "        temperature = scores[0].item() - scores[min(scores.shape[0]-1, 4)].item()\n",
        "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
        "        gumbels = temperature * gumbel.sample(gumbel_shape).to(scores.device)\n",
        "        safek = min(k, scores.shape[0])\n",
        "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=safek).indices, sorted=False, dim=0)\n",
        "\n",
        "    def inner_batch(func, inner_batch_size, inputs):\n",
        "        from more_itertools import chunked\n",
        "        return [ func(*ib) for ib in zip(*[ chunked(g, inner_batch_size) for g in inputs ]) ]\n",
        "\n",
        "    print(f'*** step1_iter: {step1_iter} step2_iter: {step2_iter} nvoters {nvoters} ***')\n",
        "    \n",
        "    with ProgressPrinter(f'{k} acc (dev)') as printer:\n",
        "        devgolds, testgolds = [], []\n",
        "        cumsum = lambda z, acc=0: [0] + [ acc := acc + v for v in z ]\n",
        "\n",
        "        for isdev, (examples, labels) in interleave(dev, test, sequential=True):\n",
        "            with torch.no_grad():\n",
        "                texts_to_embed = [ [ text[:256]\n",
        "                                     for text in (' '.join(ex['article'].split()), )\n",
        "                                   ] +\n",
        "                                   [ text[:256]\n",
        "                                     for v in ex['profile']\n",
        "                                     for text in (' '.join(v['text'].split()), )\n",
        "                                   ]\n",
        "                                   for ex in examples\n",
        "                                 ]\n",
        "                embeddings = torch.cat(inner_batch(func = dev.embed,\n",
        "                                                   inner_batch_size = 128,\n",
        "                                                   inputs = (sum(texts_to_embed, []),)\n",
        "                                                  ),\n",
        "                                       dim=0)\n",
        "                splits = cumsum(map(len, texts_to_embed))\n",
        "                randos = [ randomized_similarity(embeddings[a:b,:], 64) for a, b in zip(splits, splits[1:]) ]\n",
        "                prompts = [ [ dev.prepend_to_prompt(ex, [ ex['profile'][ind] for ind in indices ])\n",
        "                              for indices in rando.to('cpu').tolist()\n",
        "                            ]\n",
        "                            for ex, rando in zip(examples, randos)\n",
        "                          ]\n",
        "                rhats = torch.cat(inner_batch(func = rewardpredictor.predict,\n",
        "                                              inner_batch_size = 128,\n",
        "                                              inputs = (sum(prompts, []),)\n",
        "                                             ),\n",
        "                                  dim=0)\n",
        "                splits = cumsum(map(len, prompts))\n",
        "                votingprompts = [ [ prompt[v] for v in torch.topk(rhats[a:b].view(-1), k=min(nvoters, b-a)).indices.to('cpu').tolist() ]\n",
        "                                    for a, b, prompt in zip(splits, splits[1:], prompts)\n",
        "                                ]\n",
        "                predicts = torch.cat(inner_batch(func = taskllm.predict,\n",
        "                                                 inner_batch_size = 128,\n",
        "                                                 inputs = (sum(votingprompts, []),)\n",
        "                                                ),\n",
        "                                     dim=0)\n",
        "                splits = cumsum(map(len, votingprompts))\n",
        "                guesses = torch.cat([ predicts[a:b,:].logsumexp(dim=0, keepdim=True).argmax(dim=1)\n",
        "                                      for a, b in zip(splits, splits[1:])\n",
        "                                    ],\n",
        "                                    dim=0)\n",
        "\n",
        "                if isdev:\n",
        "                    targets = [ dev.choices.index(label) for label in labels ]\n",
        "                    targets = torch.Tensor(targets).long().to(guesses.device)\n",
        "                    acc = (guesses == targets).float().mean().item()\n",
        "                else:\n",
        "                    acc = None\n",
        "\n",
        "                for ex, guess in zip(examples, guesses):\n",
        "                    (devgolds if isdev else testgolds).append({ 'id': ex['id'], 'output': dev.choices[guess] })\n",
        "\n",
        "            printer.addobs(acc)\n",
        "\n",
        "        printer.print()\n",
        "        printer.autoprint = False\n",
        "\n",
        "        for wut, golds in ( ('dev', devgolds), ('test', testgolds) ):\n",
        "            with open(f'lamp2u_{wut}golds_t5base_keq{k}_step1_iter{step1_iter}_step2_iter{step2_iter}_nvoters{nvoters}.json', 'w') as jsonfile:\n",
        "                json.dump({ 'task': 'LaMP_2', 'golds': golds }, jsonfile)\n",
        "            \n",
        "for nvoters in [1, 3, 5, 7]:\n",
        "    prepare_submission_probensemble(k=4, step1_iter='0_augment4', step2_iter='2_augment1', nvoters=nvoters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c49603e0-5997-4d92-97e0-2b8c7191bc54",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}