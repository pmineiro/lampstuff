{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Step 1: fine-tune LLM using top result from (fixed) ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n              iter (since)      4 loss (since)       4 MAE (since) 4 MAE (dev) (since)      dt\n",
      "1             0.000 (0.000)       0.954 (0.954)       0.438 (0.438)       0.000 (0.000)  6.77 s\n",
      "2             0.000 (0.000)       0.734 (0.513)       0.344 (0.250)       0.000 (0.000)    12 s\n",
      "4             0.000 (0.000)       0.975 (1.217)       0.578 (0.812)       0.000 (0.000)  18.4 s\n",
      "8             0.000 (0.000)       0.733 (0.491)       0.406 (0.234)       0.000 (0.000)  31.5 s\n",
      "16            0.000 (0.000)       0.697 (0.661)       0.363 (0.320)       0.000 (0.000)  57.7 s\n",
      "32            0.000 (0.000)       0.631 (0.566)       0.311 (0.258)       0.000 (0.000)  1.77 m\n",
      "64            0.000 (0.000)       0.664 (0.697)       0.329 (0.348)       0.000 (0.000)   3.5 m\n",
      "128           0.000 (0.000)       0.641 (0.617)       0.313 (0.297)       0.000 (0.000)  7.08 m\n",
      "256           0.000 (0.000)       0.636 (0.631)       0.307 (0.301)       0.000 (0.000)    14 m\n",
      "512           0.000 (0.000)       0.627 (0.619)       0.302 (0.297)       0.000 (0.000)  28.3 m\n",
      "1024          0.000 (0.000)       0.610 (0.592)       0.293 (0.283)       0.000 (0.000)    57 m\n",
      "2048          0.000 (0.000)       0.590 (0.570)       0.280 (0.267)       0.000 (0.000)  1.91 h\n",
      "2657          0.000 (0.000)       0.581 (0.543)       0.276 (0.257)       0.267 (0.267)  2.45 h\n",
      "5314          0.500 (1.000)       0.556 (0.530)       0.261 (0.246)       0.261 (0.255)  4.89 h\n",
      "7971          1.000 (2.000)       0.544 (0.519)       0.254 (0.241)       0.260 (0.260)  7.33 h\n",
      "10628         1.500 (3.000)       0.533 (0.503)       0.248 (0.230)       0.259 (0.254)  9.76 h\n",
      "13285         2.000 (4.000)       0.526 (0.495)       0.244 (0.229)       0.259 (0.259)  12.2 h\n"
     ]
    }
   ],
   "source": [
    "def step_one(*, k, max_iteration):\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedProductRating import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import LoraConfig, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    train = train_loader(batch_size=8, augment=True)\n",
    "    dev = dev_loader(batch_size=16)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    taskllm_config = LoraConfig(r=5, task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(taskllm_config, \"taskllm\")\n",
    "    t5.enable_adapters()\n",
    "\n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} MAE', f'{k} MAE (dev)') as printer:\n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev, sequential=True):\n",
    "                with torch.no_grad():\n",
    "                    prompts, targets = [], []\n",
    "    \n",
    "                    for ex, label in zip(examples, labels):\n",
    "                        embeddings = dev.embed( [ text[:256]\n",
    "                                                  for text in (' '.join(ex['review'].split()), ) \n",
    "                                                ] + \n",
    "                                                [ text[:256]\n",
    "                                                  for v in ex['profile']\n",
    "                                                  for text in (' '.join(v['text'].split()), )\n",
    "                                                ])\n",
    "                        index = torch.topk(embeddings[0,:] @ embeddings[1:,:].T, dim=0, k=k).indices.to('cpu').tolist()\n",
    "                        profile_examples = [ ex['profile'][ind] for ind in index ]\n",
    "                        prompt = dev.prepend_to_prompt(ex, profile_examples)\n",
    "                        prompts.append(prompt)\n",
    "                        targets.append(int(label)-1)\n",
    "\n",
    "                    targets = torch.Tensor(targets).long().to(device)\n",
    "                    cumul = taskllm.predict(prompts).exp().cumsum(dim=1)\n",
    "                    guesses = (cumul>=0.5).long().argmax(dim=1)\n",
    "                    mae = torch.abs(guesses - targets).float().mean().item()\n",
    "    \n",
    "                loss = taskllm.learn(prompts, targets) if istrain else None\n",
    "                printer.addobs(iteration, loss, mae if istrain else None, mae if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            taskllm.save_pretrained(f'User_keq{k}_t5base_step1_iter{iteration}_loratruncaug')\n",
    "\n",
    "step_one(k=4, max_iteration=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Step 2: learn ranker using (fixed pre-finetuned) task LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58810c2b-35e5-4efe-bd43-1b5f25c16357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_ranker(*, step1_iter, max_iteration, k):\n",
    "    from more_itertools import chunked\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedProductRating import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from SimpleRegret import SimpleRegretHypercubeSampler\n",
    "    from peft import LoraConfig, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(8675309)\n",
    "\n",
    "    train = train_loader(batch_size=8, augment=True)\n",
    "    dev = dev_loader(batch_size=16)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    t5.load_adapter(f'User_keq{k}_t5base_step1_iter{step1_iter}', 'taskllm')\n",
    "\n",
    "    rhat_config = LoraConfig(r=5, task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(rhat_config, \"rhat\")\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\")\n",
    "\n",
    "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
    "    def randomized_similarity(ex, nsamples):\n",
    "        embeddings = dev.embed( [ text[:256]\n",
    "                                  for text in (' '.join(ex['review'].split()), ) \n",
    "                                ] + \n",
    "                                [ text[:256]\n",
    "                                  for v in ex['profile']\n",
    "                                  for text in (' '.join(v['text'].split()), )\n",
    "                                ])\n",
    "        scores = embeddings[0,:] @ embeddings[1:,:].T\n",
    "        temperature = scores[0].item() - scores[min(scores.shape[0], 4)].item()\n",
    "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
    "        gumbels = temperature * gumbel.sample(gumbel_shape)\n",
    "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=k).indices, sorted=False, dim=0).to('cpu')\n",
    "\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} MAE', f'{k} MAE (dev)', 'samps') as printer:\n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev, sequential=True):\n",
    "                greedymaes, allloss, nsamps = [], [], []\n",
    "\n",
    "                for ex, label in zip(examples, labels):\n",
    "                    with torch.no_grad():\n",
    "                        randos = randomized_similarity(ex, 64)\n",
    "                        \n",
    "                        prompts, rhatprompts = [], []\n",
    "                        for rando in randos:\n",
    "                            profile_examples = [ ex['profile'][ind] for ind in rando ]\n",
    "                            prompt = dev.prepend_to_prompt(ex, profile_examples)\n",
    "                            prompts.append(prompt)\n",
    "                            rhatprompt = '\\n'.join([ f\"Example: {text[:256]}\\nScore: {v['score']}\" \n",
    "                                                     for ind in rando\n",
    "                                                     for v in (ex['profile'][ind],)\n",
    "                                                     for text in (' '.join(v['text'].split()),)\n",
    "                                                   ] + [ f\"Review: {text[:256]}\"\n",
    "                                                         for text in (' '.join(ex['review'].split()),) \n",
    "                                                       ])\n",
    "                            rhatprompts.append(rhatprompt)\n",
    "\n",
    "                        rhats = rewardpredictor.predict(rhatprompts)\n",
    "                        exploit, explore = SimpleRegretHypercubeSampler(rhats.view(1, -1), gamma=4)\n",
    "                        exploit = [ exploit.item() ]\n",
    "                        explore = explore[0].tolist() if istrain else []\n",
    "                        actionind = exploit + [ n for n, observed in enumerate(explore) if observed > 0 ]\n",
    "                        nsamps.append(len(actionind))\n",
    "                        cumul = taskllm.predict([ prompts[a] for a in actionind ]).exp().cumsum(dim=1)\n",
    "                        guesses = (cumul>=0.5).long().argmax(dim=1)\n",
    "                        target = int(label) - 1\n",
    "                        rewards = (1 - torch.abs((guesses - target)/4).float()).tolist()\n",
    "                        greedymae = torch.abs(guesses[0] - target).item()\n",
    "                        greedymaes.append(greedymae)\n",
    "\n",
    "                    if istrain:\n",
    "                        inner_batch_size = 4\n",
    "                        loss = sum(\n",
    "                            len(inner_batch[0]) * \n",
    "                            rewardpredictor.learn([ rhatprompts[a] for a in inner_batch[0] ], \n",
    "                                                    torch.Tensor([ [ r ] for r in inner_batch[1] ]).to(device)\n",
    "                                                 )\n",
    "                            for inner_batch in zip(chunked(actionind, inner_batch_size), chunked(rewards, inner_batch_size))\n",
    "                        ) / len(actionind)\n",
    "                        allloss.append(loss)\n",
    "\n",
    "                greedymae = torch.Tensor(greedymaes).float().mean().item()\n",
    "                predloss = torch.Tensor(allloss).mean().item() if istrain else None\n",
    "                nsamps = torch.Tensor(nsamps).float().mean().item() if istrain else None\n",
    "\n",
    "                printer.addobs(iteration, predloss, greedymae if istrain else None, greedymae if not istrain else None, nsamps)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            rewardpredictor.save_pretrained(f'User_keq{k}_t5base_step2_iter{iteration}_loratruncaug_hyper')\n",
    "\n",
    "learn_ranker(k=4, max_iteration=12, step1_iter='3_loratruncaug')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
