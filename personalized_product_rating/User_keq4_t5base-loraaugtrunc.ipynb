{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Step 1: fine-tune LLM using top result from (fixed) ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_one(*, k, max_iteration):\n",
    "    import os\n",
    "    from PersonalizedProductRating import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from peft import LoraConfig, TaskType\n",
    "    from TaskLLM import TaskLLM\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave, set_directory\n",
    "\n",
    "    torch.manual_seed(2112)\n",
    "\n",
    "    augment = int(os.environ.get('AUGMENT', '1'))\n",
    "    train = train_loader(batch_size=8, augment=augment)\n",
    "    dev = dev_loader(batch_size=16)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    taskllm_config = LoraConfig(r=5, task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(taskllm_config, \"taskllm\")\n",
    "    t5.enable_adapters()\n",
    "\n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "\n",
    "    def inner_batch(func, inner_batch_size, inputs):\n",
    "        from more_itertools import chunked\n",
    "        return [ func(*ib) for ib in zip(*[ chunked(g, inner_batch_size) for g in inputs ]) ]\n",
    "\n",
    "    print(f'************ augment = {augment} *************')\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} MAE', f'{k} MAE (dev)') as printer:\n",
    "        cumsum = lambda z, acc=0: [0] + [ acc := acc + v for v in z ]\n",
    "        \n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev, sequential=True):\n",
    "                with torch.no_grad():\n",
    "                    texts_to_embed = [ [ text[:256]\n",
    "                                         for text in (' '.join(ex['review'].split()), ) \n",
    "                                       ] + \n",
    "                                       [ text[:256]\n",
    "                                         for v in ex['profile']\n",
    "                                         for text in (' '.join(v['text'].split()), )\n",
    "                                       ]\n",
    "                                       for ex in examples\n",
    "                                     ]\n",
    "                    embeddings = torch.cat(inner_batch(func = lambda t: dev.embed(t),\n",
    "                                                       inner_batch_size = 64 * torch.cuda.device_count(),\n",
    "                                                       inputs = (sum(texts_to_embed, []),)\n",
    "                                                      ),\n",
    "                                           dim=0)\n",
    "                    splits = cumsum(map(len, texts_to_embed))\n",
    "                    indices = [ torch.topk(embeddings[a,:] @ embeddings[a+1:b,:].T, dim=0, k=k).indices for a, b in zip(splits, splits[1:]) ]\n",
    "                    prompts = [ dev.prepend_to_prompt(ex, [ ex['profile'][ind] for ind in index.to('cpu').tolist() ])\n",
    "                                for ex, index in zip(examples, indices) ]\n",
    "                    targets = [ int(label) - 1 for label in labels ]\n",
    "                    cumul = taskllm.predict(prompts).exp().cumsum(dim=1)\n",
    "                    guesses = (cumul>=0.5).long().argmax(dim=1)\n",
    "                    targets = torch.Tensor(targets).long().to(guesses.device)\n",
    "                    mae = torch.abs(guesses - targets).float().mean().item()\n",
    "\n",
    "                loss = taskllm.learn(prompts, targets) if istrain else None\n",
    "                printer.addobs(iteration, loss, mae if istrain else None, mae if not istrain else None)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            output_dir = os.environ.get('AMLT_OUTPUT_DIR', '.')\n",
    "            with set_directory(output_dir):\n",
    "                taskllm.save_pretrained(f'User_keq{k}_t5base_step1_iter{iteration}_augment{augment}')\n",
    "\n",
    "step_one(k=4, max_iteration=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Step 2: learn ranker using (fixed pre-finetuned) task LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58810c2b-35e5-4efe-bd43-1b5f25c16357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_ranker(*, step1_iter, max_iteration, k):\n",
    "    import os\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedProductRating import train_loader, dev_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from SimpleRegret import SimpleRegretHypercubeSampler\n",
    "    from peft import LoraConfig, TaskType\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave, set_directory\n",
    "    \n",
    "    torch.manual_seed(8675309)\n",
    "\n",
    "    augment = int(os.environ.get('AUGMENT', '1'))\n",
    "    train = train_loader(batch_size=8, augment=augment)\n",
    "    dev = dev_loader(batch_size=16)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "    t5.load_adapter(f'User_keq{k}_t5base_step1_iter{step1_iter}', 'taskllm')\n",
    "\n",
    "    rhat_config = LoraConfig(r=1, task_type=TaskType.SEQ_2_SEQ_LM)\n",
    "    t5.add_adapter(rhat_config, \"rhat\")\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\")\n",
    "\n",
    "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
    "    def randomized_similarity(embeddings, nsamples):\n",
    "        scores = embeddings[0,:] @ embeddings[1:,:].T\n",
    "        temperature = scores[0].item() - scores[min(scores.shape[0], 4)].item()\n",
    "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
    "        gumbels = temperature * gumbel.sample(gumbel_shape).to(scores.device)\n",
    "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=k).indices, sorted=False, dim=0)\n",
    "\n",
    "    def inner_batch(func, inner_batch_size, inputs):\n",
    "        from more_itertools import chunked\n",
    "        return [ func(*ib) for ib in zip(*[ chunked(g, inner_batch_size) for g in inputs ]) ]\n",
    "\n",
    "    print(f'************ augment = {augment} *************')\n",
    "    with ProgressPrinter('iter', f'{k} loss', f'{k} MAE', f'{k} MAE (dev)', 'samps') as printer:\n",
    "        cumsum = lambda z, acc=0: [0] + [ acc := acc + v for v in z ]\n",
    "        \n",
    "        for iteration in range(max_iteration):\n",
    "            for istrain, (examples, labels) in interleave(train, dev, sequential=True):\n",
    "                with torch.no_grad():\n",
    "                    texts_to_embed = [ [ text[:256]\n",
    "                                         for text in (' '.join(ex['review'].split()), ) \n",
    "                                       ] + \n",
    "                                       [ text[:256]\n",
    "                                         for v in ex['profile']\n",
    "                                         for text in (' '.join(v['text'].split()), )\n",
    "                                       ]\n",
    "                                       for ex in examples\n",
    "                                     ]\n",
    "                    embeddings = torch.cat(inner_batch(func = lambda t: dev.embed(t),\n",
    "                                                       inner_batch_size = 64 * torch.cuda.device_count(),\n",
    "                                                       inputs = (sum(texts_to_embed, []),)\n",
    "                                                      ),\n",
    "                                           dim=0)\n",
    "                    splits = cumsum(map(len, texts_to_embed))\n",
    "                    randos = [ randomized_similarity(embeddings[a:b,:], 64) for a, b in zip(splits, splits[1:]) ]\n",
    "                    prompts = [ [ dev.prepend_to_prompt(ex, [ ex['profile'][ind] for ind in indices ]) \n",
    "                                  for indices in rando.to('cpu').tolist() \n",
    "                                ]\n",
    "                                for ex, rando in zip(examples, randos) \n",
    "                              ]\n",
    "                    rhats = torch.cat(inner_batch(func = lambda p: rewardpredictor.predict(p),\n",
    "                                                  inner_batch_size = 64 * torch.cuda.device_count(),\n",
    "                                                  inputs = (sum(prompts, []),)\n",
    "                                                 ),\n",
    "                                      dim=0)\n",
    "                    splits = cumsum(map(len, prompts))\n",
    "                    samples = [ SimpleRegretHypercubeSampler(rhats[a:b].view(1, -1), gamma=4) for a, b in zip(splits, splits[1:]) ]\n",
    "                    actionind = [ [ exploit.item() ] + [ n for n, observed in enumerate(explore) if observed > 0 ]\n",
    "                                  for exploit, exploreraw in samples\n",
    "                                  for explore in (exploreraw[0].tolist() if istrain else [], )\n",
    "                                ]\n",
    "                    nsamps = [ len(aind) for aind in actionind ]\n",
    "                    guessprompts = [ [ prompt[a] for a in aind ] for prompt, aind in zip(prompts, actionind) ]\n",
    "                    cumul = torch.cat(inner_batch(func = lambda p: taskllm.predict(p).exp().cumsum(dim=1),\n",
    "                                                  inner_batch_size = 64 * torch.cuda.device_count(),\n",
    "                                                  inputs = (sum(guessprompts, []),)\n",
    "                                                 ),\n",
    "                                      dim=0)\n",
    "                    splits = cumsum(map(len, guessprompts))\n",
    "                    guesses = [ (cumul[a:b,:]>=0.5).long().argmax(dim=1) for a, b in zip(splits, splits[1:]) ]\n",
    "                    targets = [ int(label) - 1 for label in labels ]\n",
    "                    rewards = [ (1 - torch.abs((g - target)/4).float()).tolist() for g, target in zip(guesses, targets) ]\n",
    "                    greedymaes = [ torch.abs(g[0] - target).item() for g, target in zip(guesses, targets) ] \n",
    "\n",
    "                if istrain:\n",
    "                    rhatprompts = sum(guessprompts, [])\n",
    "                    rhattargets = sum(rewards, [])\n",
    "                    predlosses = inner_batch(func = lambda a, b: (len(a), rewardpredictor.learn(a, torch.Tensor([ [ r ] for r in b ]))),\n",
    "                                             inner_batch_size = 16 * torch.cuda.device_count(),\n",
    "                                             inputs = (rhatprompts, rhattargets)\n",
    "                                            )\n",
    "                    predloss = sum(n * v for n, v in predlosses) / sum(n for n, v in predlosses)\n",
    "                else:\n",
    "                    predloss = None\n",
    "\n",
    "                greedymae = torch.Tensor(greedymaes, device='cpu').float().mean().item()\n",
    "                nsamps = torch.Tensor(nsamps, device='cpu').float().mean().item() if istrain else None\n",
    "\n",
    "                printer.addobs(iteration, predloss, greedymae if istrain else None, greedymae if not istrain else None, nsamps)\n",
    "\n",
    "            printer.print()\n",
    "            printer.autoprint = False\n",
    "            output_dir = os.environ.get('AMLT_OUTPUT_DIR', '.')\n",
    "            with set_directory(output_dir):\n",
    "                taskllm.save_pretrained(f'User_keq{k}_t5base_step2_iter{iteration}_augment{augment}')\n",
    "                \n",
    "learn_ranker(k=4, max_iteration=2, step1_iter='0_augment8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa5c51-2bce-415a-8abf-e7ce3d0e1cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
