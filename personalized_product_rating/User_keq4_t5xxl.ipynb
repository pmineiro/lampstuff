{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a258105a-3b77-499a-bc5c-6e1ceb3e92e5",
   "metadata": {},
   "source": [
    "# Step 1: fine-tune LLM using top result from (fixed) ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f4483a-9d5d-4c65-923c-cc9e327c9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** augment = 4 max_iteration = 5 model_type = xxl *********\n",
      "n              iter (since)      4 loss (since)       4 MAE (since) 4 MAE (dev) (since)      dt\n",
      "8             0.000 (0.000)       0.374 (0.698)       0.500 (1.000)       0.000 (0.000)  22.1 s\n",
      "16            0.000 (0.000)       0.331 (0.288)       0.250 (0.000)       0.000 (0.000)  43.5 s\n",
      "32            0.000 (0.000)       0.374 (0.416)       0.219 (0.188)       0.000 (0.000)  1.41 m\n",
      "64            0.000 (0.000)       0.640 (0.905)       0.297 (0.375)       0.000 (0.000)  2.76 m\n",
      "128           0.000 (0.000)       0.654 (0.669)       0.328 (0.359)       0.000 (0.000)  5.57 m\n",
      "256           0.000 (0.000)       0.635 (0.615)       0.297 (0.266)       0.000 (0.000)  11.1 m\n",
      "512           0.000 (0.000)       0.553 (0.472)       0.258 (0.219)       0.000 (0.000)    22 m\n",
      "1024          0.000 (0.000)       0.541 (0.529)       0.237 (0.217)       0.000 (0.000)  44.6 m\n",
      "2048          0.000 (0.000)       0.532 (0.524)       0.238 (0.239)       0.000 (0.000)  1.48 h\n",
      "4096          0.000 (0.000)       0.526 (0.519)       0.234 (0.230)       0.000 (0.000)  2.97 h\n",
      "8192          0.000 (0.000)       0.503 (0.479)       0.227 (0.220)       0.000 (0.000)  5.94 h\n",
      "16384         0.000 (0.000)       0.480 (0.457)       0.217 (0.207)       0.000 (0.000)  11.9 h\n",
      "27500         0.000 (0.000)       0.477 (0.471)       0.216 (0.213)       0.209 (0.209)  18.8 h\n",
      "55000         0.500 (1.000)       0.467 (0.457)       0.209 (0.203)       0.211 (0.213)  1.56 d\n",
      "82500         1.000 (2.000)       0.462 (0.451)       0.207 (0.202)       0.209 (0.206)  2.34 d\n",
      "110000        1.500 (3.000)       0.457 (0.445)       0.205 (0.200)       0.208 (0.206)  3.12 d\n"
     ]
    }
   ],
   "source": [
    "# NB: amulet dropped some of the log output when this was run (?)\n",
    "def launch():\n",
    "    import os\n",
    "    import StepOne\n",
    "    import torch\n",
    "\n",
    "    os.environ['MODEL_TYPE'] = 'xxl'\n",
    "    augment = int(os.environ.get('AUGMENT', '4'))\n",
    "    os.environ['BATCH_SIZE'] = '1'\n",
    "    \n",
    "    world_size = torch.cuda.device_count()\n",
    "    torch.multiprocessing.spawn(StepOne.step_one,\n",
    "                                args=(world_size,),\n",
    "                                nprocs=world_size,\n",
    "                                join=True)\n",
    "    \n",
    "launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf16df8-9320-4be9-98f9-da38da180a91",
   "metadata": {},
   "source": [
    "# Step 2: learn ranker using (fixed pre-finetuned) task LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58810c2b-35e5-4efe-bd43-1b5f25c16357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** augment = 0 max_iteration = 5 model_type = xxl *********\n",
      "n              iter (since)      4 loss (since)       4 MAE (since) 4 MAE (dev) (since)      nsamps (since)      dt\n",
      "1             0.000 (0.000)       0.234 (0.234)       0.000 (0.000)       0.000 (0.000)      64.000 (64.000)  37.5 s\n",
      "2             0.000 (0.000)       0.118 (0.001)       0.000 (0.000)       0.000 (0.000)      33.000 (2.000)    45 s\n",
      "4             0.000 (0.000)       1.786 (3.455)       0.250 (0.500)       0.000 (0.000)      17.750 (2.500)  56.4 s\n",
      "8             0.000 (0.000)       1.210 (0.634)       0.250 (0.250)       0.000 (0.000)      19.125 (20.500)  1.71 m\n",
      "16            0.000 (0.000)       0.928 (0.647)       0.312 (0.375)       0.000 (0.000)      15.000 (10.875)  3.29 m\n",
      "32            0.000 (0.000)       0.670 (0.412)       0.219 (0.125)       0.000 (0.000)      11.750 (8.500)  5.37 m\n",
      "64            0.000 (0.000)       0.592 (0.514)       0.219 (0.219)       0.000 (0.000)       8.859 (5.969)  9.25 m\n",
      "128           0.000 (0.000)       0.510 (0.428)       0.195 (0.172)       0.000 (0.000)       6.727 (4.594)  16.5 m\n",
      "256           0.000 (0.000)       0.533 (0.557)       0.215 (0.234)       0.000 (0.000)       6.473 (6.219)  32.9 m\n",
      "512           0.000 (0.000)       0.529 (0.524)       0.219 (0.223)       0.000 (0.000)       6.350 (6.227)  1.08 h\n",
      "1024          0.000 (0.000)       0.499 (0.468)       0.198 (0.178)       0.000 (0.000)       5.821 (5.293)  2.12 h\n",
      "2048          0.000 (0.000)       0.497 (0.496)       0.195 (0.191)       0.000 (0.000)       5.844 (5.866)  4.24 h\n",
      "4096          0.000 (0.000)       0.477 (0.457)       0.196 (0.197)       0.000 (0.000)       5.608 (5.373)  8.43 h\n",
      "8192          0.000 (0.000)       0.461 (0.445)       0.199 (0.201)       0.000 (0.000)       5.359 (5.111)  16.7 h\n",
      "16384         0.000 (0.000)       0.439 (0.418)       0.197 (0.195)       0.000 (0.000)       4.998 (4.637)  1.35 d\n",
      "22500         0.000 (0.000)       0.435 (0.412)       0.197 (0.198)       0.214 (0.214)       4.916 (4.541)  1.79 d\n",
      "45000         0.500 (1.000)       0.421 (0.408)       0.196 (0.195)       0.215 (0.216)       4.653 (4.390)  3.52 d\n",
      "67500         1.000 (2.000)       0.414 (0.399)       0.195 (0.195)       0.217 (0.223)       4.508 (4.219)  5.23 d\n",
      "90000         1.500 (3.000)       0.409 (0.394)       0.196 (0.199)       0.217 (0.217)       4.430 (4.196)  6.94 d\n",
      "112500        2.000 (4.000)       0.404 (0.385)       0.196 (0.197)       0.217 (0.218)       4.375 (4.152)  1.24 w\n"
     ]
    }
   ],
   "source": [
    "def launch():\n",
    "    import os\n",
    "    import StepTwo\n",
    "    import torch\n",
    "\n",
    "    # NB: these are 80Gb gpu ram settings\n",
    "    os.environ['MODEL_TYPE'] = 'xxl'\n",
    "    os.environ['BATCH_SIZE'] = '1'\n",
    "    os.environ['LEARN_BATCH_SIZE'] = '4'\n",
    "    os.environ['STEP1_ITER'] = '2_augment4'\n",
    "    \n",
    "    world_size = torch.cuda.device_count()\n",
    "    torch.multiprocessing.spawn(StepTwo.step_two,\n",
    "                                args=(world_size,),\n",
    "                                nprocs=world_size,\n",
    "                                join=True)\n",
    "    \n",
    "launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0883bfa-8314-4417-a7bf-00d19fb0fc9c",
   "metadata": {},
   "source": [
    "# Step 3: Prepare Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508c656-d8f7-4987-8003-944f1f9ee516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** step1_iter: 2_augment4 step2_iter: 0_augment0 nvoters 1 ***\n",
      "n       4 MAE (dev) (since) 4 MSE (dev) (since)      dt\n",
      "1             0.000 (0.000)       0.000 (0.000)  1.26 s\n",
      "2             0.500 (1.000)       0.500 (1.000)  10.2 s\n",
      "4             0.500 (0.500)       0.500 (0.500)  44.2 s\n",
      "8             0.375 (0.250)       0.375 (0.250)  1.61 m\n",
      "16            0.312 (0.250)       0.312 (0.250)  3.34 m\n",
      "32            0.219 (0.125)       0.219 (0.125)  6.81 m\n",
      "64            0.234 (0.250)       0.234 (0.250)  12.9 m\n",
      "128           0.242 (0.250)       0.258 (0.281)  27.2 m\n",
      "256           0.207 (0.172)       0.215 (0.172)  53.5 m\n",
      "512           0.227 (0.246)       0.258 (0.301)  1.77 h\n",
      "1024          0.227 (0.227)       0.256 (0.254)  3.57 h\n",
      "2048          0.213 (0.200)       0.233 (0.210)  7.11 h\n",
      "4096          0.211 (0.199)       0.231 (0.221)  14.4 h\n",
      "*** step1_iter: 2_augment4 step2_iter: 0_augment0 nvoters 3 ***\n",
      "n       4 MAE (dev) (since) 4 MSE (dev) (since)      dt\n",
      "1             0.000 (0.000)       0.000 (0.000)  1.46 s\n",
      "2             0.500 (1.000)       0.500 (1.000)  10.7 s\n",
      "4             0.500 (0.500)       0.500 (0.500)  45.8 s\n",
      "8             0.375 (0.250)       0.375 (0.250)  1.66 m\n",
      "16            0.250 (0.125)       0.250 (0.125)  3.45 m\n",
      "32            0.188 (0.125)       0.188 (0.125)  7.02 m\n",
      "64            0.234 (0.281)       0.234 (0.281)  13.3 m\n",
      "128           0.250 (0.266)       0.266 (0.297)    28 m\n",
      "256           0.223 (0.195)       0.238 (0.211)  55.3 m\n",
      "512           0.229 (0.234)       0.260 (0.281)  1.83 h\n",
      "1024          0.224 (0.219)       0.253 (0.246)   3.7 h\n",
      "2048          0.210 (0.196)       0.229 (0.206)  7.37 h\n",
      "4096          0.207 (0.195)       0.229 (0.226)  14.9 h\n",
      "*** step1_iter: 2_augment4 step2_iter: 0_augment0 nvoters 5 ***\n",
      "n       4 MAE (dev) (since) 4 MSE (dev) (since)      dt\n",
      "1             0.000 (0.000)       0.000 (0.000)  1.43 s\n",
      "2             0.500 (1.000)       0.500 (1.000)    11 s\n",
      "4             0.500 (0.500)       0.500 (0.500)  47.2 s\n",
      "8             0.375 (0.250)       0.375 (0.250)  1.71 m\n",
      "16            0.250 (0.125)       0.250 (0.125)  3.54 m\n",
      "32            0.188 (0.125)       0.188 (0.125)   7.2 m\n",
      "64            0.219 (0.250)       0.219 (0.250)  13.7 m\n",
      "128           0.227 (0.234)       0.242 (0.266)  28.8 m\n",
      "256           0.191 (0.156)       0.207 (0.172)  56.7 m\n",
      "512           0.211 (0.230)       0.242 (0.277)  1.88 h\n",
      "1024          0.212 (0.213)       0.241 (0.240)   3.8 h\n",
      "2048          0.203 (0.193)       0.222 (0.203)  7.61 h\n",
      "4096          0.202 (0.201)       0.225 (0.237)  15.4 h\n",
      "*** step1_iter: 2_augment4 step2_iter: 0_augment0 nvoters 7 ***\n",
      "n       4 MAE (dev) (since) 4 MSE (dev) (since)      dt\n",
      "1             0.000 (0.000)       0.000 (0.000)  1.46 s\n",
      "2             0.500 (1.000)       0.500 (1.000)  11.4 s\n",
      "4             0.500 (0.500)       0.500 (0.500)  48.9 s\n",
      "8             0.375 (0.250)       0.375 (0.250)  1.76 m\n",
      "16            0.250 (0.125)       0.250 (0.125)  3.65 m\n",
      "32            0.188 (0.125)       0.188 (0.125)  7.42 m\n",
      "64            0.234 (0.281)       0.234 (0.281)  14.1 m\n",
      "128           0.250 (0.266)       0.266 (0.297)  29.7 m\n",
      "256           0.215 (0.180)       0.230 (0.195)  58.4 m\n",
      "512           0.225 (0.234)       0.256 (0.281)  1.94 h\n",
      "1024          0.217 (0.209)       0.244 (0.232)   3.9 h\n",
      "2048          0.206 (0.194)       0.224 (0.204)  7.79 h\n",
      "4096          0.204 (0.195)       0.224 (0.221)  15.8 h\n"
     ]
    }
   ],
   "source": [
    "def prepare_submission_probensemble(*, nvoters, step2_iter, step1_iter, k):\n",
    "    import json\n",
    "    from RewardPredictor import RewardPredictor\n",
    "    from TaskLLM import TaskLLM\n",
    "    from PersonalizedProductRating import dev_loader, test_loader\n",
    "    from ProgressPrinter import ProgressPrinter\n",
    "    from transformers import T5ForConditionalGeneration\n",
    "    import torch\n",
    "    from Util import interleave\n",
    "    \n",
    "    device = 'cuda'\n",
    "    torch.set_default_device(device)\n",
    "    torch.manual_seed(8675309)\n",
    "\n",
    "    dev = dev_loader(batch_size=1)\n",
    "    test = test_loader(batch_size=1)\n",
    "\n",
    "    t5 = T5ForConditionalGeneration.from_pretrained('google/flan-t5-xxl')\n",
    "    t5.load_adapter(f'User_keq{k}_t5xxl_step1_iter{step1_iter}', 'taskllm')\n",
    "    t5.load_adapter(f'User_keq{k}_t5xxl_step2_iter{step2_iter}', 'rhat')\n",
    "    t5.enable_adapters()\n",
    "    \n",
    "    taskllm = TaskLLM(t5=t5, adapter_name=\"taskllm\")\n",
    "    rewardpredictor = RewardPredictor(t5=t5, adapter_name=\"rhat\", model_id=f'User_keq{k}_t5xxl_step2_iter{step2_iter}')\n",
    "\n",
    "    gumbel = torch.distributions.gumbel.Gumbel(0,1)\n",
    "    def randomized_similarity(embeddings, nsamples):\n",
    "        scores = embeddings[0,:] @ embeddings[1:,:].T\n",
    "        temperature = scores[0].item() - scores[min(scores.shape[0], 4)].item()\n",
    "        gumbel_shape = torch.Size([nsamples, scores.shape[0]])\n",
    "        gumbels = temperature * gumbel.sample(gumbel_shape).to(scores.device)\n",
    "        return torch.unique(torch.topk(scores.unsqueeze(0) + gumbels, dim=1, k=k).indices, sorted=False, dim=0)\n",
    "\n",
    "    def inner_batch(func, inner_batch_size, inputs):\n",
    "        from more_itertools import chunked\n",
    "        return [ func(*ib) for ib in zip(*[ chunked(g, inner_batch_size) for g in inputs ]) ]\n",
    "\n",
    "    print(f'*** step1_iter: {step1_iter} step2_iter: {step2_iter} nvoters {nvoters} ***')\n",
    "    \n",
    "    with ProgressPrinter(f'{k} MAE (dev)', f'{k} MSE (dev)') as printer:\n",
    "        devgolds, testgolds = [], []\n",
    "        cumsum = lambda z, acc=0: [0] + [ acc := acc + v for v in z ]\n",
    "\n",
    "        for isdev, (examples, labels) in interleave(dev, test, sequential=True):\n",
    "            with torch.no_grad():\n",
    "                texts_to_embed = [ [ text[:256]\n",
    "                                     for text in (' '.join(ex['review'].split()), )\n",
    "                                   ] +\n",
    "                                   [ text[:256]\n",
    "                                     for v in ex['profile']\n",
    "                                     for text in (' '.join(v['text'].split()), )\n",
    "                                   ]\n",
    "                                   for ex in examples\n",
    "                                 ]\n",
    "                embeddings = torch.cat(inner_batch(func = dev.embed,\n",
    "                                                   inner_batch_size = 128,\n",
    "                                                   inputs = (sum(texts_to_embed, []),)\n",
    "                                                  ),\n",
    "                                       dim=0)\n",
    "                splits = cumsum(map(len, texts_to_embed))\n",
    "                randos = [ randomized_similarity(embeddings[a:b,:], 64) for a, b in zip(splits, splits[1:]) ]\n",
    "                prompts = [ [ dev.prepend_to_prompt(ex, [ ex['profile'][ind] for ind in indices ])\n",
    "                              for indices in rando.to('cpu').tolist()\n",
    "                            ]\n",
    "                            for ex, rando in zip(examples, randos)\n",
    "                          ]\n",
    "                rhats = torch.cat(inner_batch(func = rewardpredictor.predict,\n",
    "                                              inner_batch_size = 128,\n",
    "                                              inputs = (sum(prompts, []),)\n",
    "                                             ),\n",
    "                                  dim=0)\n",
    "                splits = cumsum(map(len, prompts))\n",
    "                votingprompts = [ [ prompt[v] for v in torch.topk(rhats[a:b].view(-1), k=min(nvoters, b-a)).indices.to('cpu').tolist() ]\n",
    "                                    for a, b, prompt in zip(splits, splits[1:], prompts)\n",
    "                                ]\n",
    "                predicts = torch.cat(inner_batch(func = taskllm.predict,\n",
    "                                                 inner_batch_size = 128,\n",
    "                                                 inputs = (sum(votingprompts, []),)\n",
    "                                                ),\n",
    "                                     dim=0)\n",
    "                splits = cumsum(map(len, votingprompts))\n",
    "                guesses = torch.cat([ (predicts[a:b,:].logsumexp(dim=0, keepdim=True).exp().cumsum(dim=1) >= 0.5 * (b-a)).long().argmax(dim=1)\n",
    "                                      for a, b in zip(splits, splits[1:])\n",
    "                                    ],\n",
    "                                    dim=0)\n",
    "\n",
    "                if isdev:\n",
    "                    targets = [ int(label) - 1 for label in labels ]\n",
    "                    targets = torch.Tensor(targets).long().to(guesses.device)\n",
    "                    mae = torch.abs(guesses - targets).float().mean().item()\n",
    "                    mse = torch.square(guesses - targets).float().mean().item()\n",
    "                else:\n",
    "                    mae, mse = None, None\n",
    "\n",
    "                for ex, guess in zip(examples, guesses):\n",
    "                    (devgolds if isdev else testgolds).append({ 'id': ex['id'], 'output': f'{1+guess}' })\n",
    "\n",
    "            printer.addobs(mae, mse)\n",
    "\n",
    "        printer.print()\n",
    "        printer.autoprint = False\n",
    "\n",
    "        for wut, golds in ( ('dev', devgolds), ('test', testgolds) ):\n",
    "            with open(f'lamp3u_{wut}golds_t5xxl_keq{k}_step1_iter{step1_iter}_step2_iter{step2_iter}_nvoters{nvoters}.json', 'w') as jsonfile:\n",
    "                json.dump({ 'task': 'LaMP_3', 'golds': golds }, jsonfile)\n",
    "            \n",
    "for nvoters in [1, 3, 5, 7]:\n",
    "    # ugh ... without complete cleanup, run out of memory\n",
    "    from multiprocessing import Process\n",
    "    p = Process(target=prepare_submission_probensemble, \n",
    "                kwargs = { 'k': 4,\n",
    "                           'step1_iter': '2_augment4', \n",
    "                           'step2_iter': '0_augment0', \n",
    "                           'nvoters': nvoters\n",
    "                         })\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ef598-0f93-4a5f-a9ab-2c582bc5a407",
   "metadata": {},
   "source": [
    "```\n",
    "Hi, this is the results of your submissions to the LaMP benchmark:\n",
    "\n",
    "LaMP-3:\n",
    "{\"MAE\": 0.1932, \"RMSE\": 0.46604720790924176}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dcfeeb-dd4a-4467-bd8c-ce08f15e9d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
